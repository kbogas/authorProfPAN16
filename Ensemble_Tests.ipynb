{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAN16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "Learning to judge gender..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from pan import preprocess\n",
    "\n",
    "task = 'gender'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)\n",
    "print len(X)\n",
    "X = preprocess.preprocess(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "X, y = dataset.get_data('age')\n",
    "#X, y = dataset.get_data('gender')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3grams',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[2, 2], norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('svm', SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from pan.features import SOA_Model2\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[2,2], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "svm = SVC(kernel='rbf', C=10, gamma=1, class_weight='balanced', probability=False)\n",
    "pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "        tokenizer_var='sklearn')),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=False)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])+\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pan.features import LSI_Model\n",
    "LSImodel = LSI_Model(num_topics=100)\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=False)\n",
    "#pipe2 = Pipeline([('counts',combined), ('svm', svm)])\n",
    "pipe2 = Pipeline([('LSI',LSImodel), ('svm', svm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    temp = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            temp[i,j] = len([m for l, m in enumerate(predictions[i]) if (m==predictions[j][l] and m==predictions[N-1][l])])/float(len(predictions[0]))\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (names[i],  names[j], 100*res[i,j], 100*temp[i,j])\n",
    "    return  [res, temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(combinations)\n",
    "combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 65 65 432 436\n",
      "Fit took: 11.881 seconds\n",
      "Predict took: 248.361 seconds\n",
      "Round 0 took: 288.737 seconds\n",
      "303 65 64 432 436\n",
      "Fit took: 11.593 seconds\n",
      "Predict took: 293.411 seconds\n",
      "Round 1 took: 332.095 seconds\n",
      "303 65 64 432 436\n",
      "Fit took: 11.497 seconds\n",
      "Predict took: 270.229 seconds\n",
      "Round 2 took: 308.851 seconds\n",
      "302 65 65 432 436\n",
      "Fit took: 11.357 seconds\n",
      "Predict took: 301.399 seconds\n",
      "Round 3 took: 339.907 seconds\n",
      "302 65 65 432 436\n",
      "Fit took: 11.556 seconds\n",
      "Predict took: 373.047 seconds\n",
      "Round 4 took: 412.087 seconds\n",
      "303 65 64 432 436\n",
      "Fit took: 12.338 seconds\n",
      "Predict took: 275.913 seconds\n",
      "Round 5 took: 316.432 seconds\n",
      "301 66 65 432 436\n",
      "Fit took: 11.370 seconds\n",
      "Predict took: 334.509 seconds\n",
      "Round 6 took: 372.412 seconds\n",
      "305 64 63 432 436\n",
      "Fit took: 11.815 seconds\n",
      "Predict took: 292.918 seconds\n",
      "Round 7 took: 332.446 seconds\n",
      "302 65 65 432 436\n",
      "Fit took: 11.847 seconds\n",
      "Predict took: 329.510 seconds\n",
      "Round 8 took: 368.647 seconds\n",
      "303 65 64 432 436\n",
      "Fit took: 11.937 seconds\n",
      "Predict took: 340.734 seconds\n",
      "Round 9 took: 380.985 seconds\n",
      "Total time: 3452.598 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../EnsembleDiversityTests/\")\n",
    "import combinations\n",
    "import copy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,precision_recall_fscore_support, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pan.features import Metaclassifier\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "#pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe2 = Pipeline([('soa',soa), ('svm', svm)])\n",
    "\n",
    "### AGE ###\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='hard')\n",
    "#models = [pipe,pipe1,pipe2,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting', 'votingh']\n",
    "\n",
    "# Base Models\n",
    "base_models = [pipe, pipe1, pipe2]\n",
    "base_model_names = ['3grams', 'soac', 'lsi']\n",
    "\n",
    "# Meta Voting Models\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), ('2', pipe2)], voting='soft')\n",
    "eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), ('2', pipe2)], voting='hard')\n",
    "voting_dic = {'votingf':eclf, 'votingh':eclfh}\n",
    "combinator_names = ['majority', 'weights', 'accuracy', 'optimal']\n",
    "#meta_models_names = ['votingf', 'votingh', 'space3', 'meta'] + combinator_names\n",
    "meta_models_names = ['space3'] #+ combinator_names\n",
    "## all_models ##\n",
    "all_models_names = base_model_names + meta_models_names\n",
    "\n",
    "\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='hard')\n",
    "#models = [pipe,pipe1,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'voting', 'votingh']\n",
    "\n",
    "results = {'over':[]}\n",
    "for name in all_models_names:\n",
    "    results[name] = {'pred': [], 'conf': [], 'rep': [], 'acc': []}\n",
    "\n",
    "num_folds = 4\n",
    "train_split = 0.3\n",
    "meta_split = 0.5\n",
    "cv_rounds = 10\n",
    "t0 = time.time()\n",
    "t1 = t0\n",
    "for j in xrange(cv_rounds):\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=train_split, stratify=y)\n",
    "    for i, x in enumerate(X_train):\n",
    "        if len(x)==0:\n",
    "            X_train.remove(x)\n",
    "            y_train.remove(y_train[i])\n",
    "    for i, x in enumerate(X_cv):\n",
    "        if len(x)==0:\n",
    "            X_cv.remove(x)\n",
    "            y_cv.remove(y_cv[i])\n",
    "    if meta_split > 0:\n",
    "        X_meta, X_cv, y_meta, y_cv = train_test_split(X_cv, y_cv, test_size=meta_split, stratify=y_cv)\n",
    "        print len(X_train), len(X_cv), len(X_meta), len(X_cv) + len(X_train) + len(X_meta), len(X)\n",
    "    else:\n",
    "        print len(X_train), len(X_cv), len(X_cv) + len(X_train) , len(X)\n",
    "    trained_base_models = []\n",
    "    predictions = []\n",
    "    base_predictions_cv = []\n",
    "    base_predictions_meta = []\n",
    "    for i, model in enumerate(base_models):\n",
    "        model.fit(X_train,y_train)\n",
    "        trained_base_models.append(model)\n",
    "        predict = model.predict(X_cv)\n",
    "        predictions.append(predict)\n",
    "        base_predictions_cv.append(predict)\n",
    "        #base_predictions_meta.append(model.predict(X_meta))\n",
    "        results[base_model_names[i]]['pred'].append(predict)\n",
    "        results[base_model_names[i]]['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results[base_model_names[i]]['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        results[base_model_names[i]]['rep'].append(classification_report(y_cv, predict, labels=list(set(y))))\n",
    "    trained_all_models = copy.deepcopy(trained_base_models)\n",
    "    for name in meta_models_names:\n",
    "        #print name\n",
    "        if name =='votingf' or name=='votingh':\n",
    "            model = voting_dic[name]\n",
    "            model.fit(X_train, y_train)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'space':\n",
    "            models_for_space = {}\n",
    "            cv_scores = []\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                models_for_space[base_model_names[i]] = base_trained_model\n",
    "                cv_scores.append(base_trained_model.score(X_meta, y_meta))\n",
    "            model = combinations.SubSpaceEnsemble4_2(models_for_space, cv_scores, k=6, weights=[0.65,0.35,0.32,6], N_rand=10, rand_split=0.6)\n",
    "            model.fit(X_meta, y_meta)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'space3':\n",
    "            models_for_space = {}\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                models_for_space[base_model_names[i]] = base_trained_model\n",
    "            model = SubSpaceEnsemble3(models_for_space, k=5, weights= [2,1,3,0.6])\n",
    "            model.fit(X_train, y_train)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'meta':\n",
    "            model_dic = {}\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                model_dic[base_model_names[i]] = base_trained_model\n",
    "            model = Metaclassifier(models=model_dic, C=1.0, weights='balanced')\n",
    "            model.fit(X_meta, y_meta)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name in combinator_names:\n",
    "            #print 'mpike'\n",
    "            model = combinations.Combinator(scheme=name, weights= [1/float(len(base_predictions_meta)) for i in xrange(len(base_predictions_meta))])\n",
    "            model.fit(base_predictions_meta, y_meta)\n",
    "            predict = model.predict(base_predictions_cv)\n",
    "        trained_all_models.append(model)\n",
    "        predictions.append(predict)\n",
    "        results[name]['pred'].append(predict)\n",
    "        results[name]['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results[name]['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        results[name]['rep'].append(classification_report(y_cv, predict, labels=list(set(y))))\n",
    "    print('Round %d took: %0.3f seconds') % (j, time.time()-t1)\n",
    "    t1 = time.time()\n",
    "print('Total time: %0.3f seconds') % (time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[11,  6,  4,  0,  0],\n",
       "        [ 5, 17,  2,  2,  1],\n",
       "        [ 2,  5,  4,  1,  0],\n",
       "        [ 0,  2,  0,  2,  0],\n",
       "        [ 0,  0,  1,  0,  0]]), array([[19,  1,  1,  0,  0],\n",
       "        [ 0, 27,  0,  0,  0],\n",
       "        [ 0,  1, 11,  0,  0],\n",
       "        [ 0,  0,  0,  4,  0],\n",
       "        [ 0,  0,  0,  0,  1]]), array([[11,  8,  1,  0,  1],\n",
       "        [ 3, 21,  2,  1,  0],\n",
       "        [ 0,  4,  5,  2,  1],\n",
       "        [ 1,  1,  0,  2,  0],\n",
       "        [ 0,  0,  0,  1,  0]]), array([[10,  8,  2,  1,  0],\n",
       "        [ 6, 16,  2,  3,  0],\n",
       "        [ 2,  6,  4,  0,  0],\n",
       "        [ 0,  1,  2,  1,  0],\n",
       "        [ 1,  0,  0,  0,  0]]), array([[12,  4,  2,  2,  1],\n",
       "        [ 1, 23,  2,  1,  0],\n",
       "        [ 1,  6,  5,  0,  0],\n",
       "        [ 0,  1,  2,  1,  0],\n",
       "        [ 0,  0,  1,  0,  0]]), array([[18,  3,  0,  0,  0],\n",
       "        [ 0, 28,  0,  0,  0],\n",
       "        [ 0,  4,  8,  0,  0],\n",
       "        [ 0,  0,  0,  4,  0],\n",
       "        [ 0,  0,  0,  0,  1]]), array([[19,  2,  0,  0,  0],\n",
       "        [ 1, 26,  0,  0,  0],\n",
       "        [ 0,  2, 10,  0,  0],\n",
       "        [ 0,  1,  0,  3,  0],\n",
       "        [ 0,  0,  0,  0,  1]]), array([[13,  4,  1,  3,  0],\n",
       "        [ 4, 22,  1,  0,  0],\n",
       "        [ 0,  4,  8,  0,  0],\n",
       "        [ 0,  2,  1,  1,  0],\n",
       "        [ 0,  0,  0,  0,  1]]), array([[19,  2,  0,  0,  0],\n",
       "        [ 0, 28,  0,  0,  0],\n",
       "        [ 0,  2, 10,  0,  0],\n",
       "        [ 0,  1,  0,  3,  0],\n",
       "        [ 0,  0,  0,  0,  1]]), array([[18,  2,  0,  1,  0],\n",
       "        [ 0, 28,  0,  0,  0],\n",
       "        [ 0,  2, 10,  0,  0],\n",
       "        [ 0,  0,  0,  4,  0],\n",
       "        [ 0,  0,  0,  1,  0]])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['space3']['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%  3grams  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.441563228438\n",
      "Precision : 0.358\n",
      "Recall : 0.443\n",
      "F1 : 0.366\n",
      "Confusion matrix :\n",
      " [[  7.2  13.3   0.4   0.    0. ]\n",
      " [  4.9  21.2   0.6   0.4   0. ]\n",
      " [  2.5   9.2   0.2   0.1   0. ]\n",
      " [  1.    2.8   0.1   0.1   0. ]\n",
      " [  0.2   0.8   0.    0.    0. ]]\n",
      "#################################\n",
      "%%%%%%%%%%%%%%%%  soac  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.36321532634\n",
      "Precision : 0.354\n",
      "Recall : 0.364\n",
      "F1 : 0.341\n",
      "Confusion matrix :\n",
      " [[  8.5   9.4   1.9   1.1   0. ]\n",
      " [  8.9  13.3   2.6   2.3   0. ]\n",
      " [  3.9   6.1   1.3   0.7   0. ]\n",
      " [  1.2   2.    0.3   0.5   0. ]\n",
      " [  0.3   0.4   0.2   0.1   0. ]]\n",
      "#################################\n",
      "%%%%%%%%%%%%%%%%  lsi  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.324606643357\n",
      "Precision : 0.122\n",
      "Recall : 0.327\n",
      "F1 : 0.176\n",
      "Confusion matrix :\n",
      " [[  4.1  12.6   0.    4.2   0. ]\n",
      " [  5.5  16.2   0.    5.4   0. ]\n",
      " [  2.4   7.2   0.    2.4   0. ]\n",
      " [  0.8   2.4   0.    0.8   0. ]\n",
      " [  0.2   0.6   0.    0.2   0. ]]\n",
      "#################################\n",
      "%%%%%%%%%%%%%%%%  space3  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.395335081585\n",
      "Precision : 0.338\n",
      "Recall : 0.395\n",
      "F1 : 0.338\n",
      "Confusion matrix :\n",
      " [[  8.   12.4   0.5   0.    0. ]\n",
      " [  8.6  17.4   0.8   0.3   0. ]\n",
      " [  3.    8.7   0.3   0.    0. ]\n",
      " [  1.6   2.3   0.1   0.    0. ]\n",
      " [  0.4   0.6   0.    0.    0. ]]\n",
      "#################################\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for name in all_models_names:\n",
    "    print '%%%%%%%%%%%%%%%%  ' + name  + '  % %%%%%%%%%%%%%%%%%%%%%%%'\n",
    "    print '#################################'\n",
    "    mean_acc = 0\n",
    "    mean_prec = 0\n",
    "    mean_rec = 0\n",
    "    mean_f1 = 0\n",
    "    conf = numpy.zeros([5,5])\n",
    "    for i in xrange(cv_rounds):\n",
    "        mean_acc += results[name]['acc'][i]\n",
    "        #print results[key]['report'][i].split('     ')\n",
    "        mean_prec += float(results[name]['rep'][i].split('     ')[-4][2:])\n",
    "        mean_rec += float(results[name]['rep'][i].split('     ')[-3][2:])\n",
    "        mean_f1 += float(results[name]['rep'][i].split('     ')[-2][2:])\n",
    "        conf += results[name]['conf'][i]\n",
    "    mean_acc = mean_acc/float(cv_rounds)\n",
    "    mean_prec = mean_prec/float(cv_rounds)\n",
    "    mean_rec = mean_rec/float(cv_rounds)\n",
    "    mean_f1 = mean_f1/float(cv_rounds)\n",
    "    conf = conf/float(cv_rounds)\n",
    "    print('Accuracy : {}'.format(mean_acc))\n",
    "    print('Precision : {}'.format(mean_prec))\n",
    "    print('Recall : {}'.format(mean_rec))\n",
    "    print('F1 : {}'.format(mean_f1))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))\n",
    "    print '#################################'\n",
    "print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(y_meta)):\n",
    "    print \"True Label: %s\" % y_meta[i]\n",
    "    prediction_string = ''\n",
    "    for name, model in zip(base_model_names, pred_cv):\n",
    "        prediction_string += ' %s:%s |' % (name, g.lab.inverse_transform(g.transformation(model).argmax(axis=1))[0])\n",
    "    prediction_string += ' %s:%s' % ('Bernoulli', predict[i])\n",
    "    print prediction_string[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.292307692308\n",
      "Confusion matrix :\n",
      " [[ 0  0  3  1  0]\n",
      " [ 0  0 20  1  0]\n",
      " [ 0  7 18  1  1]\n",
      " [ 0  4  7  1  0]\n",
      " [ 0  0  0  1  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.00      0.00      0.00        21\n",
      "      35-49       0.38      0.67      0.48        27\n",
      "      50-64       0.20      0.08      0.12        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.19      0.29      0.22        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = combinations.Combinator(scheme='majority')\n",
    "g.fit(base_predictions_meta, y_meta)\n",
    "pred_meta = g.lab.transform(base_predictions_meta)\n",
    "pred_meta = g.ohe.transform(pred_meta.reshape(-1, 1)).todense().reshape(len(base_predictions_meta[0]), -1)\n",
    "pred_cv = g.lab.transform(base_predictions_cv)\n",
    "pred_cv = g.ohe.transform(pred_cv.reshape(-1, 1)).todense().reshape(len(base_predictions_cv[0]), -1)\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "gg =MultinomialNB()\n",
    "gg.fit(pred_meta, y_meta)\n",
    "gg.predict(pred_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "l = [[base0,base1,base2]for base0,base1,base2 in zip(base_predictions_meta[0],base_predictions_meta[1],base_predictions_meta[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 65)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_predictions_meta[0]), len(y_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pan.features import tokenization2\n",
    "\n",
    "class Freq(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Find the frequency of votes corresponding to specific classes.\n",
    "        It does not learn anything new. Just counting on the evaluation\n",
    "        dataset.\n",
    "        \n",
    "        Args:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "        from sklearn.naive_bayes import BernoulliNB\n",
    "        \n",
    "        self.rule_book = None\n",
    "        self.rule_index = {}\n",
    "        self.transformed = None\n",
    "        self.labels = None\n",
    "        self.num_models = None\n",
    "        self.num_labels = None\n",
    "        self.lab = LabelEncoder()\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.Bernoulli = BernoulliNB()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Expects a list of string inputs as X and a list of lists containing\n",
    "           the prediciton of each model for y\"\"\"\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        X_tr, y_tr = self.fit_encoders(X, y)\n",
    "        self.transformed = X_tr\n",
    "        tmp = numpy.zeros([1, self.num_labels])\n",
    "        j = 0\n",
    "        self.rule_book = numpy.copy(tmp)\n",
    "        for i, x in enumerate(X_tr):\n",
    "            x = str(x)\n",
    "            #print x\n",
    "            #print self.rule_book\n",
    "            if x in self.rule_index.keys():\n",
    "                #print y_tr[i].argmax(axis=1)\n",
    "                #print self.rule_book[self.rule_index[x], y_tr.argmax(axis=1)].shape\n",
    "                self.rule_book[self.rule_index[x], y_tr[i].argmax(axis=1)] += 1\n",
    "                #print self.rule_book[self.rule_index[x], :]\n",
    "            else:\n",
    "                self.rule_index[x] = j\n",
    "                self.rule_book = numpy.vstack((self.rule_book, tmp))\n",
    "                #self.rule_book = numpy.delete(self.rule_book, 0, 0)\n",
    "                self.rule_book[self.rule_index[x], y_tr[i].argmax(axis=1)] += 1\n",
    "                j += 1\n",
    "        self.num_rules = len(list(self.rule_index.keys()))\n",
    "        self.rule_book = numpy.delete(self.rule_book, self.rule_book.shape[0]-1, 0)\n",
    "#         print \"Fitted\"\n",
    "#         import pprint\n",
    "#         pprint.pprint(self.rule_index)\n",
    "#         print self.rule_book\n",
    "        # print X_tr\n",
    "        self.Bernoulli.fit(X_tr, y)\n",
    "        return\n",
    "            \n",
    "        \n",
    "        \n",
    "    def fit_encoders(self, X, y):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        self.num_labels = len(set(y))\n",
    "        self.labels = sorted(list(set(y)))\n",
    "        N_samples = len(y)\n",
    "        if type(X) is numpy.array:\n",
    "            y = y.reshape(-1, 1)\n",
    "        else:\n",
    "            y = numpy.array(y).reshape(-1, 1)\n",
    "        y = self.lab.fit_transform(y).reshape(-1, 1)\n",
    "        y = self.ohe.fit_transform(y).todense()\n",
    "        X = self.lab.transform(X)\n",
    "        X = self.ohe.transform(X.T.reshape(-1, 1)).todense().reshape(N_samples, -1)\n",
    "        self.num_models = int(X.shape[1] / self.num_labels)\n",
    "        return X, y\n",
    "    \n",
    "    def transformation(self, X, y):\n",
    "        \n",
    "        import random\n",
    "        #from sklearn.\n",
    "        predictions = []\n",
    "        print len(X), len(y)\n",
    "        for i, x in enumerate(X):\n",
    "            x1 = str(x)\n",
    "            if x1 in self.rule_index.keys():\n",
    "#                 print \"True\"\n",
    "#                 print y[i]\n",
    "                #print self.rule_book[self.rule_index[x],:]\n",
    "                #print self.rule_book[self.rule_index[x],:].argmax(axis=0)\n",
    "                predictions.append(self.labels[self.rule_book[self.rule_index[x1],:].argmax(axis=0)])\n",
    "#                 print \"Predicted\"\n",
    "#                 print self.rule_book[self.rule_index[x1],:]\n",
    "#                 print predictions[-1]\n",
    "            else:\n",
    "                predictions.append(random.choice(self.labels))\n",
    "                scores = []\n",
    "                for x_ in self.transformed:\n",
    "                    pass\n",
    "                #print [x]\n",
    "                #print type(x)\n",
    "                    # print [x[0]]\n",
    "        predictions = []\n",
    "        #for x in X:\n",
    "        #    predictions.append(self.Bernoulli.predict([x]))\n",
    "        predictions = self.Bernoulli.predict(X)    \n",
    "        #predictions.append(self.Bernoulli.predict([]))\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        if type(X[0]) is numpy.array:\n",
    "            N_samples = X[0].shape[0]\n",
    "        else:\n",
    "            N_samples = len(X[0])\n",
    "        X = self.lab.transform(X)\n",
    "        X = self.ohe.transform(X.reshape(-1, 1)).todense().reshape(N_samples, -1)\n",
    "        #print len(X), len(y)\n",
    "        prediction = self.transformation(X, y)\n",
    "        #prediction = self.lab.inverse_transform(prediction.argmax(axis=1))\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        return self.transform(X, y)\n",
    "\n",
    "    def score(self, X, y_true):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y_true, y_pred, normalize=True)\n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66\n",
      "Accuracy : 0.257575757576\n",
      "Confusion matrix :\n",
      " [[ 0  2  0  2  0]\n",
      " [ 5  9  2  3  2]\n",
      " [11  9  4  4  0]\n",
      " [ 3  4  1  4  0]\n",
      " [ 1  0  0  0  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.38      0.43      0.40        21\n",
      "      35-49       0.57      0.14      0.23        28\n",
      "      50-64       0.31      0.33      0.32        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.42      0.26      0.28        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = Freq()\n",
    "a.fit(base_predictions_meta, y_meta)\n",
    "predict = a.predict(base_predictions_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble3(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme.\"\"\"\n",
    "\n",
    "    def __init__(self, models, k=3, weights= [2,1,3,0.7]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\ ')\n",
    "        else:\n",
    "            self.models = models\n",
    "            # self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.weights = weights\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            count = 0\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            #print 'Sample ' + y_real[i]\n",
    "            #print dist\n",
    "            #print type(dist)\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            #pass\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  dist, X[i]))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, dist, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "#         print 'True'\n",
    "#         print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[2]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[1]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "#                 print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "#                 print 'Predictions'\n",
    "#                 print model_pred\n",
    "#                 print 'Representations'\n",
    "#                 print model_neig_pred\n",
    "#                 print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for i, n in enumerate(neigbors_true) for j in xrange(int(weights['true']*(self.k-i)))])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "#         print data\n",
    "#         best_model_ind = acc.index(max(acc))\n",
    "#         print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "p1 = models_for_space['3grams'].predict(X_meta)\n",
    "df1 = pandas.DataFrame(numpy.hstack((p1.reshape(-1,1), numpy.array(y_cv).reshape(-1,1))), columns=['3grams', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 1,  2,  5,  9, 14, 15, 21, 22, 23, 26, 29, 31, 33, 35, 39, 40, 45,\n",
       "            47, 49, 51, 53, 58, 60, 61, 63, 64],\n",
       "           dtype='int64', name=[u'lala0', u'lala1', u'lala2', u'lala3', u'lala4', u'lala5', u'lala6', u'lala7', u'lala8', u'lala9', u'lala10', u'lala11', u'lala12', u'lala13', u'lala14', u'lala15', u'lala16', u'lala17', u'lala18', u'lala19', u'lala20', u'lala21', u'lala22', u'lala23', u'lala24', u'lala25'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df1[df1['3grams']==df1['True']]\n",
    "#print g\n",
    "g[g['True'] == '35-49'].shape[0]\n",
    "g.index.rename(['lala' + str(i) for i in xrange(g.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit took: 18.552 seconds\n",
      "Predict took: 78.486 seconds\n",
      "Accuracy : 0.6\n",
      "Confusion matrix :\n",
      " [[ 1  1  0  2  0]\n",
      " [ 2 11  4  3  0]\n",
      " [ 0  4 22  2  0]\n",
      " [ 0  0  7  5  0]\n",
      " [ 0  1  0  0  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.33      0.25      0.29         4\n",
      "      25-34       0.65      0.55      0.59        20\n",
      "      35-49       0.67      0.79      0.72        28\n",
      "      50-64       0.42      0.42      0.42        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.58      0.60      0.59        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "space2 = SubSpaceEnsemble3(models_for_space, k=3, weights= [6,3,2,0.7])\n",
    "#2,1,3,0.7\n",
    "space2.fit(X, y)\n",
    "predict = space2.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3grams\n",
      "0.363636363636\n",
      "soac\n",
      "0.333333333333\n",
      "lsi\n",
      "0.318181818182\n",
      "votingf\n",
      "0.393939393939\n",
      "votingh\n",
      "0.333333333333\n",
      "space3\n",
      "0.878787878788\n",
      "meta\n",
      "0.242424242424\n",
      "majority\n",
      "0.424242424242\n",
      "weights\n",
      "0.424242424242\n",
      "accuracy\n",
      "0.424242424242\n",
      "optimal\n",
      "0.409090909091\n"
     ]
    }
   ],
   "source": [
    "for name in all_models_names:\n",
    "    print name\n",
    "    print results[name]['acc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble3_w(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme. Finding Optimal weights also!\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=3, scheme = 'weights', weights=[6,3,2,0.7]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.scheme = scheme\n",
    "            self.weights = None\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "            if self.scheme == 'weights':\n",
    "                if type(self.weights) in (numpy.array, numpy.ndarray):\n",
    "                    pass  # It is from the optimization part\n",
    "                else:\n",
    "                    if not(self.weights):\n",
    "                        print \"Need weights for this scheme!\"\n",
    "                self.weights = weights\n",
    "                weights_string = \" %.2f |\" * len(self.weights) % tuple(self.weights)\n",
    "                # print \"Using given weights: | %s\" % weights_string\n",
    "            elif self.scheme == 'optimal':\n",
    "                # print \"Will find the weights after fitting\"\n",
    "                pass\n",
    "            else:\n",
    "                self.weights = [6,3,2,0.7]\n",
    "        \n",
    "\n",
    "    def fit(self, X, X_cv, y = None, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X + X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X + X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X + X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y + y_true\n",
    "            count = 0\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            if self.scheme=='optimal':\n",
    "                self.find_weights(X, X_cv, y, y_cv)\n",
    "                weights_string = \" %.2f |\" * len(self.weights) % tuple(self.weights)\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            return self\n",
    "        \n",
    "    def find_weights(self, X, X_cv, y_cv, y):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        from scipy.optimize import minimize\n",
    "\n",
    "        w = [6,3,2,0.7]\n",
    "        bnds = tuple([(0, None) for i in xrange(len(w))])\n",
    "        a = minimize(self.f, w, args=(SubSpaceEnsemble3_w, X, X_cv, y, y_cv), method='L-BFGS-B', bounds=bnds)\n",
    "        self.weights = list(a.x)\n",
    "        return\n",
    "\n",
    "    def f(self, w, SubSpaceEnsemble3_w, X, X_cv, y, y_cv):\n",
    "        gg = SubSpaceEnsemble3_w(self.models, self.cv_scores, self.k, scheme= 'weights', weights= w)\n",
    "        gg.fit(X, X_cv, y, y_cv)\n",
    "        score = 1 - gg.score(x, y)\n",
    "        # print 'Weights'\n",
    "        # print w\n",
    "        # print 'Score: ' + str(score)\n",
    "        return score\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            # print 'Sample ' + y_real[i]\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  X[i]))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "#         print 'True'\n",
    "#         print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[2]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[1]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "#                 print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "#                 print 'Predictions'\n",
    "#                 print model_pred\n",
    "#                 print 'Representations'\n",
    "#                 print model_neig_pred\n",
    "#                 print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for j in xrange(int(weights['true'])) for n in neigbors_true])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "#         print data\n",
    "#         best_model_ind = acc.index(max(acc))\n",
    "#         print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need weights for this scheme!\n",
      "Fit took: 121.750 seconds\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4f97eee18fac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspace_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_for_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'optimal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspace_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, X_cv, y, y_true, weights)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;31m#print self.experts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'optimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[0mweights_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" %.2f |\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fit took: %0.3f seconds'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mfind_weights\u001b[1;34m(self, X, X_cv, y_cv, y)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mbnds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'L-BFGS-B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 447\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, w, SubSpaceEnsemble3_w, X, X_cv, y, y_cv)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;31m# print 'Weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# print w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;31m#return self.svc.score(self.transform_to_y(X), y, sample_weight)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# print \"PRedict\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# print X.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mX_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m#print type((X_transformed)[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m#print X_transformed.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/coo.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space_k = SubSpaceEnsemble3_w(models_for_space, cv_scores, k=3, scheme='optimal', weights=[2,1,3,0.5])\n",
    "space_k.fit(X,X_meta, y,y_meta)\n",
    "predict = space_k.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import EnsembleDiversityTests\n",
    "reload(EnsembleDiversityTests)\n",
    "from EnsembleDiversityTests import DiversityTests, BaseClassifiers\n",
    "#gg = DiversityTests(predictions[:-1], print_names[:-1], predictions[-1])\n",
    "gg = DiversityTests(base_predictions_cv, base_model_names, y_cv)\n",
    "#gg.print_report()\n",
    "gg1 = BaseClassifiers(base_predictions_cv, base_model_names, y_cv, True)\n",
    "#gg1.get_comparison_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Accuracy of the models!\n",
      "        18-24      25-34      35-49      50-64  65-xx\n",
      "3grams      0  47.619048  74.074074   0.000000      0\n",
      "soac        0  52.380952  40.740741  16.666667      0\n",
      "lsi       100   0.000000   0.000000   0.000000      0\n"
     ]
    }
   ],
   "source": [
    "gg1.get_per_class_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
