{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAN16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "Learning to judge gender..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from pan import preprocess\n",
    "\n",
    "task = 'gender'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)\n",
    "print len(X)\n",
    "X = preprocess.preprocess(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "X, y = dataset.get_data('age')\n",
    "#X, y = dataset.get_data('gender')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3grams',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[2, 2], norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('svm', SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from pan.features import SOA_Model2\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[2,2], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "svm = SVC(kernel='rbf', C=10, gamma=1, class_weight='balanced', probability=False)\n",
    "pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "        tokenizer_var='sklearn')),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=False)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])+\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pan.features import LSI_Model\n",
    "LSImodel = LSI_Model(num_topics=100)\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=False)\n",
    "#pipe2 = Pipeline([('counts',combined), ('svm', svm)])\n",
    "pipe2 = Pipeline([('LSI',LSImodel), ('svm', svm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    temp = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            temp[i,j] = len([m for l, m in enumerate(predictions[i]) if (m==predictions[j][l] and m==predictions[N-1][l])])/float(len(predictions[0]))\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (names[i],  names[j], 100*res[i,j], 100*temp[i,j])\n",
    "    return  [res, temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(combinations)\n",
    "combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 65 64 432 436\n",
      "Round 0 took: 29.586 seconds\n",
      "Total time: 29.586 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../EnsembleDiversityTests/\")\n",
    "import combinations\n",
    "import copy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,precision_recall_fscore_support, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pan.features import Metaclassifier\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "#pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe2 = Pipeline([('soa',soa), ('svm', svm)])\n",
    "\n",
    "### AGE ###\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='hard')\n",
    "#models = [pipe,pipe1,pipe2,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting', 'votingh']\n",
    "\n",
    "# Base Models\n",
    "base_models = [pipe, pipe1, pipe2]\n",
    "base_model_names = ['3grams', 'soac', 'lsi']\n",
    "\n",
    "# Meta Voting Models\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), ('2', pipe2)], voting='soft')\n",
    "eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), ('2', pipe2)], voting='hard')\n",
    "voting_dic = {'votingf':eclf, 'votingh':eclfh}\n",
    "combinator_names = ['majority', 'weights', 'accuracy', 'optimal']\n",
    "#meta_models_names = ['votingf', 'votingh', 'space3', 'meta'] + combinator_names\n",
    "#meta_models_names = ['space3'] + combinator_names\n",
    "meta_models_names = []\n",
    "## all_models ##\n",
    "all_models_names = base_model_names + meta_models_names\n",
    "\n",
    "\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='hard')\n",
    "#models = [pipe,pipe1,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'voting', 'votingh']\n",
    "\n",
    "results = {'over':[]}\n",
    "for name in all_models_names:\n",
    "    results[name] = {'pred': [], 'conf': [], 'rep': [], 'acc': []}\n",
    "\n",
    "num_folds = 4\n",
    "train_split = 0.3\n",
    "meta_split = 0.5\n",
    "cv_rounds = 1\n",
    "t0 = time.time()\n",
    "t1 = t0\n",
    "for j in xrange(cv_rounds):\n",
    "    X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=train_split, stratify=y)\n",
    "    for i, x in enumerate(X_train):\n",
    "        if len(x)==0:\n",
    "            X_train.remove(x)\n",
    "            y_train.remove(y_train[i])\n",
    "    for i, x in enumerate(X_cv):\n",
    "        if len(x)==0:\n",
    "            X_cv.remove(x)\n",
    "            y_cv.remove(y_cv[i])\n",
    "    if meta_split > 0:\n",
    "        X_meta, X_cv, y_meta, y_cv = train_test_split(X_cv, y_cv, test_size=meta_split, stratify=y_cv)\n",
    "        print len(X_train), len(X_cv), len(X_meta), len(X_cv) + len(X_train) + len(X_meta), len(X)\n",
    "    else:\n",
    "        print len(X_train), len(X_cv), len(X_cv) + len(X_train) , len(X)\n",
    "    trained_base_models = []\n",
    "    predictions = []\n",
    "    base_predictions_cv = []\n",
    "    base_predictions_meta = []\n",
    "    for i, model in enumerate(base_models):\n",
    "        model.fit(X_train,y_train)\n",
    "        trained_base_models.append(model)\n",
    "        predict = model.predict(X_cv)\n",
    "        predictions.append(predict)\n",
    "        base_predictions_cv.append(predict)\n",
    "        base_predictions_meta.append(model.predict(X_meta))\n",
    "        results[base_model_names[i]]['pred'].append(predict)\n",
    "        results[base_model_names[i]]['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results[base_model_names[i]]['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        results[base_model_names[i]]['rep'].append(classification_report(y_cv, predict, labels=list(set(y))))\n",
    "    trained_all_models = copy.deepcopy(trained_base_models)\n",
    "    for name in meta_models_names:\n",
    "        #print name\n",
    "        if name =='votingf' or name=='votingh':\n",
    "            model = voting_dic[name]\n",
    "            model.fit(X_train, y_train)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'space':\n",
    "            models_for_space = {}\n",
    "            cv_scores = []\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                models_for_space[base_model_names[i]] = base_trained_model\n",
    "                cv_scores.append(base_trained_model.score(X_meta, y_meta))\n",
    "            model = combinations.SubSpaceEnsemble4_2(models_for_space, cv_scores, k=6, weights=[0.65,0.35,0.32,6], N_rand=10, rand_split=0.6)\n",
    "            model.fit(X_meta, y_meta)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'space3':\n",
    "            models_for_space = {}\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                models_for_space[base_model_names[i]] = base_trained_model\n",
    "            model = SubSpaceEnsemble3(models_for_space, k=5, weights= [2,1,3,0.6])\n",
    "            model.fit(X_train, y_train)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name == 'meta':\n",
    "            model_dic = {}\n",
    "            for i, base_trained_model in enumerate(trained_base_models):\n",
    "                model_dic[base_model_names[i]] = base_trained_model\n",
    "            model = Metaclassifier(models=model_dic, C=1.0, weights='balanced')\n",
    "            model.fit(X_meta, y_meta)\n",
    "            predict = model.predict(X_cv)\n",
    "        if name in combinator_names:\n",
    "            #print 'mpike'\n",
    "            model = combinations.Combinator(scheme=name, weights= [1/float(len(base_predictions_meta)) for i in xrange(len(base_predictions_meta))])\n",
    "            model.fit(base_predictions_meta, y_meta)\n",
    "            predict = model.predict(base_predictions_cv)\n",
    "        trained_all_models.append(model)\n",
    "        predictions.append(predict)\n",
    "        results[name]['pred'].append(predict)\n",
    "        results[name]['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results[name]['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        results[name]['rep'].append(classification_report(y_cv, predict, labels=list(set(y))))\n",
    "    print('Round %d took: %0.3f seconds') % (j, time.time()-t1)\n",
    "    t1 = time.time()\n",
    "print('Total time: %0.3f seconds') % (time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4, 16,  1,  0,  0],\n",
       "        [ 4, 21,  2,  0,  0],\n",
       "        [ 1, 11,  0,  0,  0],\n",
       "        [ 0,  4,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[10, 11,  0,  0,  0],\n",
       "        [ 8, 18,  1,  0,  0],\n",
       "        [ 6,  6,  0,  0,  0],\n",
       "        [ 3,  1,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[ 8, 13,  0,  0,  0],\n",
       "        [ 6, 19,  2,  0,  0],\n",
       "        [ 2, 10,  0,  0,  0],\n",
       "        [ 0,  2,  2,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[ 8, 13,  0,  0,  0],\n",
       "        [ 7, 19,  2,  0,  0],\n",
       "        [ 3,  8,  1,  0,  0],\n",
       "        [ 1,  3,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[12,  9,  0,  0,  0],\n",
       "        [11, 14,  2,  0,  0],\n",
       "        [ 6,  6,  0,  0,  0],\n",
       "        [ 1,  3,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[ 9, 11,  1,  0,  0],\n",
       "        [ 6, 18,  3,  0,  0],\n",
       "        [ 3,  9,  0,  0,  0],\n",
       "        [ 0,  4,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0]]), array([[ 5, 16,  0,  0,  0],\n",
       "        [ 7, 21,  0,  0,  0],\n",
       "        [ 2, 10,  0,  0,  0],\n",
       "        [ 0,  3,  1,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0]]), array([[ 9, 12,  0,  0,  0],\n",
       "        [ 4, 23,  0,  0,  0],\n",
       "        [ 7,  5,  0,  0,  0],\n",
       "        [ 1,  3,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[ 8, 13,  0,  0,  0],\n",
       "        [ 6, 21,  0,  0,  0],\n",
       "        [ 5,  7,  0,  0,  0],\n",
       "        [ 1,  3,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]]), array([[ 9, 11,  0,  1,  0],\n",
       "        [13, 14,  0,  0,  0],\n",
       "        [ 4,  6,  2,  0,  0],\n",
       "        [ 1,  3,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  0]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['space3']['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%  3grams  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.4\n",
      "Precision : 0.28\n",
      "Recall : 0.4\n",
      "F1 : 0.29\n",
      "Confusion matrix :\n",
      " [[  3.  18.   0.   0.   0.]\n",
      " [  4.  23.   0.   0.   0.]\n",
      " [  0.  12.   0.   0.   0.]\n",
      " [  2.   2.   0.   0.   0.]\n",
      " [  0.   1.   0.   0.   0.]]\n",
      "#################################\n",
      "%%%%%%%%%%%%%%%%  soac  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.369230769231\n",
      "Precision : 0.34\n",
      "Recall : 0.37\n",
      "F1 : 0.34\n",
      "Confusion matrix :\n",
      " [[  4.  17.   0.   0.   0.]\n",
      " [  7.  15.   5.   0.   0.]\n",
      " [  2.   5.   5.   0.   0.]\n",
      " [  0.   3.   1.   0.   0.]\n",
      " [  0.   1.   0.   0.   0.]]\n",
      "#################################\n",
      "%%%%%%%%%%%%%%%%  lsi  % %%%%%%%%%%%%%%%%%%%%%%%\n",
      "#################################\n",
      "Accuracy : 0.415384615385\n",
      "Precision : 0.17\n",
      "Recall : 0.42\n",
      "F1 : 0.24\n",
      "Confusion matrix :\n",
      " [[  0.  21.   0.   0.   0.]\n",
      " [  0.  27.   0.   0.   0.]\n",
      " [  0.  12.   0.   0.   0.]\n",
      " [  0.   4.   0.   0.   0.]\n",
      " [  0.   1.   0.   0.   0.]]\n",
      "#################################\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for name in all_models_names:\n",
    "    print '%%%%%%%%%%%%%%%%  ' + name  + '  % %%%%%%%%%%%%%%%%%%%%%%%'\n",
    "    print '#################################'\n",
    "    mean_acc = 0\n",
    "    mean_prec = 0\n",
    "    mean_rec = 0\n",
    "    mean_f1 = 0\n",
    "    conf = numpy.zeros([5,5])\n",
    "    for i in xrange(cv_rounds):\n",
    "        mean_acc += results[name]['acc'][i]\n",
    "        #print results[key]['report'][i].split('     ')\n",
    "        mean_prec += float(results[name]['rep'][i].split('     ')[-4][2:])\n",
    "        mean_rec += float(results[name]['rep'][i].split('     ')[-3][2:])\n",
    "        mean_f1 += float(results[name]['rep'][i].split('     ')[-2][2:])\n",
    "        conf += results[name]['conf'][i]\n",
    "    mean_acc = mean_acc/float(cv_rounds)\n",
    "    mean_prec = mean_prec/float(cv_rounds)\n",
    "    mean_rec = mean_rec/float(cv_rounds)\n",
    "    mean_f1 = mean_f1/float(cv_rounds)\n",
    "    conf = conf/float(cv_rounds)\n",
    "    print('Accuracy : {}'.format(mean_acc))\n",
    "    print('Precision : {}'.format(mean_prec))\n",
    "    print('Recall : {}'.format(mean_rec))\n",
    "    print('F1 : {}'.format(mean_f1))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))\n",
    "    print '#################################'\n",
    "print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 102406)\n",
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511627906977\n",
      "{'n_neighbors': 15, 'weights': 'uniform'}\n",
      "(65, 102406)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [65 66]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-411d8051c4d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[1;32m--> 176\u001b[1;33m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [65 66]"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "counter.set_params(**parameters)\n",
    "X_train_truth = counter.fit_transform(X_train)\n",
    "print X_train_truth.shape\n",
    "num_folds = 5\n",
    "params = {'n_neighbors':[i for i in xrange(1,20)], 'weights':['uniform', 'distance']}\n",
    "gg = GridSearchCV(KNeighborsClassifier(), param_grid=params, n_jobs=-1, cv=num_folds, refit=True, verbose=1)\n",
    "gg.fit(X_train_truth, y_train)\n",
    "print(gg.best_score_)\n",
    "print(gg.best_params_)\n",
    "predict = gg.best_estimator_.predict(counter.transform(X_meta))\n",
    "print counter.transform(X_meta).shape\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n",
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights Found:\n",
      "[22, 20, 28, 23, 25, 28, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transform() takes exactly 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c95b5c83fe96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeigbors_Combinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels_tr11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-c95b5c83fe96>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transform() takes exactly 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Neigbors_Combinator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"GIving untrained Models and their transformers create a combinator of information:\n",
    "       - Based on the count vectorizer predictions of a kNN classifier (fitted in X_train).\n",
    "       - Based on the transformed kNN classifiers predictions (fitted in X_train)\n",
    "       - Based on the samples predictions of the now trained models (fitted in X_train)\n",
    "       - Combining the above predictions using weights (fitted in X_meta)\n",
    "       \n",
    "       Args:\n",
    "           - models: dic of trained models in the form of: {\"name\": Model, :\"name2\":Model2...}\n",
    "           - models_tr: dic of transformers of the models. Form like models.\\\n",
    "           - names: list of names for the models to be used\n",
    "           - knn_params: dictionary containing params for fitting the knn classifiers.\n",
    "                         Expects a dictionary like: {\"general\":{\"num_folds\":5, \"n_jobs\":-1},\n",
    "                                                     \"name\":  parameter_grid_for_grid_search1,\n",
    "                                                     \"name2\": parameter_grid_for_grid_search2,...}\n",
    "            - scheme: for wegithing \"\"\"\n",
    "    \n",
    "    def __init__(self, models, models_tr, names, knn_params, scheme='majority', weights=None):\n",
    "        \n",
    "        from combinations import Combinator\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        self.counter = CountVectorizer()\n",
    "        self.models = models\n",
    "        self.models_tr = models_tr\n",
    "        self.names = names\n",
    "        self.knn_params = knn_params\n",
    "        self.scheme = scheme\n",
    "        self.weights = weights\n",
    "        self.ind2names = {}\n",
    "        for i, name in enumerate(names):\n",
    "            self.ind2names[i] = name\n",
    "        self.counter = CountVectorizer()\n",
    "        self.gt_knn = None\n",
    "        self.tr_knn = {}\n",
    "        self.comb = Combinator(scheme=self.scheme)\n",
    "            \n",
    "        \n",
    "\n",
    "    def fit(self, X_train, X_meta, y_train, y_meta, weights=None):\n",
    "        \n",
    "        from sklearn.grid_search import GridSearchCV\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "        import random, time\n",
    "        #print len(y_train), len(y_meta)\n",
    "        if (y_train is None)  or (y_meta is None):\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            \n",
    "            # Fit the Meta-Classifier\n",
    "            predictions_meta = []\n",
    "            # Fitting the ground truth neighbors\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            X_train_truth = self.counter.fit_transform(X_train)\n",
    "            #print X_train_truth.toarray().shape\n",
    "            grid_ = GridSearchCV(KNeighborsClassifier(), param_grid=self.knn_params['true'],\n",
    "                                    n_jobs=self.knn_params['general']['n_jobs'], \n",
    "                                     cv=self.knn_params['general']['cv'], refit=True, \n",
    "                                      verbose=self.knn_params['general']['verbose'])\n",
    "            grid_.fit(X_train_truth, y_train)\n",
    "            self.gt_knn = grid_.best_estimator_\n",
    "            # Add the gt predictions\n",
    "            #print self.counter.transform(X_meta).toarray().shape\n",
    "            predictions_meta.append(self.gt_knn.predict(self.counter.transform(X_meta)))\n",
    "            # Fit the transformation Classifiers\n",
    "            for name in self.names:\n",
    "                X_train_tr = self.models_tr[name].transform(X_train)\n",
    "                grid_ = GridSearchCV(KNeighborsClassifier(), param_grid=self.knn_params[name],\n",
    "                                    n_jobs=self.knn_params['general']['n_jobs'], \n",
    "                                     cv=self.knn_params['general']['cv'], refit=True, \n",
    "                                      verbose=self.knn_params['general']['verbose'])\n",
    "                grid_.fit(X_train_tr, y_train)\n",
    "                self.tr_knn[name] = grid_.best_estimator_\n",
    "                # Add the transformed knn predictions\n",
    "                predictions_meta.append(self.tr_knn[name].predict(self.models_tr[name].transform(X_meta)))\n",
    "                # Add the per sample predictions\n",
    "                predictions_meta.append(self.models[name].predict(X_meta))\n",
    "            #print len(predictions_meta)\n",
    "            #print predictions_meta\n",
    "            self.comb.fit(predictions_meta, y_meta)\n",
    "            print \"Best Weights Found:\"\n",
    "            print self.comb.weights\n",
    "            return\n",
    "        \n",
    "        \n",
    "    def transform(self, X, y):\n",
    "\n",
    "        import numpy\n",
    "        \n",
    "        predictions = []\n",
    "        X_truth = self.counter.transform(X)   \n",
    "        predictions.append(self.gt_knn.predict(X_truth))\n",
    "        for name in self.names:\n",
    "            #print name\n",
    "            # Add the transformed knn predictions\n",
    "            predictions.append(self.tr_knn[name].predict(self.models_tr[name].transform(X)))\n",
    "            # Add the per sample predictions\n",
    "            predictions.append(self.models[name].predict(X))\n",
    "            #print len(predictions)\n",
    "        #print len(predictions)\n",
    "        #for pred in predictions:\n",
    "        #    print len(pred)\n",
    "        final_predict =self.comb.predict(predictions)\n",
    "        names = ['Ground_Truth', '3grams-Neighbors', '3grams-Pred',\n",
    "                     'SOAC-Neigbors', 'SOAC-Pred', 'LSI-Neighbors', 'LSI-Pred', 'Comb']\n",
    "        for i in xrange(len(y)):\n",
    "            print 'True: ' + str(y[i])\n",
    "            for  j, pred in enumerate(predictions):\n",
    "                print '%s: %s' % (names[j], pred[i])\n",
    "            print \"Comb: %s\" % final_predict[i]\n",
    "            print '*'*100\n",
    "        return final_predict\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def score(self, X, y_true):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y_true, y_pred, normalize=True)\n",
    "\n",
    "models11 = {}\n",
    "models_tr11 = {}\n",
    "tr_params = {'n_neighbors':[i for i in xrange(1,20)], 'weights':['uniform', 'distance']}\n",
    "knn_params = {\"general\":{\"n_jobs\":-1, \"cv\":5, \"verbose\":1}}\n",
    "knn_params['true'] = tr_params\n",
    "names11 = []\n",
    "for i, model in enumerate(trained_base_models):\n",
    "    names11.append(base_model_names[i])\n",
    "    models11[names11[-1]] = model\n",
    "    models_tr11[names11[-1]] = trained_base_models[i].steps[0][1]\n",
    "    knn_params[names11[-1]] = tr_params\n",
    "    #print base_model_names[i]\n",
    "    #print trained_base_models[i].steps[0][1]\n",
    "aa = Neigbors_Combinator(models11, models_tr11, names11, knn_params, scheme='accuracy')            \n",
    "aa.fit(X_train, X_meta, y_train, y_meta)\n",
    "predict = aa.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa.transform(X_cv,y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(y_meta)):\n",
    "    print \"True Label: %s\" % y_meta[i]\n",
    "    prediction_string = ''\n",
    "    for name, model in zip(base_model_names, pred_cv):\n",
    "        prediction_string += ' %s:%s |' % (name, g.lab.inverse_transform(g.transformation(model).argmax(axis=1))[0])\n",
    "    prediction_string += ' %s:%s' % ('Bernoulli', predict[i])\n",
    "    print prediction_string[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.292307692308\n",
      "Confusion matrix :\n",
      " [[ 0  0  3  1  0]\n",
      " [ 0  0 20  1  0]\n",
      " [ 0  7 18  1  1]\n",
      " [ 0  4  7  1  0]\n",
      " [ 0  0  0  1  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.00      0.00      0.00        21\n",
      "      35-49       0.38      0.67      0.48        27\n",
      "      50-64       0.20      0.08      0.12        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.19      0.29      0.22        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = combinations.Combinator(scheme='majority')\n",
    "g.fit(base_predictions_meta, y_meta)\n",
    "pred_meta = g.lab.transform(base_predictions_meta)\n",
    "pred_meta = g.ohe.transform(pred_meta.reshape(-1, 1)).todense().reshape(len(base_predictions_meta[0]), -1)\n",
    "pred_cv = g.lab.transform(base_predictions_cv)\n",
    "pred_cv = g.ohe.transform(pred_cv.reshape(-1, 1)).todense().reshape(len(base_predictions_cv[0]), -1)\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "gg =MultinomialNB()\n",
    "gg.fit(pred_meta, y_meta)\n",
    "gg.predict(pred_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "l = [[base0,base1,base2]for base0,base1,base2 in zip(base_predictions_meta[0],base_predictions_meta[1],base_predictions_meta[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 65)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_predictions_meta[0]), len(y_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble3(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme.\"\"\"\n",
    "\n",
    "    def __init__(self, models, k=3, weights= [2,1,3,0.7]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\ ')\n",
    "        else:\n",
    "            self.models = models\n",
    "            # self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.weights = weights\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            count = 0\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            return self\n",
    "\n",
    "    def predict(self, X, y_real):\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            print 'Sample ' + y_real[i]\n",
    "            #print dist\n",
    "            #print type(dist)\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            #pass\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  dist, X[i]))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, dist, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "        print 'True'\n",
    "        print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[2]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_neig_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[1]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "                print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_neig_pred, normalize=True))\n",
    "                print 'Predictions'\n",
    "                print model_pred\n",
    "                print 'Representations'\n",
    "                print model_neig_pred\n",
    "                print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for i, n in enumerate(neigbors_true) for j in xrange(int(weights['true']*(self.k-i)))])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "        print data\n",
    "        best_model_ind = acc.index(max(acc))\n",
    "        print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        print '='*50\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "p1 = models_for_space['3grams'].predict(X_meta)\n",
    "df1 = pandas.DataFrame(numpy.hstack((p1.reshape(-1,1), numpy.array(y_cv).reshape(-1,1))), columns=['3grams', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 1,  2,  5,  9, 14, 15, 21, 22, 23, 26, 29, 31, 33, 35, 39, 40, 45,\n",
       "            47, 49, 51, 53, 58, 60, 61, 63, 64],\n",
       "           dtype='int64', name=[u'lala0', u'lala1', u'lala2', u'lala3', u'lala4', u'lala5', u'lala6', u'lala7', u'lala8', u'lala9', u'lala10', u'lala11', u'lala12', u'lala13', u'lala14', u'lala15', u'lala16', u'lala17', u'lala18', u'lala19', u'lala20', u'lala21', u'lala22', u'lala23', u'lala24', u'lala25'])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS PER MODEL~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "============================ Model: 3grams ==================================+\n",
      "Accuracy : 0.4375\n",
      "Confusion matrix :\n",
      " [[ 0  0  4  0  0]\n",
      " [ 0  7 13  0  0]\n",
      " [ 0  7 20  0  0]\n",
      " [ 0  0 11  1  0]\n",
      " [ 0  0  0  1  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.50      0.35      0.41        20\n",
      "      35-49       0.42      0.74      0.53        27\n",
      "      50-64       0.50      0.08      0.14        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.43      0.44      0.38        64\n",
      "\n",
      "============================================================================\n",
      "============================ Model: soac ==================================+\n",
      "Accuracy : 0.390625\n",
      "Confusion matrix :\n",
      " [[ 0  0  3  1  0]\n",
      " [ 0  4  8  8  0]\n",
      " [ 1  5 18  3  0]\n",
      " [ 1  1  7  3  0]\n",
      " [ 0  0  0  1  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.40      0.20      0.27        20\n",
      "      35-49       0.50      0.67      0.57        27\n",
      "      50-64       0.19      0.25      0.21        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.37      0.39      0.36        64\n",
      "\n",
      "============================================================================\n",
      "============================ Model: lsi ==================================+\n",
      "Accuracy : 0.421875\n",
      "Confusion matrix :\n",
      " [[ 0  0  4  0  0]\n",
      " [ 0  0 20  0  0]\n",
      " [ 0  0 27  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 0  0  1  0  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       0.00      0.00      0.00        20\n",
      "      35-49       0.42      1.00      0.59        27\n",
      "      50-64       0.00      0.00      0.00        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.18      0.42      0.25        64\n",
      "\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "import EnsembleDiversityTests\n",
    "reload(EnsembleDiversityTests)\n",
    "a = EnsembleDiversityTests.BaseClassifiers(base_predictions_meta, base_model_names, y_meta)\n",
    "a.get_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit took: 12.390 seconds\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['50-64', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['50-64', '18-24', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 125, '50-64': 39, '25-34': 5, '18-24': 5})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '35-49', '25-34']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '25-34']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '25-34']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 150, '25-34': 42})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['25-34', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 143, '50-64': 31, '25-34': 18})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '18-24']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 88, '25-34': 38, '50-64': 10, '18-24': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['25-34', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['50-64', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 88, '50-64': 34, '25-34': 22})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['50-64', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['50-64', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 116, '50-64': 20, '25-34': 20})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['18-24', '50-64', '25-34']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '25-34']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['18-24', '50-64', '25-34']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 62, '25-34': 24, '18-24': 12, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['25-34', '25-34', '18-24']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '25-34', '18-24']\n",
      "Representations\n",
      "['50-64', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '25-34', '18-24']\n",
      "Representations\n",
      "['35-49', '18-24', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 51, '25-34': 18, '18-24': 11, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 253, '50-64': 18, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['50-64', '18-24', '18-24']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['50-64', '18-24', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['50-64', '18-24', '18-24']\n",
      "Representations\n",
      "['35-49', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 56, '18-24': 14, '25-34': 10, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '18-24', '18-24']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '18-24', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '18-24', '18-24']\n",
      "Representations\n",
      "['35-49', '25-34', '18-24']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 57, '18-24': 26, '25-34': 25})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 268, '25-34': 20})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 133, '25-34': 31, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['18-24', '50-64', '25-34']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '25-34']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['18-24', '50-64', '25-34']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 62, '25-34': 24, '18-24': 12, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 118, '25-34': 14, '50-64': 12})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '50-64', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '50-64', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '50-64', '50-64']\n",
      "Representations\n",
      "['25-34', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 111, '50-64': 64, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['18-24', '50-64', '18-24']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '18-24']\n",
      "Representations\n",
      "['50-64', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 61, '18-24': 16, '50-64': 13})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '50-64', '25-34']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '50-64', '25-34']\n",
      "Representations\n",
      "['50-64', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '50-64', '25-34']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 87, '50-64': 26, '25-34': 13})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '25-34', '50-64']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '25-34', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '25-34', '50-64']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 57, '25-34': 43, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['50-64', '18-24', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '18-24', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['50-64', '18-24', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 91, '25-34': 13, '50-64': 12, '18-24': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3462, '25-34': 34})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 18-24\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3462, '50-64': 17, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['50-64', '35-49', '18-24']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '35-49', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '35-49', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 112, '50-64': 14, '18-24': 10, '25-34': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['25-34', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 166, '25-34': 74})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '18-24', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '18-24', '50-64']\n",
      "Representations\n",
      "['25-34', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '18-24', '50-64']\n",
      "Representations\n",
      "['25-34', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 74, '25-34': 20, '18-24': 8, '50-64': 6})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['18-24', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['18-24', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '18-24', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 196, '18-24': 21, '25-34': 5})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '50-64']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '50-64']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 166, '25-34': 16, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 162, '50-64': 16, '25-34': 14})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 18-24\n",
      "True\n",
      "['35-49', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 216, '50-64': 16, '25-34': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['18-24', '18-24', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '18-24', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '18-24', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 75, '18-24': 18, '25-34': 15})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '18-24', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '18-24', '35-49']\n",
      "Representations\n",
      "['50-64', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '18-24', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 81, '25-34': 25, '18-24': 10, '50-64': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 266, '25-34': 22})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['50-64', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '25-34', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 110, '25-34': 20, '50-64': 14})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3462, '50-64': 17, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 104, '50-64': 26, '25-34': 14})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '35-49', '50-64']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '50-64']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 143, '25-34': 35, '50-64': 14})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 156, '25-34': 28, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 65-xx\n",
      "True\n",
      "['18-24', '18-24', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['18-24', '18-24', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['18-24', '18-24', '35-49']\n",
      "Representations\n",
      "['18-24', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 102, '18-24': 34, '25-34': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 9912})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 18-24\n",
      "True\n",
      "['25-34', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 94, '25-34': 17, '50-64': 15})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '35-49', '25-34']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '25-34']\n",
      "Representations\n",
      "['35-49', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '25-34']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 184, '25-34': 56})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['18-24', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['18-24', '25-34', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 91, '25-34': 23, '18-24': 12})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['18-24', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 6640, '18-24': 8, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['25-34', '25-34', '25-34']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['25-34', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 1.0\n",
      "Predictions\n",
      "['25-34', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'25-34': 5412, '35-49': 1226})\n",
      "Total pred: 25-34\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['50-64', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 1.0\n",
      "Predictions\n",
      "['50-64', '25-34', '35-49']\n",
      "Representations\n",
      "['50-64', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 1574, '50-64': 918, '25-34': 908})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 232, '25-34': 56})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['18-24', '50-64', '18-24']\n",
      "Model: lsi Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '18-24']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['18-24', '50-64', '18-24']\n",
      "Representations\n",
      "['35-49', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 56, '18-24': 16, '25-34': 10, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '18-24', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 146, '25-34': 22, '50-64': 16, '18-24': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '25-34', '25-34']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 87, '25-34': 39})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['50-64', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['50-64', '50-64', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['50-64', '50-64', '35-49']\n",
      "Representations\n",
      "['25-34', '25-34', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 81, '50-64': 27, '25-34': 18})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['50-64', '35-49', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3415, '25-34': 17, '50-64': 16})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 2582, '25-34': 914})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 18-24\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 6687, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['25-34', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 162, '25-34': 22, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3398, '25-34': 27, '50-64': 5})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3415, '25-34': 25, '50-64': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '25-34', '25-34']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '25-34']\n",
      "Representations\n",
      "['25-34', '25-34', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'25-34': 97, '35-49': 95})\n",
      "Total pred: 25-34\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['50-64', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '18-24', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3415, '50-64': 17, '18-24': 8, '25-34': 8})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 6687, '25-34': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '18-24', '25-34']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '18-24', '25-34']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '18-24', '25-34']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 168, '25-34': 52, '18-24': 20})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '35-49', '35-49']\n",
      "Model: lsi Accuracy: 1.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['25-34', '50-64', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 3351, '25-34': 18, '50-64': 13})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 50-64\n",
      "True\n",
      "['35-49', '25-34', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '25-34', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '25-34', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 182, '25-34': 41, '50-64': 17})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['35-49', '25-34', '18-24']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '25-34', '18-24']\n",
      "Representations\n",
      "['35-49', '25-34', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '25-34', '18-24']\n",
      "Representations\n",
      "['25-34', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 126, '25-34': 36, '18-24': 12})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 25-34\n",
      "True\n",
      "['35-49', '50-64', '35-49']\n",
      "Model: lsi Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.0\n",
      "Predictions\n",
      "['35-49', '50-64', '35-49']\n",
      "Representations\n",
      "['25-34', '35-49', '25-34']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 198, '50-64': 14, '25-34': 10})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Sample 35-49\n",
      "True\n",
      "['25-34', '35-49', '18-24']\n",
      "Model: lsi Accuracy: 0.333333333333\n",
      "Predictions\n",
      "['35-49', '35-49', '35-49']\n",
      "Representations\n",
      "['35-49', '35-49', '35-49']\n",
      "Sample prediction: 35-49\n",
      "Model: soac Accuracy: 0.0\n",
      "Predictions\n",
      "['25-34', '35-49', '18-24']\n",
      "Representations\n",
      "['50-64', '50-64', '50-64']\n",
      "Sample prediction: 35-49\n",
      "Model: 3grams Accuracy: 0.666666666667\n",
      "Predictions\n",
      "['25-34', '35-49', '18-24']\n",
      "Representations\n",
      "['25-34', '25-34', '18-24']\n",
      "Sample prediction: 35-49\n",
      "Counter({'35-49': 80, '25-34': 50, '18-24': 29, '50-64': 15})\n",
      "Total pred: 35-49\n",
      "==================================================\n",
      "Predict took: 702.672 seconds\n",
      "Accuracy : 0.446153846154\n",
      "Confusion matrix :\n",
      " [[ 0  0  4  0  0]\n",
      " [ 0  2 19  0  0]\n",
      " [ 0  0 27  0  0]\n",
      " [ 0  0 12  0  0]\n",
      " [ 0  0  1  0  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.00      0.00      0.00         4\n",
      "      25-34       1.00      0.10      0.17        21\n",
      "      35-49       0.43      1.00      0.60        27\n",
      "      50-64       0.00      0.00      0.00        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.50      0.45      0.31        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_for_space = {}\n",
    "for i, base_trained_model in enumerate(trained_base_models):\n",
    "    models_for_space[base_model_names[i]] = base_trained_model\n",
    "space2 = SubSpaceEnsemble3(models_for_space, k=3, weights= [6,3,2,-1])\n",
    "#2,1,3,0.7\n",
    "space2.fit(X_train, y_train)\n",
    "predict = space2.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3grams\n",
      "0.363636363636\n",
      "soac\n",
      "0.333333333333\n",
      "lsi\n",
      "0.318181818182\n",
      "votingf\n",
      "0.393939393939\n",
      "votingh\n",
      "0.333333333333\n",
      "space3\n",
      "0.878787878788\n",
      "meta\n",
      "0.242424242424\n",
      "majority\n",
      "0.424242424242\n",
      "weights\n",
      "0.424242424242\n",
      "accuracy\n",
      "0.424242424242\n",
      "optimal\n",
      "0.409090909091\n"
     ]
    }
   ],
   "source": [
    "for name in all_models_names:\n",
    "    print name\n",
    "    print results[name]['acc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble3_w(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme. Finding Optimal weights also!\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=3, scheme = 'weights', weights=[6,3,2,0.7]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.scheme = scheme\n",
    "            self.weights = None\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "            if self.scheme == 'weights':\n",
    "                if type(self.weights) in (numpy.array, numpy.ndarray):\n",
    "                    pass  # It is from the optimization part\n",
    "                else:\n",
    "                    if not(self.weights):\n",
    "                        print \"Need weights for this scheme!\"\n",
    "                self.weights = weights\n",
    "                weights_string = \" %.2f |\" * len(self.weights) % tuple(self.weights)\n",
    "                # print \"Using given weights: | %s\" % weights_string\n",
    "            elif self.scheme == 'optimal':\n",
    "                # print \"Will find the weights after fitting\"\n",
    "                pass\n",
    "            else:\n",
    "                self.weights = [6,3,2,0.7]\n",
    "        \n",
    "\n",
    "    def fit(self, X, X_cv, y = None, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X + X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X + X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X + X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y + y_true\n",
    "            count = 0\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            if self.scheme=='optimal':\n",
    "                self.find_weights(X, X_cv, y, y_cv)\n",
    "                weights_string = \" %.2f |\" * len(self.weights) % tuple(self.weights)\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            return self\n",
    "        \n",
    "    def find_weights(self, X, X_cv, y, y_cv):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        from scipy.optimize import minimize\n",
    "\n",
    "        w = [6,3,2,0.7]\n",
    "        bnds = tuple([(0, None) for i in xrange(len(w))])\n",
    "        a = minimize(self.f, w, args=(SubSpaceEnsemble3_w, X, X_cv, y, y_cv), method='L-BFGS-B', bounds=bnds)\n",
    "        self.weights = list(a.x)\n",
    "        return\n",
    "    \n",
    "    def find_weigths2(self, X, X_cv, y):\n",
    "        \n",
    "        N_rand = 100\n",
    "        N_rand1 = 50\n",
    "        poss_w = []\n",
    "        acc_ = []\n",
    "        pred = []\n",
    "        for i in xrange(N_rand1):\n",
    "            tmp_w = [2,1,3,6]\n",
    "            tmp_w[0] = round(random.random(), 3)\n",
    "            tmp_w[1] = round(1 - tmp_w[0], 3)\n",
    "            tmp_w[2] = round(random.uniform(0.2, 0.8), 3)\n",
    "            # tmp_w[3] = random.randint(1,10)\n",
    "            poss_w.append(tmp_w)\n",
    "            pred = self.find_weights(X_cv, tmp_w)\n",
    "            acc = accuracy_score(self.true, pred)\n",
    "            # print('Accuracy : {}'.format(acc))\n",
    "            acc_.append(acc)\n",
    "        print('First search took: %0.3f seconds') % (time.time() - t0)\n",
    "        tmp_w = poss_w[acc_.index(max(acc_))]\n",
    "        poss_w = []\n",
    "        acc_ = []\n",
    "        for i in xrange(self.N_rand  -N_rand1):\n",
    "            tmp_w2 = tmp_w\n",
    "            tmp_w2[0] = round(random.uniform(tmp_w[0] - 0.1, tmp_w[0] + 0.1), 3)\n",
    "            tmp_w2[1] = round(1 - tmp_w2[0], 3)\n",
    "            tmp_w2[2] = round(random.uniform(tmp_w[2] - 0.1, tmp_w[1] + 0.1), 3)\n",
    "            poss_w.append(tmp_w2)\n",
    "            pred = self.find_weights(X_cv, tmp_w2)\n",
    "            acc = accuracy_score(self.true, pred)\n",
    "            # print('Accuracy : {}'.format(acc))\n",
    "            acc_.append(acc)\n",
    "        self.weights = poss_w[acc_.index(max(acc_))]\n",
    "        self.k = self.weights[3]\n",
    "\n",
    "    def f(self, w, SubSpaceEnsemble3_w, X, X_cv, y, y_cv):\n",
    "        gg = SubSpaceEnsemble3_w(self.models, self.cv_scores, self.k, scheme= 'weights', weights= w)\n",
    "        gg.fit(X, X_cv, y, y_cv)\n",
    "        score = 1 - gg.score(x, y)\n",
    "        # print 'Weights'\n",
    "        # print w\n",
    "        # print 'Score: ' + str(score)\n",
    "        return score\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            # print 'Sample ' + y_real[i]\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  X[i]))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "#         print 'True'\n",
    "#         print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[2]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[1]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "#                 print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "#                 print 'Predictions'\n",
    "#                 print model_pred\n",
    "#                 print 'Representations'\n",
    "#                 print model_neig_pred\n",
    "#                 print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for j in xrange(int(weights['true'])) for n in neigbors_true])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "#         print data\n",
    "#         best_model_ind = acc.index(max(acc))\n",
    "#         print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need weights for this scheme!\n",
      "Fit took: 121.750 seconds\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4f97eee18fac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspace_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_for_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'optimal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspace_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, X_cv, y, y_true, weights)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;31m#print self.experts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'optimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[0mweights_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" %.2f |\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fit took: %0.3f seconds'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mfind_weights\u001b[1;34m(self, X, X_cv, y_cv, y)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mbnds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'L-BFGS-B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 447\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, w, SubSpaceEnsemble3_w, X, X_cv, y, y_cv)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubSpaceEnsemble3_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;31m# print 'Weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# print w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;31m#return self.svc.score(self.transform_to_y(X), y, sample_weight)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2b3510c291bb>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# print \"PRedict\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# print X.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mX_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m#print type((X_transformed)[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m#print X_transformed.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/coo.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space_k = SubSpaceEnsemble3_w(models_for_space, cv_scores, k=3, scheme='optimal', weights=[2,1,3,0.5])\n",
    "space_k.fit(X,X_meta, y,y_meta)\n",
    "predict = space_k.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import EnsembleDiversityTests\n",
    "reload(EnsembleDiversityTests)\n",
    "from EnsembleDiversityTests import DiversityTests, BaseClassifiers\n",
    "#gg = DiversityTests(predictions[:-1], print_names[:-1], predictions[-1])\n",
    "gg = DiversityTests(base_predictions_cv, base_model_names, y_cv)\n",
    "#gg.print_report()\n",
    "gg1 = BaseClassifiers(base_predictions_cv, base_model_names, y_cv, True)\n",
    "#gg1.get_comparison_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Class Accuracy of the models!\n",
      "        18-24      25-34      35-49      50-64  65-xx\n",
      "3grams      0  47.619048  74.074074   0.000000      0\n",
      "soac        0  52.380952  40.740741  16.666667      0\n",
      "lsi       100   0.000000   0.000000   0.000000      0\n"
     ]
    }
   ],
   "source": [
    "gg1.get_per_class_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xrange(1, 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 810 candidates, totalling 8100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-5507b7043464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mgrid_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#grid_ = GridSearchCV(tree1, param_grid = params, n_jobs= -1, cv=10, refit=True, verbose=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mgrid_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_meta_trees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_meta_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mtree1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#tree1.fit(numpy.array(X_meta_trees), y_meta_tr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tree1 = tree.DecisionTreeClassifier()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lab = LabelEncoder()\n",
    "y_meta_tr = lab.fit_transform(y_meta)\n",
    "X_meta_trees = []\n",
    "for i in xrange(len(y_meta)):\n",
    "    tmp = []\n",
    "    for j in xrange(len(base_predictions_meta)):\n",
    "        tmp.append(base_predictions_meta[j][i])\n",
    "    X_meta_trees.append(tmp)\n",
    "#\n",
    "X_meta_trees = numpy.array(X_meta_trees, dtype='|S5')\n",
    "\n",
    "\n",
    "X_meta_trees = lab.transform(X_meta_trees.reshape(-1,1)).reshape(len(y_meta), len(base_predictions_meta))\n",
    "#params = {'criterion': ['gini', 'entropy'], 'min_samples_split': list(xrange(1,10)), \n",
    "#          'max_depth': [None]+list(xrange(1,5)), 'min_samples_leaf': list(xrange(1,4)) }\n",
    "params = {'criterion': ['gini', 'entropy'], 'n_estimators': [100, 1000, 10000],\n",
    "          'min_samples_split': list(xrange(1,10)), 'max_depth': [None]+list(xrange(1,5)), \n",
    "          'min_samples_leaf': list(xrange(1,4)) }\n",
    "\n",
    "grid_ = GridSearchCV(RandomForestClassifier(), param_grid = params, n_jobs= -1, cv=10, refit=True, verbose=1)\n",
    "#grid_ = GridSearchCV(tree1, param_grid = params, n_jobs= -1, cv=10, refit=True, verbose=1)\n",
    "grid_.fit(numpy.array(X_meta_trees), y_meta_tr)\n",
    "tree1 = grid_.best_estimator_\n",
    "#tree1.fit(numpy.array(X_meta_trees), y_meta_tr)\n",
    "\n",
    "y_cv_tr = lab.transform(y_cv)\n",
    "X_cv_trees = []\n",
    "for i in xrange(len(y_cv)):\n",
    "    tmp = []\n",
    "    for j in xrange(len(base_predictions_cv)):\n",
    "        tmp.append(base_predictions_cv[j][i])\n",
    "    X_cv_trees.append(tmp)\n",
    "#\n",
    "X_cv_trees = numpy.array(X_cv_trees, dtype='|S5')\n",
    "\n",
    "X_cv_trees = lab.transform(X_cv_trees.reshape(-1,1)).reshape(len(y_cv), len(base_predictions_cv))\n",
    "predict = lab.inverse_transform(tree1.predict(X_cv_trees))\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pan.features import tokenization2\n",
    "\n",
    "class Freq(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Find the frequency of votes corresponding to specific classes.\n",
    "        It does not learn anything new. Just counting on the evaluation\n",
    "        dataset.\n",
    "        \n",
    "        Args:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "        from sklearn.naive_bayes import BernoulliNB\n",
    "        \n",
    "        self.rule_book = None\n",
    "        self.rule_index = {}\n",
    "        self.transformed = None\n",
    "        self.labels = None\n",
    "        self.num_models = None\n",
    "        self.num_labels = None\n",
    "        self.lab = LabelEncoder()\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.Bernoulli = BernoulliNB()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Expects a list of string inputs as X and a list of lists containing\n",
    "           the prediciton of each model for y\"\"\"\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        X_tr, y_tr = self.fit_encoders(X, y)\n",
    "        self.transformed = X_tr\n",
    "        tmp = numpy.zeros([1, self.num_labels])\n",
    "        j = 0\n",
    "        self.rule_book = numpy.copy(tmp)\n",
    "        for i, x in enumerate(X_tr):\n",
    "            x = str(x)\n",
    "            #print x\n",
    "            #print self.rule_book\n",
    "            if x in self.rule_index.keys():\n",
    "                #print y_tr[i].argmax(axis=1)\n",
    "                #print self.rule_book[self.rule_index[x], y_tr.argmax(axis=1)].shape\n",
    "                self.rule_book[self.rule_index[x], y_tr[i].argmax(axis=1)] += 1\n",
    "                #print self.rule_book[self.rule_index[x], :]\n",
    "            else:\n",
    "                self.rule_index[x] = j\n",
    "                self.rule_book = numpy.vstack((self.rule_book, tmp))\n",
    "                #self.rule_book = numpy.delete(self.rule_book, 0, 0)\n",
    "                self.rule_book[self.rule_index[x], y_tr[i].argmax(axis=1)] += 1\n",
    "                j += 1\n",
    "        self.num_rules = len(list(self.rule_index.keys()))\n",
    "        self.rule_book = numpy.delete(self.rule_book, self.rule_book.shape[0]-1, 0)\n",
    "#         print \"Fitted\"\n",
    "#         import pprint\n",
    "#         pprint.pprint(self.rule_index)\n",
    "#         print self.rule_book\n",
    "        # print X_tr\n",
    "        self.Bernoulli.fit(X_tr, y)\n",
    "        return\n",
    "            \n",
    "        \n",
    "        \n",
    "    def fit_encoders(self, X, y):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        self.num_labels = len(set(y))\n",
    "        self.labels = sorted(list(set(y)))\n",
    "        N_samples = len(y)\n",
    "        if type(X) is numpy.array:\n",
    "            y = y.reshape(-1, 1)\n",
    "        else:\n",
    "            y = numpy.array(y).reshape(-1, 1)\n",
    "        y = self.lab.fit_transform(y).reshape(-1, 1)\n",
    "        y = self.ohe.fit_transform(y).todense()\n",
    "        X = self.lab.transform(X)\n",
    "        X = self.ohe.transform(X.T.reshape(-1, 1)).todense().reshape(N_samples, -1)\n",
    "        self.num_models = int(X.shape[1] / self.num_labels)\n",
    "        return X, y\n",
    "    \n",
    "    def transformation(self, X):\n",
    "        \n",
    "        import random\n",
    "        #from sklearn.\n",
    "        predictions = []\n",
    "        #print len(X), len(y)\n",
    "        for i, x in enumerate(X):\n",
    "            x1 = str(x)\n",
    "            if x1 in self.rule_index.keys():\n",
    "#                 print \"True\"\n",
    "#                 print y[i]\n",
    "                #print self.rule_book[self.rule_index[x],:]\n",
    "                #print self.rule_book[self.rule_index[x],:].argmax(axis=0)\n",
    "                predictions.append(self.labels[self.rule_book[self.rule_index[x1],:].argmax(axis=0)])\n",
    "#                 print \"Predicted\"\n",
    "#                 print self.rule_book[self.rule_index[x1],:]\n",
    "#                 print predictions[-1]\n",
    "            else:\n",
    "                print \"Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\n",
    "                predictions.append(random.choice(self.labels))\n",
    "                scores = []\n",
    "                for x_ in self.transformed:\n",
    "                    pass\n",
    "                #print [x]\n",
    "                #print type(x)\n",
    "                    # print [x[0]]\n",
    "        #predictions = []\n",
    "        #for x in X:\n",
    "        #    predictions.append(self.Bernoulli.predict([x]))\n",
    "        #predictions = self.Bernoulli.predict(X)    \n",
    "        #predictions.append(self.Bernoulli.predict([]))\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        import numpy\n",
    "\n",
    "        if type(X[0]) is numpy.array:\n",
    "            N_samples = X[0].shape[0]\n",
    "        else:\n",
    "            N_samples = len(X[0])\n",
    "        X = self.lab.transform(X)\n",
    "        X = self.ohe.transform(X.reshape(-1, 1)).todense().reshape(N_samples, -1)\n",
    "        #print len(X), len(y)\n",
    "        prediction = self.transformation(X)\n",
    "        #prediction = self.lab.inverse_transform(prediction.argmax(axis=1))\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def score(self, X, y_true):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y_true, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n",
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights Found:\n",
      "[22, 20, 28, 23, 25, 28, 27]\n",
      "None\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Random!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 18-24\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 18-24\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 25-34\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 65-xx\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 50-64\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 18-24\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 50-64\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 65-xx\n",
      "****************************************************************************************************\n",
      "True: 18-24\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 18-24\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 25-34\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 25-34\n",
      "SOAC-Pred: 25-34\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 50-64\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 25-34\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 50-64\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 35-49\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 25-34\n",
      "Ground_Truth: 35-49\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 35-49\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 35-49\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "True: 35-49\n",
      "Ground_Truth: 25-34\n",
      "3grams-Neighbors: 25-34\n",
      "3grams-Pred: 25-34\n",
      "SOAC-Neigbors: 35-49\n",
      "SOAC-Pred: 50-64\n",
      "LSI-Neighbors: 35-49\n",
      "LSI-Pred: 35-49\n",
      "Comb: 35-49\n",
      "Freq: 35-49\n",
      "****************************************************************************************************\n",
      "Accuracy : 0.292307692308\n",
      "Confusion matrix :\n",
      " [[ 1  1  0  1  1]\n",
      " [ 3  3 11  2  2]\n",
      " [ 6  2 14  3  2]\n",
      " [ 1  1  6  1  3]\n",
      " [ 0  0  1  0  0]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      18-24       0.09      0.25      0.13         4\n",
      "      25-34       0.43      0.14      0.21        21\n",
      "      35-49       0.44      0.52      0.47        27\n",
      "      50-64       0.14      0.08      0.11        12\n",
      "      65-xx       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.35      0.29      0.29        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Neigbors_Combinator2(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"GIving untrained Models and their transformers create a combinator of information:\n",
    "       - Based on the count vectorizer predictions of a kNN classifier (fitted in X_train).\n",
    "       - Based on the transformed kNN classifiers predictions (fitted in X_train)\n",
    "       - Based on the samples predictions of the now trained models (fitted in X_train)\n",
    "       - Combining the above predictions using weights (fitted in X_meta)\n",
    "       \n",
    "       Args:\n",
    "           - models: dic of trained models in the form of: {\"name\": Model, :\"name2\":Model2...}\n",
    "           - models_tr: dic of transformers of the models. Form like models.\\\n",
    "           - names: list of names for the models to be used\n",
    "           - knn_params: dictionary containing params for fitting the knn classifiers.\n",
    "                         Expects a dictionary like: {\"general\":{\"num_folds\":5, \"n_jobs\":-1},\n",
    "                                                     \"name\":  parameter_grid_for_grid_search1,\n",
    "                                                     \"name2\": parameter_grid_for_grid_search2,...}\n",
    "            - scheme: for wegithing \"\"\"\n",
    "    \n",
    "    def __init__(self, models, models_tr, names, knn_params, scheme='majority', weights=None):\n",
    "        \n",
    "        from combinations import Combinator\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        self.counter = CountVectorizer()\n",
    "        self.models = models\n",
    "        self.models_tr = models_tr\n",
    "        self.names = names\n",
    "        self.knn_params = knn_params\n",
    "        self.scheme = scheme\n",
    "        self.weights = weights\n",
    "        self.ind2names = {}\n",
    "        for i, name in enumerate(names):\n",
    "            self.ind2names[i] = name\n",
    "        self.counter = CountVectorizer()\n",
    "        self.gt_knn = None\n",
    "        self.tr_knn = {}\n",
    "        self.comb = Combinator(scheme=self.scheme)\n",
    "        self.freq = Freq()\n",
    "            \n",
    "        \n",
    "\n",
    "    def fit(self, X_train, X_meta, y_train, y_meta, weights=None):\n",
    "        \n",
    "        from sklearn.grid_search import GridSearchCV\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "        import random, time\n",
    "        #print len(y_train), len(y_meta)\n",
    "        if (y_train is None)  or (y_meta is None):\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            \n",
    "            # Fit the Meta-Classifier\n",
    "            predictions_meta = []\n",
    "            # Fitting the ground truth neighbors\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            X_train_truth = self.counter.fit_transform(X_train)\n",
    "            #print X_train_truth.toarray().shape\n",
    "            grid_ = GridSearchCV(KNeighborsClassifier(), param_grid=self.knn_params['true'],\n",
    "                                    n_jobs=self.knn_params['general']['n_jobs'], \n",
    "                                     cv=self.knn_params['general']['cv'], refit=True, \n",
    "                                      verbose=self.knn_params['general']['verbose'])\n",
    "            grid_.fit(X_train_truth, y_train)\n",
    "            self.gt_knn = grid_.best_estimator_\n",
    "            # Add the gt predictions\n",
    "            #print self.counter.transform(X_meta).toarray().shape\n",
    "            predictions_meta.append(self.gt_knn.predict(self.counter.transform(X_meta)))\n",
    "            # Fit the transformation Classifiers\n",
    "            for name in self.names:\n",
    "                X_train_tr = self.models_tr[name].transform(X_train)\n",
    "                grid_ = GridSearchCV(KNeighborsClassifier(), param_grid=self.knn_params[name],\n",
    "                                    n_jobs=self.knn_params['general']['n_jobs'], \n",
    "                                     cv=self.knn_params['general']['cv'], refit=True, \n",
    "                                      verbose=self.knn_params['general']['verbose'])\n",
    "                grid_.fit(X_train_tr, y_train)\n",
    "                self.tr_knn[name] = grid_.best_estimator_\n",
    "                # Add the transformed knn predictions\n",
    "                predictions_meta.append(self.tr_knn[name].predict(self.models_tr[name].transform(X_meta)))\n",
    "                # Add the per sample predictions\n",
    "                predictions_meta.append(self.models[name].predict(X_meta))\n",
    "            #print len(predictions_meta)\n",
    "            #print predictions_meta\n",
    "            self.comb.fit(predictions_meta, y_meta)\n",
    "            print \"Best Weights Found:\"\n",
    "            print self.comb.weights\n",
    "            print self.freq.fit(predictions_meta, y_meta)\n",
    "            return\n",
    "        \n",
    "        \n",
    "    def transform(self, X, y):\n",
    "\n",
    "        import numpy\n",
    "        \n",
    "        predictions = []\n",
    "        X_truth = self.counter.transform(X)   \n",
    "        predictions.append(self.gt_knn.predict(X_truth))\n",
    "        for name in self.names:\n",
    "            #print name\n",
    "            # Add the transformed knn predictions\n",
    "            predictions.append(self.tr_knn[name].predict(self.models_tr[name].transform(X)))\n",
    "            # Add the per sample predictions\n",
    "            predictions.append(self.models[name].predict(X))\n",
    "            #print len(predictions)\n",
    "        #print len(predictions)\n",
    "        #for pred in predictions:\n",
    "        #    print len(pred)\n",
    "        final_predict =self.comb.predict(predictions)\n",
    "        final_predict2 = self.freq.predict(predictions)\n",
    "        names = ['Ground_Truth', '3grams-Neighbors', '3grams-Pred',\n",
    "                     'SOAC-Neigbors', 'SOAC-Pred', 'LSI-Neighbors', 'LSI-Pred', 'Comb']\n",
    "        for i in xrange(len(y)):\n",
    "            print 'True: ' + str(y[i])\n",
    "            for  j, pred in enumerate(predictions):\n",
    "                print '%s: %s' % (names[j], pred[i])\n",
    "            print \"Comb: %s\" % final_predict[i]\n",
    "            print \"Freq: %s\" % final_predict2[i]\n",
    "            print '*'*100\n",
    "        return final_predict2\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        return self.transform(X, y)\n",
    "\n",
    "    def score(self, X, y_true):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y_true, y_pred, normalize=True)\n",
    "\n",
    "models11 = {}\n",
    "models_tr11 = {}\n",
    "tr_params = {'n_neighbors':[i for i in xrange(1,20)], 'weights':['uniform', 'distance']}\n",
    "knn_params = {\"general\":{\"n_jobs\":-1, \"cv\":5, \"verbose\":1}}\n",
    "knn_params['true'] = tr_params\n",
    "names11 = []\n",
    "for i, model in enumerate(trained_base_models):\n",
    "    names11.append(base_model_names[i])\n",
    "    models11[names11[-1]] = model\n",
    "    models_tr11[names11[-1]] = trained_base_models[i].steps[0][1]\n",
    "    knn_params[names11[-1]] = tr_params\n",
    "    #print base_model_names[i]\n",
    "    #print trained_base_models[i].steps[0][1]\n",
    "aa = Neigbors_Combinator2(models11, models_tr11, names11, knn_params, scheme='accuracy')            \n",
    "aa.fit(X_train, X_meta, y_train, y_meta)\n",
    "predict = aa.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
