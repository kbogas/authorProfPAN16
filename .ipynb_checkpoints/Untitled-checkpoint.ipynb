{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAN 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAN 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "Learning to judge gender..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "import pprint\n",
    "print \"Num of samples: \" + str(len(y))\n",
    "pprint.pprint(Counter(y))\n",
    "X, y = dataset.get_data('age')\n",
    "print len(X)\n",
    "\n",
    "X, X_cv, X, y_cv = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.5, random_state=42, stratify=y_cv)\n",
    "\n",
    "print len(X_cv), len(X_test), len(X) , len(X)+ len(X_cv) + len(X_test)\n",
    "pprint.pprint(Counter(y))\n",
    "pprint.pprint(Counter(y_cv))\n",
    "pprint.pprint(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277792\n"
     ]
    }
   ],
   "source": [
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from pan import preprocess\n",
    "\n",
    "task = 'gender'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "#X, y = dataset.get_data('age')\n",
    "X, y = dataset.get_data('gender')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams+soa+soac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Happy Moodle     Release Day \\xa0|\\xa0Moodle News via\\nWeb     Tools in Education  A Quick Guide\\nLAS TICs\\neFront Learning  Free eLearning books  via\\nTrying twitterberry\\ncachureando android apps para mi tablet\\n\\xa1Hackearon mi Facebook \\nHow Long Does it Take to Create Learning  via\\nInfographic    Reasons Teachers should use Diigo\\nInstructional Design for Beginners \\u2013 What Motivates People To Learn  | Upside Learning Blog |\\nMany things until now\\nBroken Co Worker | Interactive Scenario via\\nYouTube |\\nmy last summer days \\nI   m taking Computer Science     a free online class  Join me and sign up at \\nLearning by doing  Reflexiones marca MIT | El blog de \\xcd\\xf1igo Babot |\\nNamathis   videos educativos |\\npreparing my master   s final research project\\nEL CELULAR EN EL AULA  \\u201cUSTED ME LO VA A DEVOLVER\\u201d    EduGlobal |\\nAdd This \\nThe MOOC Guide |\\nCoursera |\\nExplore free courses from edX universities |\\nFree online courses from Duke University |\\nI just signed up for Think Again  How to Reason and Argue thinkagain   a free online class  Join me at\\nWeduboX Portal |\\nMake This Your New Years Resolution    The Fastest Way To Lose Body Fat in    Weeks\\nMake This Your New Years Resolution    The Fastest Way To Lose Body Fat in    Weeks\\nEn webinar Designing eLearning for iPads\\ntermin\\xf3   Things I Wish Someone Would Have Told Me About Elearning de John Araiza\\nFastest way to shed fat off your body in   weeks\\nFastest way to shed fat off your body in   weeks\\nBasic process of creating an online course | Brigham Communications | Thanks \\n  Great Tools to Create Educational Infographics ~ Teachers Tech Workshop |\\nThis is a book from the guy who created powtoon   must read\\nThe Power of Cartoon Marketing\\ne learning |\\nCommunity Manager\\nTwittmate   M\\xe1s all\\xe1 de Twitter \\nThe Facebook guide for teachers  How to use ir in your classroom \\nQu\\xe9 es el marketing relacional \\nWatch videos to improve work skills and Elance know how \\nPresentacion edulearning consultores on\\nOnline Marketing vs Marketing Tradicional  v\\xeda\\nOnline Marketing vs Marketing Tradicional  Subt\\xedtulos \\nSocialnomics Medios Sociales | Social Media Revolution Spanish |\\nSoluciones e learning |\\nEdulearning Consultores |\\nKeep an eye on the website  Something big and FREE is coming to EDU when the counter hits    \\n\\n Sure   Are you tired of  renting classrooms for your training courses   Have you thought about distance education \\n\\nEbooks gratis de social media\\nI liked a video Marca Personal\\n\\nMi perfil en about me  and sign up for your own at\\nQuiero ser un Community Manager  Infografia CommunityManager MarketingDigital\\nDescargar INFORME FUTURO DIGITAL LATINOAMERICA   COMSCORE \\nI   m getting a pack of Business Cards because I   ve got Klout   thanks to  MOOPerk\\nI   m following   Users who aren   t following me back  Found using\\n\\nI just found the online course  quot The Future Of Storytelling quot  on  Check it out  mooc\\nborrar  agregar archivos  via\\nufff   vina  live at\\nThe eLearning Guild     Tips on Graphics and Animations for eLearning   Publications Library\\nMe gust\\xf3 un video de Will it Blend  iPhone  s and  c\\n\\xbfC\\xf3mo ser un buen Community Manager   Excelentes tips \\n\\nExcelente herramienta para crear mapas mentales \\nSpiderScribe net  beta  is out \\nThink  tv   Videoteca via REDES DE APRENDIZAJE PERSONAL\\n  web     tools your students want you to use\\niPad for eLearning\\nTecnolog\\xeda educativa on\\neLearning Resources | Online Training Guides | Links   CommLab India  via\\neFront  Free Stock Photos Sites for e Learning\\nReading   quot   \\nHappy Moodle     Release Day \\xa0|\\xa0Moodle News via\\nWeb     Tools in Education  A Quick Guide\\nLAS TICs\\neFront Learning  Free eLearning books  via\\nTrying twitterberry\\ncachureando android apps para mi tablet\\n\\xa1Hackearon mi Facebook \\nHow Long Does it Take to Create Learning  via\\nInfographic    Reasons Teachers should use Diigo\\nInstructional Design for Beginners \\u2013 What Motivates People To Learn  | Upside Learning Blog |\\nMany things until now\\nBroken Co Worker | Interactive Scenario via\\nYouTube |\\nmy last summer days \\nI   m taking Computer Science     a free online class  Join me and sign up at \\nLearning by doing  Reflexiones marca MIT | El blog de \\xcd\\xf1igo Babot |\\nNamathis   videos educativos |\\npreparing my master   s final research project\\nEL CELULAR EN EL AULA  \\u201cUSTED ME LO VA A DEVOLVER\\u201d    EduGlobal |\\nAdd This \\nThe MOOC Guide |\\nCoursera |\\nExplore free courses from edX universities |\\nFree online courses from Duke University |\\nI just signed up for Think Again  How to Reason and Argue thinkagain   a free online class  Join me at\\nWeduboX Portal |\\nMake This Your New Years Resolution    The Fastest Way To Lose Body Fat in    Weeks\\nMake This Your New Years Resolution    The Fastest Way To Lose Body Fat in    Weeks\\nEn webinar Designing eLearning for iPads\\ntermin\\xf3   Things I Wish Someone Would Have Told Me About Elearning de John Araiza\\nFastest way to shed fat off your body in   weeks\\nFastest way to shed fat off your body in   weeks\\nBasic process of creating an online course | Brigham Communications | Thanks \\n  Great Tools to Create Educational Infographics ~ Teachers Tech Workshop |\\nThis is a book from the guy who created powtoon   must read\\nThe Power of Cartoon Marketing\\ne learning |\\nCommunity Manager\\nTwittmate   M\\xe1s all\\xe1 de Twitter \\nThe Facebook guide for teachers  How to use ir in your classroom \\nQu\\xe9 es el marketing relacional \\nWatch videos to improve work skills and Elance know how \\nPresentacion edulearning consultores on\\nOnline Marketing vs Marketing Tradicional  v\\xeda\\nOnline Marketing vs Marketing Tradicional  Subt\\xedtulos \\nSocialnomics Medios Sociales | Social Media Revolution Spanish |\\nSoluciones e learning |\\nEdulearning Consultores |\\nKeep an eye on the website  Something big and FREE is coming to EDU when the counter hits    \\n\\n Sure   Are you tired of  renting classrooms for your training courses   Have you thought about distance education \\n\\nEbooks gratis de social media\\nI liked a video Marca Personal\\n\\nMi perfil en about me  and sign up for your own at\\nQuiero ser un Community Manager  Infografia CommunityManager MarketingDigital\\nDescargar INFORME FUTURO DIGITAL LATINOAMERICA   COMSCORE \\nI   m getting a pack of Business Cards because I   ve got Klout   thanks to  MOOPerk\\nI   m following   Users who aren   t following me back  Found using\\n\\nI just found the online course  quot The Future Of Storytelling quot  on  Check it out  mooc\\nborrar  agregar archivos  via\\nufff   vina  live at\\nThe eLearning Guild     Tips on Graphics and Animations for eLearning   Publications Library\\nMe gust\\xf3 un video de Will it Blend  iPhone  s and  c\\n\\xbfC\\xf3mo ser un buen Community Manager   Excelentes tips \\n\\nExcelente herramienta para crear mapas mentales \\nSpiderScribe net  beta  is out \\nThink  tv   Videoteca via REDES DE APRENDIZAJE PERSONAL\\n  web     tools your students want you to use\\niPad for eLearning\\nTecnolog\\xeda educativa on\\neLearning Resources | Online Training Guides | Links   CommLab India  via\\neFront  Free Stock Photos Sites for e Learning\\nReading   quot   '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "#pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + SOA+SOAC. Ommit preprocess!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "features.SOAC_Model2.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3grams',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "scaler = StandardScaler()#MinMaxScaler()#StandardScaler()\n",
    "#svm = DecisionTreeClassifier()\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe = Pipeline([('3grams', grams3), ('svm', svm)])\n",
    "#pipe = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grams3.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])]\n"
     ]
    }
   ],
   "source": [
    "a= grams3.transform([X[1]])\n",
    "import pprint\n",
    "pprint.pprint(list(a.todense()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pan.features import LDA\n",
    "\n",
    "LDAmodel = LDA(num_topics=30, lib='sklearn')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "#svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced')\n",
    "svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('LDA', LDAmodel)])#, ('soa', soa), ('soac', soac)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from pan.features import SOA_Model2\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "#pipe = Pipeline([('3grams+soa',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "        tokenizer_var='sklearn')),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "      tokenizer_var='sklearn')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 125532)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac.counter.transform([X[1]]).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.features import LDA\n",
    "LDAmodel = LDA(num_topics=30, lib='sklearn')\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "svm = SVC(kernel='rbf', C=10, gamma=1, class_weight='balanced', probability=True)\n",
    "#pipe2 = Pipeline([('counts',combined), ('svm', svm)])\n",
    "pipe2 = Pipeline([('LDAmodel',LDAmodel), ('svm', svm)])\n",
    "pipe2.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from pan.features import SOA_Model2\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "svm = SVC(kernel='rbf', C=10, gamma=1, class_weight='balanced', probability=True)\n",
    "#pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from pan.features import SOAC_Model2\n",
    "from sklearn.svm import SVC\n",
    "soac = SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pan.features import LDA\n",
    "LDAmodel = LDA(num_topics=120, lib='sklearn')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#pipe2 = Pipeline([('counts',combined), ('svm', svm)])\n",
    "pipe2 = Pipeline([('LDAmodel',LDAmodel), ('svm', svm)])\n",
    "#pipe2 = Pipeline([('soa',soa), ('svm', svm)])\n",
    "pipe2.steps                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.3\n",
    "#X, y = dataset.get_data('age')\n",
    "X, y = dataset.get_data('gender')\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y)\n",
    "for i, x in enumerate(X_train):\n",
    "    if len(x)==0:\n",
    "        X_train.remove(x)\n",
    "        y_train.remove(y_train[i])\n",
    "for i, x in enumerate(X_cv):\n",
    "    if len(x)==0:\n",
    "        X_cv.remove(x)\n",
    "        y_cv.remove(y_cv[i])\n",
    "X_meta, X_cv, y_meta, y_cv = train_test_split(X_cv, y_cv, test_size=0.5, stratify=y_cv)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "bdt = AdaBoostClassifier(pipe1,\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(X_train, y_train)\n",
    "predict = bdt.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(results['3grams']['pred'])):\n",
    "    predictions = []\n",
    "    model_names3 = []\n",
    "    for key in sorted(results.keys()):\n",
    "        model_names3.append(key)\n",
    "        predictions.append(results[key]['pred'][i])\n",
    "    #print len(predictions + [y_cv])\n",
    "    #print len(model_names3+['true'])\n",
    "    #print len(predictions[0])\n",
    "    print_overlaps(predictions+[y_cv], model_names3+['true'], True)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, copy\n",
    "\n",
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    temp = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            temp[i,j] = len([m for l, m in enumerate(predictions[i]) if (m==predictions[j][l] and m==predictions[N-1][l])])/float(len(predictions[0]))\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (names[i],  names[j], 100*res[i,j], 100*temp[i,j])\n",
    "    return  [res, temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from pan.features import Metaclassifier\n",
    "import time\n",
    "\n",
    "#pipe = Pipeline([('3grams',grams3), ('svm', svm)])\n",
    "#pipe1 = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe2 = Pipeline([('soa',soa), ('svm', svm)])\n",
    "\n",
    "### AGE ###\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='hard')\n",
    "#models = [pipe,pipe1,pipe2,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting', 'votingh']\n",
    "\n",
    "### GENDER ###\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='hard')\n",
    "models = [pipe,pipe1,eclf, eclfh]\n",
    "model_names = ['3grams', 'soac', 'voting', 'votingh']\n",
    "\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "#eclfh = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='hard')\n",
    "#models = [pipe,pipe1,eclf, eclfh]\n",
    "#model_names = ['3grams', 'soac', 'voting', 'votingh']\n",
    "\n",
    "results = {}\n",
    "for name in model_names:\n",
    "    results[name] = {'pred': [], 'acc': [], 'conf': [], 'over': []}\n",
    "results['space'] = {'pred': [], 'acc': [], 'conf': [], 'over':[]}\n",
    "results['meta'] = {'pred': [], 'acc': [], 'conf': [], 'over':[]}\n",
    "params = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "#params = {}\n",
    "num_folds = 3\n",
    "splits = [0.25, 0.3, 0.4]\n",
    "N = 4\n",
    "t0 = time.time()\n",
    "for split in splits:\n",
    "    print \"Split: \" + str(split)  \n",
    "    for i in xrange(N):\n",
    "        #X, y = dataset.get_data('age')\n",
    "        #X, y = dataset.get_data('gender')\n",
    "        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y)\n",
    "        for i, x in enumerate(X_train):\n",
    "            if len(x)==0:\n",
    "                X_train.remove(x)\n",
    "                y_train.remove(y_train[i])\n",
    "        for i, x in enumerate(X_cv):\n",
    "            if len(x)==0:\n",
    "                X_cv.remove(x)\n",
    "                y_cv.remove(y_cv[i])\n",
    "        if 'space' or 'meta' in results.keys():\n",
    "            X_meta, X_cv, y_meta, y_cv = train_test_split(X_cv, y_cv, test_size=0.5, stratify=y_cv)\n",
    "        print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "        trained_models = []\n",
    "        for i, model in enumerate(models):\n",
    "            if model_names[i] == 'voting' or model_names[i] == 'votingh':\n",
    "                params = {}\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=params, verbose=0, n_jobs=-1, cv=num_folds, refit=True)\n",
    "            grid_search.fit(X_train,y_train)\n",
    "            trained_models.append(grid_search.best_estimator_)\n",
    "        predictions = []\n",
    "        for i, model in enumerate(trained_models):\n",
    "            predict = model.predict(X_cv)\n",
    "            predictions.append(predict)\n",
    "            results[model_names[i]]['pred'].append(predict)\n",
    "            results[model_names[i]]['acc'].append(accuracy_score(y_cv, predict))\n",
    "            results[model_names[i]]['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        # Space model ###\n",
    "        models_for_space = {}\n",
    "        cv_scores = []\n",
    "        for name, model in zip(model_names, trained_models):\n",
    "            if name!='voting' and name!='votingh':\n",
    "                models_for_space[name] = model\n",
    "                cv_scores.append(model.score(X_meta, y_meta))\n",
    "        space = SubSpaceEnsemble4_2(models_for_space, cv_scores, k=6, weights=[0.65,0.35,0.32,6], N_rand=10, rand_split=0.6)\n",
    "        space.fit(X_meta, y_meta)\n",
    "        predict = space.predict(X_cv)\n",
    "        #grid_search = GridSearchCV(space, param_grid={}, verbose=0, n_jobs=-1, cv=num_folds, refit=True)\n",
    "        #grid_search.fit(X_meta+X_train, y_meta+y_train)\n",
    "        #predict = grid_search.best_estimator_.predict(X_cv)\n",
    "        results['space']['pred'].append(predict)\n",
    "        results['space']['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results['space']['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        predictions.append(predict)\n",
    "        # Space model end ###\n",
    "        # Meta ###\n",
    "        model_dic = {}\n",
    "        for i, model in enumerate(trained_models):\n",
    "            if model_names[i] != 'voting' and model_names[i] !='votingh': \n",
    "                model_dic[model_names[i]] = model\n",
    "        Meta = Metaclassifier(models=model_dic, C=1.0, weights='balanced')\n",
    "        Meta.fit(X_meta, y_meta)\n",
    "        predict = Meta.predict(X_cv)\n",
    "        results['meta']['pred'].append(predict)\n",
    "        results['meta']['acc'].append(accuracy_score(y_cv, predict))\n",
    "        results['meta']['conf'].append(confusion_matrix(y_cv, predict, labels=list(set(y))))\n",
    "        predictions.append(predict)\n",
    "        # Meta model END ###\n",
    "        predictions.append(y_cv)\n",
    "        results['3grams']['over'].append(print_overlaps(predictions, model_names+['space', 'meta', 'true'], False))\n",
    "    print('Split %0.1f.: %0.3f seconds') % (split, time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "for i, split in enumerate(splits):\n",
    "    print 'Split: %0.2f' % split\n",
    "    print '----------- Scores-----------'\n",
    "    #for name in model_names:\n",
    "    for name in model_names + ['space'] + ['meta']:\n",
    "        tmp = results[name]['acc'][N*i:(N*i+N)]\n",
    "        print \n",
    "        print 'Model: %s Accuracy: %0.3f Std: %0.3f' % (name, statistics.mean(tmp), \n",
    "                                                          statistics.stdev(tmp))\n",
    "        #tmp_conf = copy.deepcopy(results[name]['conf'][N*i])\n",
    "        #for j in xrange(N*i+1, N*i+N):\n",
    "        #    tmp_conf += results[name]['conf'][j]\n",
    "        #tmp_conf /= N\n",
    "        #print('Confusion matrix :\\n {}'.format(tmp_conf))\n",
    "    print '----------- Overlaps-----------'\n",
    "    tmp_overlaps = copy.deepcopy(results['3grams']['over'][N*i][0])\n",
    "    tmp_gt_overlaps = copy.deepcopy(results['3grams']['over'][N*i][1])\n",
    "    for j in xrange(N*i+1, N*i+N):\n",
    "            tmp_overlaps += results['3grams']['over'][j][0]\n",
    "            tmp_gt_overlaps += results['3grams']['over'][j][1]\n",
    "    tmp_overlaps /= N\n",
    "    tmp_gt_overlaps /= N\n",
    "    print_names = model_names+['space', 'meta','true']\n",
    "    #print_names = model_names+['true']\n",
    "    for k in xrange(tmp_overlaps.shape[0]):\n",
    "        for v in xrange(k+1, tmp_overlaps.shape[0]):\n",
    "            print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (print_names[k],  print_names[v], 100*tmp_overlaps[k, v], 100*tmp_gt_overlaps[k,v])\n",
    "    print '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.3\n",
    "#X, y = dataset.get_data('age')\n",
    "#X, y = dataset.get_data('gender')\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y)\n",
    "for i, x in enumerate(X_train):\n",
    "    if len(x)==0:\n",
    "        X_train.remove(x)\n",
    "        y_train.remove(y_train[i])\n",
    "for i, x in enumerate(X_cv):\n",
    "    if len(x)==0:\n",
    "        X_cv.remove(x)\n",
    "        y_cv.remove(y_cv[i])\n",
    "X_meta, X_cv, y_meta, y_cv = train_test_split(X_cv, y_cv, test_size=0.5, stratify=y_cv)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='soft')\n",
    "#eclf2 = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), (\"2\", pipe2)], voting='hard')\n",
    "#models = [pipe,pipe1,pipe2,eclf, eclf2]\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting', 'votingh']\n",
    "models = [pipe1, pipe]\n",
    "model_names = ['soac', '3grams']\n",
    "trained_models = []\n",
    "params = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "for i, model in enumerate(models):\n",
    "    if model_names[i] == 'voting' or model_names[i]=='votingh':\n",
    "        params = {}\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, copy\n",
    "\n",
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    temp = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            #print i,j\n",
    "            #print N\n",
    "            #print l\n",
    "            #print len(predictions[j]), predictions[j]\n",
    "            #print len(predictions[N-1]), predictions[N-1]\n",
    "            temp[i,j] = len([m for l, m in enumerate(predictions[i]) if (m==predictions[j][l] and m==predictions[N-1][l])])/float(len(predictions[0]))\n",
    "            #print i,j\n",
    "            #predictions[i]\n",
    "            #predictions[j]\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            #print res[i,j]\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (names[i],  names[j], 100*res[i,j], 100*temp[i,j])\n",
    "    return  [res, temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = []\n",
    "for i, model in enumerate(trained_models):\n",
    "    print \"Model: \" + str(model_names[i])\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "    rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))\n",
    "    print('Classification report :\\n {}'.format(rep))\n",
    "    \n",
    "pred2 = copy.deepcopy(predictions)\n",
    "#pred2.append(y_space)\n",
    "pred2.append(y_cv)\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting']\n",
    "#model_names += ['space']\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting', 'votingh']\n",
    "#model_names += ['True']\n",
    "#print len([(i, j) for i,j in zip(predictions[0], predictions[1]) if i==j])/float(len(predictions[0]))\n",
    "_ = print_overlaps(pred2, model_names + ['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Metaclassifier based on the document-term representation accuracy of the\n",
    "        base classifiers. Currently looking only at the nearest neighbor for\n",
    "        each instance and selecting the model that correctly classifies it.\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.doc_terms = None\n",
    "            self.experts = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X_cv).toarray()\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "            count = 0\n",
    "            for i, y in enumerate(y_true):\n",
    "                possible_experts = []\n",
    "                for j, pred in enumerate(predictions):\n",
    "                    if pred[i] == y:\n",
    "                        possible_experts.append(j)\n",
    "                if possible_experts:\n",
    "                    possible_scores = [self.cv_scores[poss] for poss in possible_experts]\n",
    "                    self.experts.append(possible_experts[possible_scores.index(max(possible_scores))])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    self.experts.append(self.cv_scores.index(max(self.cv_scores)))\n",
    "            print \"Chosen through expert: %0.2f\" % (100*count/float(len(y_true))) \n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            best_model_ind = self.find_sim_projection(X_transformed[i,:])\n",
    "            #print best_model_ind\n",
    "            #print self.models[self.ind2names[best_model_ind]].predict([X[i]])[0]\n",
    "            y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def find_sim_projection(self, x_sample):\n",
    "\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        cos = []\n",
    "        j = None\n",
    "        min_s = -10000\n",
    "        for i in range(0, self.doc_terms.shape[0]):\n",
    "            #print x_sample.reshape(1,-1).shape\n",
    "            #print self.doc_terms[i,:].reshape(1,-1).shape\n",
    "            temp = cosine_similarity(x_sample.reshape(1,-1), self.doc_terms[i,:].reshape(1,-1))[0][0]\n",
    "            if min_s < 0 or  temp > min_s:\n",
    "                min_s = temp\n",
    "                j = i\n",
    "        return self.experts[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [0,1,2,3]\n",
    "b= [3,1]\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import time\n",
    "\n",
    "class SubSpaceEnsemble3(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme.\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=3, weights= [6,3,2,0.7]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.weights = weights\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            count = 0\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            #print 'Sample ' + y_real[i]\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  X[i]))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "        #print 'True'\n",
    "        #print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[1]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[2]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "                #print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "                #print 'Predictions'\n",
    "                #print model_pred\n",
    "                #print 'Representations'\n",
    "                #print model_neig_pred\n",
    "                #print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for j in xrange(int(weights['true'])) for n in neigbors_true])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "        #print data\n",
    "        best_model_ind = acc.index(max(acc))\n",
    "        #print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = models['lda']\n",
    "a.steps[0][1].transform(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble2(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Best model base on the prediction of the nearest, according to each model, neighbor \"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=10):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.ind2names = {}\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.trees = []\n",
    "            self.representations = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "                self.trees.append(BallTree(self.representations[-1], leaf_size=20))\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            return self\n",
    "\n",
    "    def predict(self, X, y_real):\n",
    "        \n",
    "\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        y_pred = []\n",
    "        for i, x in enumerate(X):\n",
    "            print 'True: ' + y_real[i]\n",
    "            y_pred.append(self.expert_decision(x))  \n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        \n",
    "        possible_experts = []\n",
    "        sample_predictions = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = self.trees[model_i].query(temp_trans, 1)\n",
    "            #print \"Model neig\"\n",
    "            #print model_neig[0].tolist()[0]\n",
    "            if  self.predictions[model_i][model_neig[0].tolist()[0]] == self.true[model_neig[0].tolist()[0]]:\n",
    "                possible_experts.append(model_i)\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "        if possible_experts:\n",
    "            #print 'Possible experts:'\n",
    "            #print [self.ind2names[poss] for poss in possible_experts]\n",
    "            #print sample_predictions\n",
    "            possible_scores = [self.cv_scores[poss] for poss in possible_experts]\n",
    "            #print 'Selected: '\n",
    "            #print 'Place of best expert: %d ' % possible_scores.index(max(possible_scores))\n",
    "            #print 'Name:  ' + self.ind2names[possible_experts[possible_scores.index(max(possible_scores))]]\n",
    "            #print 'PRediction index: '\n",
    "            #print possible_scores.index(max(possible_scores))\n",
    "            #print 'PRediction : '\n",
    "            #print sample_predictions[possible_scores.index(max(possible_scores))]\n",
    "            return sample_predictions[possible_scores.index(max(possible_scores))]\n",
    "        else:\n",
    "            return self.models[self.ind2names[(self.cv_scores.index(max(self.cv_scores)))]].predict(x_sample)[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "cv_scores = []\n",
    "print len(y_cv), len(X_cv)\n",
    "for i, x in enumerate(X_cv):\n",
    "    if len(x)==0:\n",
    "        X_cv.remove(x)\n",
    "        y_cv.remove(y_cv[i])\n",
    "print len(y_cv), len(X_cv)\n",
    "\n",
    "print len(y_meta), len(X_meta)\n",
    "for i, x in enumerate(X_meta):\n",
    "    if len(x)==0:\n",
    "        X_meta.remove(x)\n",
    "        y_meta.remove(y_meta[i])\n",
    "print len(y_meta), len(X_meta)        \n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "\n",
    "for name, model in zip(model_names, trained_models):\n",
    "    if name!='voting' and name!='votingh' and name!='space' and name!='meta':\n",
    "        models[name] = model\n",
    "        cv_scores.append(model.score(X_meta, y_meta))\n",
    "        \n",
    "w = [1,1,1,0.35]\n",
    "space = SubSpaceEnsemble4(models,cv_scores,k=3)\n",
    "space.fit(X_meta+X_train, y_meta+y_train)\n",
    "predict = space.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print Counter(y_cv)\n",
    "print list(set(y))\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "\n",
    "import numpy, copy\n",
    "\n",
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    temp = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            #print i,j\n",
    "            #print N\n",
    "            #print l\n",
    "            #print len(predictions[j]), predictions[j]\n",
    "            #print len(predictions[N-1]), predictions[N-1]\n",
    "            temp[i,j] = len([m for l, m in enumerate(predictions[i]) if (m==predictions[j][l] and m==predictions[N-1][l])])/float(len(predictions[0]))\n",
    "            #print i,j\n",
    "            #predictions[i]\n",
    "            #predictions[j]\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            #print res[i,j]\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap | ground-truth coverage: %0.3f\" % (names[i],  names[j], 100*res[i,j], 100*temp[i,j])\n",
    "    return  [res, temp]\n",
    "\n",
    "pred2 = copy.deepcopy(predictions)\n",
    "pred2.append(predict)\n",
    "\n",
    "pred2.append(y_cv)\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting']\n",
    "#model_names += ['space']\n",
    "#model_names += ['True']\n",
    "#print len([(i, j) for i,j in zip(predictions[0], predictions[1]) if i==j])/float(len(predictions[0]))\n",
    "print_overlaps(pred2, model_names+ ['space', 'true'])\n",
    "a = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#statsmodels.sandbox.stats.runs.mcnemar\n",
    "\n",
    "from statsmodels.sandbox.stats.runs import mcnemar, cochrans_q\n",
    "\n",
    "print mcnemar(predictions[2], pred2[5], exact=False, correction=True)\n",
    "print cochrans_q(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names += ['space','meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, model in enumerate(trained_models+[space, Meta]):\n",
    "    print model_names[i]\n",
    "    predict1 = model.predict(X_cv)\n",
    "    predictions.append(predict1)\n",
    "    acc = accuracy_score(y_cv, predict1)\n",
    "    conf = confusion_matrix(y_cv, predict1, labels=sorted(list(set(y))))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble4(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Best model base on the prediction of the k-nearest, according to each model, neighbor \"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=6, weights=[0.6,0.2,0.3]):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.ind2names = {}\n",
    "            self.weights = weights\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.trees = []\n",
    "            self.representations = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random, time\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            t0 = time.time()\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "                self.trees.append(BallTree(self.representations[-1], leaf_size=20))\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            #print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        import time\n",
    "\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i, x in enumerate(X):\n",
    "            #print 'True: ' + y_real[i]\n",
    "            y_pred.append(self.expert_decision(x)) \n",
    "        #print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        \n",
    "        possible_experts = []\n",
    "        sample_predictions = []\n",
    "        acc = []\n",
    "        possible_experts_sc = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            #print 'Model: ' + self.ind2names[model_i]\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = self.trees[model_i].query(temp_trans, self.k)\n",
    "            #print \"Model neig\"\n",
    "            #print model_neig[0].tolist()[0]\n",
    "            model_neig_pred = []\n",
    "            neigh_true = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "                neigh_true.append(self.true[model_n_i])\n",
    "            #print \"True_neighbors\"\n",
    "            #print neigh_true\n",
    "            #print \"Predicted neighbors\"\n",
    "            #print model_neig_pred\n",
    "            acc.append(accuracy_score(neigh_true, model_neig_pred, normalize=True))\n",
    "            #print 'Neig Accc: % 0.2f' % acc[-1]\n",
    "            predicted = self.models[self.ind2names[model_i]].predict([x_sample])[0]\n",
    "            proba = max(self.models[self.ind2names[model_i]].predict_proba([x_sample])[0])\n",
    "            #print 'Predicted Sample: %s with proba: %0.3f' % (predicted, 100*proba)\n",
    "            if  acc[-1] > self.weights[2]:\n",
    "                possible_experts.append(model_i)\n",
    "                possible_experts_sc.append(self.weights[1]*acc[-1]+self.weights[0]*proba)\n",
    "                sample_predictions.append(predicted)\n",
    "        if possible_experts:\n",
    "            #print 'Possible experts:'\n",
    "            #print [self.ind2names[poss] for poss in possible_experts]\n",
    "            #print sample_predictions\n",
    "            #print 'Selected: '\n",
    "            #print 'Place of best expert: %d ' % possible_scores.index(max(possible_scores))\n",
    "            #print 'Name:  ' + self.ind2names[possible_experts[possible_scores.index(max(possible_scores))]]\n",
    "            #print 'PRediction index: '\n",
    "            #print possible_scores.index(max(possible_scores))\n",
    "            #print 'PRediction : '\n",
    "            #print sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "            return sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "        else:\n",
    "            #print 'Selected2 from base model: ' + self.ind2names[(self.acc.index(max(acc)))]\n",
    "            #print self.models[self.ind2names[(self.acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "            return self.models[self.ind2names[(acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SubSpaceEnsemble4_2(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Best model base on the prediction of the k-nearest, according to each model, neighbor.\n",
    "        Implementing fitting with random weight searching for better results.\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=6, weights=[0.6,0.2,0.3, 6], N_rand=8, rand_split=0.6):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.ind2names = {}\n",
    "            self.weights = weights\n",
    "            self.N_rand = N_rand\n",
    "            self.rand_split = rand_split\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.trees = []\n",
    "            self.representations = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        import random, time\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            t0 = time.time()\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "                self.trees.append(BallTree(self.representations[-1], leaf_size=20))\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            N_rand1 = int(self.rand_split*self.N_rand)\n",
    "            poss_w = []\n",
    "            acc_ = []\n",
    "            pred = []\n",
    "            for i in xrange(N_rand1):  \n",
    "                tmp_w = [0.6,0.2,0.3, 6]\n",
    "                tmp_w[0] = round(random.random(),3)\n",
    "                tmp_w[1] = round(1 - tmp_w[0],3)\n",
    "                tmp_w[2] = round(random.uniform(0.2,0.8),3)\n",
    "                #tmp_w[3] = random.randint(1,10)\n",
    "                poss_w.append(tmp_w)\n",
    "                pred = self.find_weights(X_cv, tmp_w)\n",
    "                acc = accuracy_score(self.true, pred)\n",
    "                #print('Accuracy : {}'.format(acc))\n",
    "                acc_.append(acc)\n",
    "            print('First search took: %0.3f seconds') % (time.time()-t0)\n",
    "            tmp_w = poss_w[acc_.index(max(acc_))]\n",
    "            poss_w = []\n",
    "            acc_ = []\n",
    "            for i in xrange(self.N_rand-N_rand1):\n",
    "                tmp_w2 = tmp_w\n",
    "                tmp_w2[0] = round(random.uniform(tmp_w[0]-0.1, tmp_w[0]+0.1),3)\n",
    "                tmp_w2[1] = round(1 - tmp_w2[0],3)\n",
    "                tmp_w2[2] = round(random.uniform(tmp_w[2]-0.1, tmp_w[1]+0.1),3)\n",
    "                poss_w.append(tmp_w2)\n",
    "                pred = self.find_weights(X_cv, tmp_w2)\n",
    "                acc = accuracy_score(self.true, pred)\n",
    "                #print('Accuracy : {}'.format(acc))\n",
    "                acc_.append(acc)\n",
    "            self.weights = poss_w[acc_.index(max(acc_))]\n",
    "            self.k = self.weights[3]\n",
    "            print 'Accuracy obtained in CV-data: %0.3f' % (100*acc_[acc_.index(max(acc_))])\n",
    "            print self.weights\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            return self\n",
    "    \n",
    "    def find_weights(self, X_cv, w):\n",
    "        \n",
    "        y_pred = []\n",
    "        #t0 = time.time()\n",
    "        for x in X_cv:\n",
    "            #print 'True: ' + y_real[i]\n",
    "            y_pred.append(self.expert_fit_decision(x, w)) \n",
    "        #print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def expert_fit_decision(self, x_sample, w):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        \n",
    "        possible_experts = []\n",
    "        sample_predictions = []\n",
    "        acc = []\n",
    "        possible_experts_sc = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            #print 'Model: ' + self.ind2names[model_i]\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = self.trees[model_i].query(temp_trans, w[3])\n",
    "            #print \"Model neig\"\n",
    "            #print model_neig[0].tolist()[0]\n",
    "            model_neig_pred = []\n",
    "            neigh_true = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "                neigh_true.append(self.true[model_n_i])\n",
    "            #print \"True_neighbors\"\n",
    "            #print neigh_true\n",
    "            #print \"Predicted neighbors\"\n",
    "            #print model_neig_pred\n",
    "            acc.append(accuracy_score(neigh_true, model_neig_pred, normalize=True))\n",
    "            #print 'Neig Accc: % 0.2f' % acc[-1]\n",
    "            predicted = self.models[self.ind2names[model_i]].predict([x_sample])[0]\n",
    "            proba = max(self.models[self.ind2names[model_i]].predict_proba([x_sample])[0])\n",
    "            #print 'Predicted Sample: %s with proba: %0.3f' % (predicted, 100*proba)\n",
    "            if  acc[-1] > w[2]:\n",
    "                possible_experts.append(model_i)\n",
    "                possible_experts_sc.append(w[1]*acc[-1]+w[0]*proba)\n",
    "                sample_predictions.append(predicted)\n",
    "        if possible_experts:\n",
    "            #print 'Possible experts:'\n",
    "            #print [self.ind2names[poss] for poss in possible_experts]\n",
    "            #print sample_predictions\n",
    "            #print 'Selected: '\n",
    "            #print 'Place of best expert: %d ' % possible_scores.index(max(possible_scores))\n",
    "            #print 'Name:  ' + self.ind2names[possible_experts[possible_scores.index(max(possible_scores))]]\n",
    "            #print 'PRediction index: '\n",
    "            #print possible_scores.index(max(possible_scores))\n",
    "            #print 'PRediction : '\n",
    "            #print sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "            return sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "        else:\n",
    "            #print 'Selected2 from base model: ' + self.ind2names[(self.acc.index(max(acc)))]\n",
    "            #print self.models[self.ind2names[(self.acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "            return self.models[self.ind2names[(acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "        \n",
    "    \n",
    "    def predict(self, X, y_real):\n",
    "        \n",
    "        #import time\n",
    "\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        y_pred = []\n",
    "        #t0 = time.time()\n",
    "        for i, x in enumerate(X):\n",
    "            print 'True: ' + y_real[i]\n",
    "            y_pred.append(self.expert_decision(x)) \n",
    "        #print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        \n",
    "        possible_experts = []\n",
    "        sample_predictions = []\n",
    "        acc = []\n",
    "        possible_experts_sc = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            print 'Model: ' + self.ind2names[model_i]\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = self.trees[model_i].query(temp_trans, self.k)\n",
    "            #print \"Model neig\"\n",
    "            #print model_neig[0].tolist()[0]\n",
    "            model_neig_pred = []\n",
    "            neigh_true = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "                neigh_true.append(self.true[model_n_i])\n",
    "            print \"True_neighbors\"\n",
    "            print neigh_true\n",
    "            print \"Predicted neighbors\"\n",
    "            print model_neig_pred\n",
    "            acc.append(accuracy_score(neigh_true, model_neig_pred, normalize=True))\n",
    "            print 'Neig Accc: % 0.2f' % acc[-1]\n",
    "            predicted = self.models[self.ind2names[model_i]].predict([x_sample])[0]\n",
    "            proba = max(self.models[self.ind2names[model_i]].predict_proba([x_sample])[0])\n",
    "            print 'Predicted Sample: %s with proba: %0.3f' % (predicted, 100*proba)\n",
    "            if  acc[-1] > self.weights[2]:\n",
    "                possible_experts.append(model_i)\n",
    "                possible_experts_sc.append(self.weights[1]*acc[-1]+self.weights[0]*proba)\n",
    "                sample_predictions.append(predicted)\n",
    "        if possible_experts:\n",
    "            print 'Possible experts:'\n",
    "            print [self.ind2names[poss] for poss in possible_experts]\n",
    "            print sample_predictions\n",
    "            print possible_experts_sc\n",
    "            #print 'Selected: '\n",
    "            #print 'Place of best expert: %d ' % possible_scores.index(max(possible_scores))\n",
    "            #print 'Name:  ' + self.ind2names[possible_experts[possible_scores.index(max(possible_scores))]]\n",
    "            #print 'PRediction index: '\n",
    "            #print possible_scores.index(max(possible_scores))\n",
    "            print 'PRediction : '\n",
    "            print sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "            return sample_predictions[possible_experts_sc.index(max(possible_experts_sc))]\n",
    "        else:\n",
    "            print 'Selected2 from base model: ' + self.ind2names[(acc.index(max(acc)))]\n",
    "            print self.models[self.ind2names[(acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "            return self.models[self.ind2names[(acc.index(max(acc)))]].predict([x_sample])[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "cv_scores = []\n",
    "models = {}\n",
    "for name, model in zip(model_names, trained_models):\n",
    "    if name!='voting' and name!='votingh' and name!='space' and name!='meta':\n",
    "        models[name] = model\n",
    "        cv_scores.append(model.score(X_meta, y_meta))\n",
    "        \n",
    "\n",
    "w = [0.649, 0.351, 0.32, 6]\n",
    "print len(X_meta)\n",
    "print len(y_meta)\n",
    "space = SubSpaceEnsemble4_2(models,cv_scores,k=w[3], weights=w[:-1], N_rand=20, rand_split=0.6)\n",
    "space.fit(X_meta, y_meta)\n",
    "predict = space.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import time\n",
    "\n",
    "class SubSpaceEnsemble3_2(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\" Utilizing the neighborhood in all representations and also ground truth model.\n",
    "        Implementing a weighted voting scheme.\"\"\"\n",
    "\n",
    "    def __init__(self, models, cv_scores, k=3, weights= [6,3,2,0.7, 3], N_rand=8, rand_split=0.6):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        if (not models) or (not cv_scores):\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier.\\\n",
    "              cv_score expects a list len(models.keys()) with the\\\n",
    "              cross validation scores of each model')\n",
    "        else:\n",
    "            self.models = models\n",
    "            self.cv_scores = cv_scores\n",
    "            self.k = k\n",
    "            self.weights = weights\n",
    "            self.ind2names = {}\n",
    "            self.N_rand = N_rand\n",
    "            self.rand_split = rand_split\n",
    "            for i, name in enumerate(models.keys()):\n",
    "                self.ind2names[i] = name\n",
    "            self.counter = CountVectorizer()\n",
    "            self.representations = []\n",
    "            self.meta = None\n",
    "            self.predictions = []\n",
    "            self.true = []\n",
    "            self.doc_terms = None\n",
    "            self.tree = None\n",
    "            self.experts = []\n",
    "        \n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "        \n",
    "        from sklearn.neighbors import BallTree\n",
    "        import random\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            parameters = {\n",
    "                    'input': 'content',\n",
    "                    'encoding': 'utf-8',\n",
    "                    'decode_error': 'ignore',\n",
    "                    'analyzer': 'word',\n",
    "                    'stop_words': 'english',\n",
    "                    # 'vocabulary':list(voc),\n",
    "                    #'tokenizer': tokenization,\n",
    "                    #'tokenizer': _twokenize.tokenizeRawTweetText,  # self.tokenization,\n",
    "                    #'tokenizer': lambda text: _twokenize.tokenizeRawTweetText(nonan.sub(po_re.sub('', text))),\n",
    "                    'max_df': 1.0,\n",
    "                    'min_df': 1,\n",
    "                    'max_features':None\n",
    "                }\n",
    "            t0 = time.time()\n",
    "            self.counter.set_params(**parameters)\n",
    "            self.doc_terms = self.counter.fit_transform(X_cv).toarray()\n",
    "            self.tree = BallTree(self.doc_terms, leaf_size=20)\n",
    "            predictions = []\n",
    "            for name, model in self.models.iteritems():\n",
    "                predictions.append(model.predict(X_cv))\n",
    "                #print len(predictions[-1])\n",
    "                transf = model.steps[0][1].transform(X_cv)\n",
    "                if hasattr(transf, \"toarray\"):\n",
    "                    #print 'Exei'\n",
    "                    self.representations.append(transf.toarray())\n",
    "                else:\n",
    "                    self.representations.append(transf)\n",
    "            self.predictions = predictions\n",
    "            self.true = y_true\n",
    "            self.true = y_true\n",
    "            N_rand1 = int(self.rand_split*self.N_rand)\n",
    "            poss_w = []\n",
    "            acc_ = []\n",
    "            pred = []\n",
    "            for i in xrange(N_rand1):  \n",
    "                tmp_w = self.weights\n",
    "                tmp_w[0] = random.randint(1,10)\n",
    "                tmp_w[1] = random.randint(1,10)\n",
    "                tmp_w[2] = random.randint(1,10)\n",
    "                tmp_w[3] = round(random.uniform(0.2,0.8),3)\n",
    "                tmp_w[4] = random.randint(1,10)\n",
    "                poss_w.append(tmp_w)\n",
    "                pred = self.find_weights(X_cv, tmp_w)\n",
    "                acc = accuracy_score(self.true, pred)\n",
    "                #print('Accuracy : {}'.format(acc))\n",
    "                acc_.append(acc)\n",
    "            print('First search took: %0.3f seconds') % (time.time()-t0)\n",
    "            tmp_w = poss_w[acc_.index(max(acc_))]\n",
    "            poss_w = []\n",
    "            acc_ = []\n",
    "            for i in xrange(self.N_rand-N_rand1):\n",
    "                tmp_w2 = tmp_w\n",
    "                tmp_w2[0] = round(random.randint(tmp_w[0]-2, tmp_w[0]+2))\n",
    "                tmp_w2[1] = round(random.randint(tmp_w[1]-2, tmp_w[1]+2))\n",
    "                tmp_w2[2] = round(random.randint(tmp_w[2]-2, tmp_w[2]+2))\n",
    "                tmp_w2[3] = round(random.uniform(tmp_w[3]-0.1, tmp_w[3]+0.1),3)\n",
    "                poss_w.append(tmp_w2)\n",
    "                pred = self.find_weights(X_cv, tmp_w2)\n",
    "                acc = accuracy_score(self.true, pred)\n",
    "                #print('Accuracy : {}'.format(acc))\n",
    "                acc_.append(acc)\n",
    "            self.weights = poss_w[acc_.index(max(acc_))]\n",
    "            self.k = self.weights[4]\n",
    "            print 'Accuracy obtained in CV-data: %0.3f' % (100*acc_[acc_.index(max(acc_))])\n",
    "            print self.weights\n",
    "            print('Fit took: %0.3f seconds') % (time.time()-t0)\n",
    "            #print self.expert_scores\n",
    "            #print self.experts\n",
    "            return self\n",
    "    \n",
    "    def find_weights(self, X_cv, w):\n",
    "        \n",
    "        X_transformed = self.counter.transform(X_cv).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), w[4])  \n",
    "            #print 'Sample ' + y_real[i]\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            y_pred.append(self.expert_fit_decision(neigbors_indexes[0],  X[i], w))\n",
    "            \n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        return y_pred\n",
    "            \n",
    "    def expert_fit_decision(self, neigbors_indexes, x_sample, w):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "        #print 'True'\n",
    "        #print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = w[1]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            #print 'acc-thres'\n",
    "            #print acc, w[3]\n",
    "            if acc[-1] >w[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(w[2]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(w[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "                #print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "                #print 'Predictions'\n",
    "                #print model_pred\n",
    "                #print 'Representations'\n",
    "                #print model_neig_pred\n",
    "                #print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "                #print \"weights\"\n",
    "                #print weights\n",
    "        total_pred.extend([n for j in xrange(int(weights['true'])) for n in neigbors_true])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        #print total_pred\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "        #print data\n",
    "        best_model_ind = acc.index(max(acc))\n",
    "        #print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]\n",
    "        \n",
    "\n",
    "    def predict(self, X, y_real):\n",
    "        \n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X_transformed = self.counter.transform(X).toarray()\n",
    "        #print type((X_transformed)[0])\n",
    "        #print X_transformed.shape\n",
    "        #return 0\n",
    "        y_pred = []\n",
    "        t0 = time.time()\n",
    "        for i in range(0, X_transformed.shape[0]):\n",
    "            #print X_transformed[i,:].shape\n",
    "            dist, neigbors_indexes = self.tree.query(X_transformed[i,:].reshape(1,-1), self.k)  \n",
    "            print 'Sample ' + y_real[i]\n",
    "            #print neigbors_indexes[0]\n",
    "            #print dist\n",
    "            #best_model_ind = self.expert_decision(neigbors_indexes[0])\n",
    "            y_pred.append(self.expert_decision(neigbors_indexes[0],  X[i]))\n",
    "            #y_pred.append(self.models[self.ind2names[best_model_ind]].predict([X[i]])[0])\n",
    "        #print y_pred\n",
    "        print('Predict took: %0.3f seconds') % (time.time()-t0)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "\n",
    "    def expert_decision(self, neigbors_indexes, x_sample):\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from collections import Counter\n",
    "        from sklearn.neighbors import BallTree\n",
    "        \n",
    "        models_pred = []\n",
    "        models_neig_pred = []\n",
    "        acc = []\n",
    "        t0 = time.time()\n",
    "        neigbors_true = [self.true[n_i] for n_i in neigbors_indexes]\n",
    "        #print('Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "        #print 'True'\n",
    "        #print neigbors_true\n",
    "        sample_predictions = []\n",
    "        total_pred = []\n",
    "        weights = {}\n",
    "        weights['true'] = self.weights[1]\n",
    "        weights['models_n'] = []\n",
    "        weights['models'] = []\n",
    "        for model_i in xrange(len(self.models.values())):\n",
    "            ModelTree = BallTree(self.representations[model_i])\n",
    "            temp_trans = self.models[self.ind2names[model_i]].steps[0][1].transform([x_sample])\n",
    "            if hasattr(temp_trans, 'toarray'):\n",
    "                temp_trans = temp_trans.toarray()\n",
    "            _, model_neig = ModelTree.query(temp_trans, self.k)\n",
    "            model_neig_pred = []\n",
    "            for model_n_i in model_neig[0].tolist():\n",
    "                model_neig_pred.append(self.predictions[model_i][model_n_i])\n",
    "            models_neig_pred.append(model_neig_pred)\n",
    "            model_pred = []\n",
    "            for n_i in neigbors_indexes:\n",
    "                model_pred.append(self.predictions[model_i][n_i])\n",
    "            models_pred.append(model_pred)\n",
    "            acc.append(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "            if acc[-1] >self.weights[3]:\n",
    "                # Adding neighbors predictions\n",
    "                weights['models_n'].append(int(self.weights[2]/float((1-acc[-1])+0.01)))\n",
    "                total_pred.extend([pred for j in xrange(weights['models_n'][-1]) for pred in model_pred])\n",
    "                #print('Predicting Neighbors per sample: %0.4f seconds') % (time.time()-t0)\n",
    "                # Adding sample prediction\n",
    "                sample_predictions.append(self.models[self.ind2names[model_i]].predict(x_sample)[0])\n",
    "                weights['models'].append(int(self.weights[0]/float((1-acc[-1])+0.01))) \n",
    "                total_pred.extend([sample_predictions[-1] for j in xrange(weights['models'][-1])])\n",
    "                total_pred.extend([pred for j in xrange(weights['models'][-1]) for pred in model_neig_pred])\n",
    "            #print len(x_sample)\n",
    "            #print self.ind2names[model_i]\n",
    "            \n",
    "                #print 'Model: ' + self.ind2names[model_i] + ' Accuracy: ' + str(accuracy_score(neigbors_true, model_pred, normalize=True))\n",
    "                #print 'Predictions'\n",
    "                #print model_pred\n",
    "                #print 'Representations'\n",
    "                #print model_neig_pred\n",
    "                #print 'Sample prediction: ' + str(sample_predictions[-1])\n",
    "        total_pred.extend([n for j in xrange(int(weights['true'])) for n in neigbors_true])\n",
    "        #print('creating votes: %0.4f seconds') % (time.time()-t0)\n",
    "        data = Counter(total_pred)\n",
    "        #data = Counter([k for pred in models_pred for k in pred])\n",
    "        print data\n",
    "        best_model_ind = acc.index(max(acc))\n",
    "        print 'Total pred: ' + str(data.most_common(1)[0][0])\n",
    "        #print len(total_pred)\n",
    "        #return best_model_ind\n",
    "        return data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space.k = space.weights[4]\n",
    "predict = space.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "cv_scores = []\n",
    "models = {}\n",
    "for name, model in zip(model_names, trained_models):\n",
    "    if name!='voting' and name!='votingh' and name!='space' and name!='meta':\n",
    "        models[name] = model\n",
    "        cv_scores.append(model.score(X_meta, y_meta))\n",
    "        \n",
    "\n",
    "weights= [6,3,2,0.7, 3]\n",
    "print len(X_meta)\n",
    "print len(y_meta)\n",
    "space = SubSpaceEnsemble3_2(models,cv_scores,k=weights[4], weights=weights, N_rand=20, rand_split=0.6)\n",
    "space.fit(X_meta, y_meta)\n",
    "predict = space.predict(X_cv, y_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Metaclassifier2(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \"\"\" A Linear Weights Metaclassifier based on the neighborhood of each sample.\n",
    "        The neighborhood is different per base model. For each sample we have\n",
    "        [N, N*k] votes, with N the number of base classifiers and k the number\n",
    "        of neighbors to look for. \"\"\"\n",
    "\n",
    "    def __init__(self, models, C=1.0, weights='balanced', k=3):\n",
    "\n",
    "        from sklearn.svm import LinearSVC\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "        if not models:\n",
    "            raise AttributeError('Models expexts a dictonary of models \\\n",
    "              containg the predictions of y_true for each classifier')\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        self.C = C\n",
    "        self.k = 3\n",
    "        self.svc = LinearSVC(C=self.C, class_weight=self.weights)\n",
    "        self.lab_encoder = LabelEncoder()\n",
    "\n",
    "    def fit(self, X_cv, y_true=None, weights=None):\n",
    "\n",
    "        if y_true is None:\n",
    "            raise ValueError('we need y labels to supervise-fit!')\n",
    "        else:\n",
    "            # import pprint\n",
    "            #print list(set(y_true))\n",
    "            # print len(y_true)\n",
    "            y_true = self.lab_encoder.fit_transform(y_true)\n",
    "            #print self.models.keys()\n",
    "            # print self.lab_encoder.classes_\n",
    "            # print self.models[self.models.keys()[1]].predict(X_cv)\n",
    "            #y_true = self.create_onehot(y_true)\n",
    "            # print \"Train X shape: \" + str(X_cv.shape) + \"train y_true \" + str(y_true.shape)\n",
    "            transformed_y = self.transform_to_y(X_cv)\n",
    "            #X = self.oh_encoder.transform(y_pred.T)\n",
    "            #print transformed_y.shape, y_true.T.shape\n",
    "            #print \"fit true\"\n",
    "            # print transformed_y\n",
    "            # print y_true\n",
    "            self.svc.fit(transformed_y, y_true.T)\n",
    "            return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # print \"PRedict\"\n",
    "        # print X.shape\n",
    "        X = self.transform_to_y(X)\n",
    "        # print \"PRedict after\"\n",
    "        # print X.shape\n",
    "        # print X.T.shape\n",
    "        import pprint\n",
    "        # pprint.pprint(X)\n",
    "        # pprint.pprint(X.T)\n",
    "        # print \"Predict\"\n",
    "        y_pred = self.svc.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(self.lab_encoder.inverse_transform(y_pred)) \n",
    "        return self.lab_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        # import numpy\n",
    "        # print \"Score\"\n",
    "        # print X.shape, numpy.array(y).shape\n",
    "        # transformed_y = self.transform_to_y(X)\n",
    "        # print 'edw ok'\n",
    "        # print self.svc.predict(transformed_y).shape\n",
    "        # print 'Transformed'\n",
    "        # print transformed_y.shape\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        # import pprint\n",
    "        # print \"Ture\"\n",
    "        # pprint.pprint(y)\n",
    "\n",
    "        return accuracy_score(y, self.predict(X), normalize=True)\n",
    "        #return self.svc.score(self.transform_to_y(X), y, sample_weight)\n",
    "\n",
    "    def create_onehot(self, l):\n",
    "\n",
    "        from numpy import zeros, vstack\n",
    "        #print \"L:\"\n",
    "        #from pprint import pprint as pprint\n",
    "        #print type(l)\n",
    "        # pprint(l)\n",
    "        l = list(l)\n",
    "        for i, el in enumerate(l):\n",
    "            temp = zeros([1, len(self.lab_encoder.classes_)], dtype=float)\n",
    "            #print(temp.shape)\n",
    "           # pprint(temp)\n",
    "            temp[0, el] = 1\n",
    "            if i == 0:\n",
    "                fin = temp\n",
    "            else:\n",
    "                fin = vstack((fin, temp))\n",
    "        #print \"onehot shape\" + str(fin.shape)\n",
    "        return fin\n",
    "\n",
    "    def transform_to_y(self, X):\n",
    "\n",
    "        from numpy import hstack\n",
    "\n",
    "        #print \"Train X shape: \" + str(X.shape)\n",
    "        for i, model in enumerate(self.models.values()):\n",
    "            #print self.models.keys()[i]\n",
    "            predict = model.predict(X)\n",
    "            #print type(predict)\n",
    "            #print predict.shape\n",
    "            #print predict\n",
    "            tmp_pred = self.create_onehot(self.lab_encoder.transform(predict))\n",
    "            #print type(tmp_pred)\n",
    "            if i == 0:\n",
    "                y_pred = tmp_pred\n",
    "            else:\n",
    "                y_pred = hstack((y_pred, tmp_pred))\n",
    "            predictions_n = self.neigh_model_pred(model, X, predict)\n",
    "            #print 'Num Pred'\n",
    "            #print len(predictions_n[0])\n",
    "            for neigh_dist in xrange(self.k):\n",
    "                tmp_pred_n = self.create_onehot(self.lab_encoder.transform(predictions_n[:, neigh_dist]))\n",
    "                y_pred = hstack((y_pred, tmp_pred_n))\n",
    "            #print \"y_pred: \" + str(y_pred.shape)\n",
    "        #print \"y_pred: \" + str(y_pred.shape)\n",
    "        #print len(self.lab_encoder.classes_)\n",
    "        #print y_pred\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def neigh_model_pred(self, model, X, pred):\n",
    "\n",
    "        from sklearn.neighbors import BallTree\n",
    "        import numpy\n",
    "\n",
    "        # Expects a pipeline with two steps. Transform and Predict.\n",
    "        transf = model.steps[0][1].transform(X)\n",
    "        if hasattr(transf, \"toarray\"):\n",
    "            # print 'Exei'\n",
    "            representations = transf.toarray()\n",
    "        else:\n",
    "            representations = transf\n",
    "        ModelTree = BallTree(representations)\n",
    "        predictions = []\n",
    "        for i in xrange(representations.shape[0]):\n",
    "            _, neig_ind = ModelTree.query(representations[i,:].reshape(1,-1), self.k)\n",
    "            predictions.extend([pred[n_i] for n_i in neig_ind])\n",
    "        return numpy.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.features import Metaclassifier\n",
    "\n",
    "model_dic = {}\n",
    "for i, model in enumerate(trained_models):\n",
    "    if model_names[i] != 'voting' and model_names[i] !='votingh' and model_names[i] !='meta' and model_names[i] !='space': \n",
    "        model_dic[model_names[i]] = model\n",
    "model_dic['space'] = space\n",
    "#Meta = Metaclassifier2(models=model_dic, C=1, weights='balanced')\n",
    "Meta = Metaclassifier(models=model_dic, C=1, weights='balanced')\n",
    "params = {'C':[0.01, 0.1, 1, 10, 100]}\n",
    "params = {}\n",
    "grid = GridSearchCV(Meta, param_grid=params, verbose=1, n_jobs=-1, cv=3, refit=True)\n",
    "grid.fit(X_train + X_meta, y_train + y_meta)\n",
    "print 'Best params: {} score: {}'.format(grid.best_params_, grid.best_score_)\n",
    "#Meta.fit(X_meta, y_meta)\n",
    "#predict = Meta.predict(X_cv)\n",
    "predict = grid.predict(X_cv)\n",
    "#Meta.fit(X_meta, y_meta)\n",
    "#predict = Meta.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "rep = classification_report(y_cv, predict, target_names=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "print('Classification report :\\n {}'.format(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cvxpy import *\n",
    "\n",
    "def f(w):\n",
    "    print \"Weights\"\n",
    "    print w\n",
    "    space = SubSpaceEnsemble3(models,cv_scores,k=10, weights=w)\n",
    "    space.fit(X_train + X_cv, y_train + y_cv)\n",
    "    score = 1- accuracy_score(y_meta, space.predict(X_meta))\n",
    "    print 'Score: ' + str(score)\n",
    "    return score\n",
    "\n",
    "n = 4\n",
    "w = Variable(n)\n",
    "objective = Minimize(f(w))\n",
    "constraints = [0 <= w]\n",
    "prob = Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective is returned by prob.solve().\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in x.value.\n",
    "print(w.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = numpy.array([[  0, 207,  65, 161,  11,  61, 152,  37, 302,  25]])\n",
    "a[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "global X_train, X_meta, x_cv, y_train, y_meta, y_cv\n",
    "\n",
    "def f(w):\n",
    "    print \"Weights\"\n",
    "    print w\n",
    "    score = 1- accuracy_score(y_meta, space.predict(X_meta, w))\n",
    "    print 'Score: ' + str(score)\n",
    "    return score\n",
    "\n",
    "w = [3,2,1,0.35]\n",
    "#space = SubSpaceEnsemble3(models,cv_scores,k=3, weights=w)\n",
    "#space.fit(X_train + X_cv, y_train + y_cv)\n",
    "#print models.keys()\n",
    "#print cv_scores\n",
    "\n",
    "bnds = ((0, None), (0, None), (0, None), (0, 1))\n",
    "a = minimize(f, w,  method='SLSQP', bounds=bnds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.features import Metaclassifier2\n",
    "\n",
    "model_dic = {}\n",
    "for i, model in enumerate(trained_models):\n",
    "    if model_names[i] != 'voting' and model_names[i] !='votingh' and model_names[i] !='meta' and model_names[i] !='space': \n",
    "        model_dic[model_names[i]] = model\n",
    "model_dic['space'] = space\n",
    "Meta = Metaclassifier(models=model_dic, C=1.0, weights='balanced')\n",
    "#grid = GridSearchCV(Meta, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "#grid.fit(X_meta, y_meta)\n",
    "Meta.fit(X_train + X_meta, y_train + y_meta)\n",
    "predict = Meta.predict(X_cv)\n",
    "#Meta.fit(X_meta, y_meta)\n",
    "#predict = Meta.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models['voting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "cv_scores = []\n",
    "for name, model in zip(model_names, trained_models):\n",
    "    if name!='voting' and name!='space' and name!='meta':\n",
    "        models[name] = model\n",
    "        cv_scores.append(model.score(X_cv, y_cv))\n",
    "\n",
    "print models.keys()\n",
    "print cv_scores\n",
    "space = SubSpaceEnsemble(models, cv_scores)\n",
    "grid_search = GridSearchCV(SubSpaceEnsemble(models, cv_scores), param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X_cv, y_cv)\n",
    "space.fit(X_cv, y_cv)\n",
    "y_space = grid_search.best_estimator_.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_space[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, model in enumerate(trained_models):\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "\n",
    "import numpy, copy\n",
    "\n",
    "def print_overlaps(predictions, names, verbose=True):\n",
    "    N = len(names)\n",
    "    res = numpy.zeros([N,N])\n",
    "    for i in range(0, N):\n",
    "        for j in range(i+1, N):\n",
    "            #print i,j\n",
    "            #predictions[i]\n",
    "            #predictions[j]\n",
    "            res[i,j] = len([(k,v) for k,v in zip(predictions[i], predictions[j]) if k==v])/float(len(predictions[0]))\n",
    "            #print res[i,j]\n",
    "            if verbose:\n",
    "                print \"%s - %s : %0.3f  overlap\" % (names[i],  names[j], 100*res[i,j])\n",
    "    return  res\n",
    "\n",
    "#pred2 = copy.deepcopy(predictions)\n",
    "#pred2.append(y_space)\n",
    "\n",
    "#pred2.append(y_cv)\n",
    "#model_names = ['3grams', 'soac', 'lda', 'voting']\n",
    "#model_names += ['space']\n",
    "#model_names += ['True']\n",
    "#print len([(i, j) for i,j in zip(predictions[0], predictions[1]) if i==j])/float(len(predictions[0]))\n",
    "#print_overlaps(pred2, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "svm = SVC(kernel='rbf', C=10, gamma=1, class_weight='balanced', probability=True)\n",
    "\n",
    "#clf = AdaBoostClassifier(base_estimator=svm, n_estimators=100, learning_rate=1.0, algorithm='SAMME.R', random_state=42)\n",
    "\n",
    "clf = BaggingClassifier(base_estimator = svm, n_estimators=100, verbose=1, random_state=42)\n",
    "\n",
    "#X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "X_train_new = soac.transform(X_train)\n",
    "#for i, x in enumerate(X_train):\n",
    "#    if len(x)<=1 or y_train[i]<=1:\n",
    "#        print 'y'\n",
    "#        X_train.remove(x)\n",
    "#        y_train.remove(y_train[i])\n",
    "print len(X_train), len(y_train)\n",
    "clf.fit(X_train_new,y_train)\n",
    "predict= clf.predict(soac.transform(X_cv))\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas, copy\n",
    "import matplotlib.pyplot as plt\n",
    "pred2 = copy.deepcopy(predictions)\n",
    "pred2.append(y_cv)\n",
    "pred2 = map(list, zip(*pred2))\n",
    "df = pandas.DataFrame(pred2, columns=model_names)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print model_names\n",
    "print len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "tls.set_credentials_file(username=\"Bogas\",\n",
    "                             api_key=\"9s60rarm2w\")\n",
    "\n",
    "py.sign_in(username=\"Bogas\", api_key=\"9s60rarm2w\")\n",
    "\n",
    "pred2 = copy.deepcopy(predictions)\n",
    "pred2.append(y_cv)\n",
    "traces = []\n",
    "model_names += ['True']\n",
    "for i, pred in enumerate(pred2):\n",
    "    traces.append(Scatter(\n",
    "        x=range(0,len(y_cv)),\n",
    "        y=pred,\n",
    "        mode='markers+line',\n",
    "        type= 'scatter',\n",
    "        name= model_names[i]\n",
    "        )\n",
    "                )\n",
    "\n",
    "title1 = \"Results on test set for Ensemble Scheme\"\n",
    "layout = Layout(\n",
    "        width= 1200,\n",
    "        height= 800,\n",
    "        title= title1,\n",
    "        xaxis = {\"title\": 'Samples'},\n",
    "        yaxis = {\"title\": 'Classes', \"type\":'category'}\n",
    ")\n",
    "\n",
    "data = Data(traces)\n",
    "fig = Figure(data=data, layout=layout)\n",
    "#py.plot(fig, filename='Grey_70_cosine_vector_list bow')\n",
    "py.iplot(fig, filename=title1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(YAxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict class probabilities for all classifiers\n",
    "probas = [c.predict_proba(X_cv) for c in trained_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "import numpy as np\n",
    "\n",
    "y_cv2 = label_binarize(y_cv, list(set(y)))\n",
    "pred2 = []\n",
    "for pred in predictions:\n",
    "    pred2.append(label_binarize(pred, list(set(y))))\n",
    "\n",
    "n_classes = len(list(set(y)))\n",
    "plt.figure()    \n",
    "for j, model in enumerate(trained_models):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(list(set(y)))):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_cv2[:, i], pred2[j][:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label=model_names[j]+' macro-area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics to multi-class for ensemble methods')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDAA = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1]\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\" \".join([feature_names[i]\n",
    "        #                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "#print_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "     \n",
    "    feat = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        feat.append(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\"#%d: \" % topic_idx + topic_words)\n",
    "    return feat\n",
    "get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "print len(feature_names)\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "feature_names = copy.deepcopy(countTokens.l)\n",
    "feature_names += ['numHash', 'numUrl', 'numRep']\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(countTokens.l), len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "#features.SOAC_Model2.__doc__\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "#y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = [#\"I like playing video games very much :).\", \n",
    "     #\"Football games are the best!\",\n",
    "     #\"Being young forever is very funny and entertaining\",\n",
    "     # \"Football games are the best!\",\n",
    "      \"best games\",\n",
    "      \"best games\",\n",
    "     #\"World leaders should gather and decide for todays meeting!\",\n",
    "     #\"Problems nowadays seem to thrive everywhere\",\n",
    "     #\"Just got off from work today! Weekend is coming though, so it's alright...\",\n",
    "     #\"This weekend we are going of for 3 days..\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\"]\n",
    "yy = [\"18-24\",\n",
    "     \"18-24\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "    ]\n",
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "XX = preprocess.preprocess(XX)\n",
    "num_folds = 2\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(XX,yy)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from pan import preprocess\n",
    "\n",
    "task = 'gender'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "        tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(features)\n",
    "#from pan import features\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "#from pan.features import SOAC_Model2\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soac', soac)])\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soa', soa)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe2= Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe2.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search1 = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search1.fit(X,y)\n",
    "print(grid_search1.best_estimator_)\n",
    "print(grid_search1.best_score_)\n",
    "grid_search2 = GridSearchCV(estimator=pipe2, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search2.fit(X,y)\n",
    "print(grid_search2.best_estimator_)\n",
    "print(grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 + 88 = 436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#reload(features)\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y)\n",
    "print \"%d + %d = %d\" % (len(X_train), len(X_cv), len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pipe1.fit(X_train, y_train)\n",
    "predict = pipe1.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
      "      tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.704022988506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 88 436 436\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.738505747126\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
      "      tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, stratify=y, random_state=2)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "#eclf = VotingClassifier(estimators=[(\"0\", pipe1), ('1', pipe2)], voting='soft')\n",
    "trained_models = []\n",
    "for model in [pipe1]:\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.75\n",
      "Confusion matrix :\n",
      " [[39  5]\n",
      " [17 27]]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for model in trained_models:\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y))))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.840909090909\n",
      "Confusion matrix :\n",
      " [[34 10]\n",
      " [ 4 40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "predict = grid_search.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#feature_names = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1].get_feature_names()\n",
    "#print len(set(y))\n",
    "feature_names = []\n",
    "soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "feature_names += soac_feat_names\n",
    "print len(feature_names)\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = trained_models[0].steps[0][1]\n",
    "#a = grid_search.best_estimator_.steps[0][1]\n",
    "#print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soacc.counter.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soacc = a.transformer_list[0][1]\n",
    "representatives = []\n",
    "voc2 = {}\n",
    "for word, ind in soacc.counter.vocabulary_.iteritems():\n",
    "    voc2[ind] = word\n",
    "for x in X_cv+X_train:\n",
    "    cc = soacc.counter.transform([x]).toarray()[0]\n",
    "    res = [voc2[word_ind] for word_ind in cc.nonzero()[0]]\n",
    "    representatives.append(res)\n",
    "    #break\n",
    "#print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       soac_prob_0  soac_prob_1\n",
      "count   436.000000   436.000000\n",
      "mean      6.120259     6.054146\n",
      "std       1.923081     1.565256\n",
      "min       0.000000     0.000000\n",
      "25%       5.019452     5.270009\n",
      "50%       6.362213     6.209389\n",
      "75%       7.359869     6.966224\n",
      "max      17.256644    12.241891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(a.transform(X), columns=feature_names)\n",
    "data[\"class\"] = y\n",
    "data['class_pred'] = grid_search.predict(X)\n",
    "#data['text'] = representatives\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       soac_prob_0  soac_prob_1\n",
      "count    88.000000    88.000000\n",
      "mean      5.886286     5.716260\n",
      "std       1.525208     1.294564\n",
      "min       0.000000     0.000000\n",
      "25%       5.032209     4.996745\n",
      "50%       6.221975     6.129128\n",
      "75%       6.864808     6.584821\n",
      "max       9.641767     7.673573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_cv = pd.DataFrame(a.transform(X_cv), columns=feature_names)\n",
    "data_cv[\"class\"] = y_cv\n",
    "data_cv['class_pred'] = grid_search.predict(X_cv)\n",
    "#data['text'] = representatives\n",
    "print(data_cv.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       soac_prob_0  soac_prob_1\n",
      "count   348.000000   348.000000\n",
      "mean      6.179424     6.139588\n",
      "std       2.008852     1.617066\n",
      "min       0.000000     0.000000\n",
      "25%       5.019452     5.360300\n",
      "50%       6.418644     6.225570\n",
      "75%       7.522992     7.108336\n",
      "max      17.256644    12.241891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.DataFrame(a.transform(X_train), columns=feature_names)\n",
    "data_train[\"class\"] = y_train\n",
    "data_train['class_pred'] = grid_search.predict(X_train)\n",
    "#data_full['text'] = representatives\n",
    "print(data_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_full[data_full['class']!=data_full['class_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soacc = a.transformer_list[0][1]\n",
    "voc = soacc.counter.vocabulary_\n",
    "print 'Voc: ' + str(len(voc))\n",
    "print soacc.term_table.shape\n",
    "#terms= ['marriage', 'pension']\n",
    "#graph_matrix = numpy.zeros([len(terms), soacc.term_table.shape[1]])\n",
    "j = 0 \n",
    "for term, index in voc.iteritems():\n",
    "    l = list(soacc.term_table[index,:])\n",
    "    if l.index(min(l))==3 and  min(l)<0.02 and min(l)!=0:\n",
    "        print term\n",
    "        print l\n",
    "        j += 1\n",
    "    if j==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy\n",
    "py.sign_in('Bogas', '9s60rarm2w')\n",
    "soacc = a.transformer_list[0][1]\n",
    "voc = soacc.counter.vocabulary_\n",
    "print 'Voc: ' + str(len(voc))\n",
    "print soacc.term_table.shape\n",
    "terms= ['dreamjob','lol', 'mortgage', 'booksellers', 'juvenile']\n",
    "graph_matrix = numpy.zeros([len(terms), soacc.term_table.shape[1]])\n",
    "j = 0\n",
    "for term in terms:\n",
    "    idx = voc[term]\n",
    "    print term\n",
    "    print soacc.term_table[idx,:]\n",
    "    graph_matrix[j, :] = soacc.term_table[idx,:]\n",
    "    j += 1\n",
    "    #plt.bar(numpy.arange(soacc.term_table.shape[1]), soacc.term_table[idx,:], color='r')\n",
    "    #plt.show()\n",
    "\n",
    "data = []\n",
    "names = sorted(list(set(y)))\n",
    "for i in range(0, soacc.term_table.shape[1]):\n",
    "    data.append(\n",
    "        go.Bar(\n",
    "        x=terms,\n",
    "        y=graph_matrix[:, i],\n",
    "        name=names[i]\n",
    "    )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "#plot_url = py.plot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "rowlength = grouped.ngroups/2                         # fix up if odd number of groups\n",
    "fig, axs = plt.subplots(figsize=(9,4), \n",
    "                        nrows=2, ncols=rowlength,     # fix as above\n",
    "                        gridspec_kw=dict(hspace=0.4)) # Much control of gridspec\n",
    "\n",
    "targets = zip(grouped.groups.keys(), axs.flatten())\n",
    "print targets\n",
    "grouped.get_group('18-24').hist(alpha=0.4)\n",
    "#for i, (key, ax) in enumerate(targets):\n",
    "#    ax.plot(grouped.get_group(key))\n",
    "#    ax.set_title('a=%s'%str(key))\n",
    "#ax.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = data.groupby('class')\n",
    "grouped.mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "### BAR PLOTS OF MEAN VALUE OF FEATURES FOR EACH CLASS ######\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "plt.figure()\n",
    "grouped.mean().T.plot(kind='bar', figsize=(60,10))\n",
    "plt.savefig('test1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Distribution over a feature for each class #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grouped = data.groupby('class')\n",
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "#fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(6,6)) # create the axes\n",
    "j = 0\n",
    "for key in list(data.columns.values):\n",
    "#    ix = numpy.unravel_index(j, ax.shape)\n",
    "#    print ix\n",
    "    print key\n",
    "    if key!='class':\n",
    "        j += 1\n",
    "        plt.figure(j, figsize=(10,10))\n",
    "        grouped[key].plot(kind='kde', alpha=0.8, legend=grouped.groups.keys(), title=key)\n",
    "    #g = grouped[key]\n",
    "    #print grouped[key].mean()\n",
    "    #if j==1:\n",
    "    #    tmp = g.mean()\n",
    "    #else:\n",
    "    #    print g.mean()\n",
    "    #    tmp.append(g.mean())\n",
    "    #print tmp\n",
    "        plt.show()\n",
    "    #if j==2:\n",
    "    #    break\n",
    "#tmp\n",
    "    #break\n",
    "    #ax[ix] = grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "    #break\n",
    "#for key in grouped.keys:\n",
    "#    grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "#for key in grouped.groups.keys():\n",
    "#    b = grouped.get_group(key)\n",
    "#    b.plot('kin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in data_cv.iterrows():\n",
    "    print row['soac_prob_0']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.590909090909\n",
      "Confusion matrix :\n",
      " [[24 20]\n",
      " [16 28]]\n"
     ]
    }
   ],
   "source": [
    "def linear_binary_pred(pandas_frame, a, b, featx, featy, upper_class, lower_class):\n",
    "    y = []\n",
    "    # Line is: y_pred = a*x+b\n",
    "    for index, row in pandas_frame.iterrows():\n",
    "        # If over the line -> male\n",
    "        if row[featy] > a*row[featx] + b:\n",
    "            y.append(upper_class)\n",
    "        else:\n",
    "            y.append(lower_class)\n",
    "    return y\n",
    "\n",
    "predict = linear_binary_pred(data_cv, 0.5, 3, 'soac_prob_0', 'soac_prob_1', 'female', 'male')\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_cv))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014368\n",
      "         Iterations: 9\n",
      "         Function evaluations: 21\n",
      "Best Line: y=0.6750*x + 1.9250 with linear optim score: 0.98563\n",
      "Accuracy : 0.659090909091\n",
      "Confusion matrix :\n",
      " [[26 18]\n",
      " [12 32]]\n",
      "Accuracy : 0.659090909091\n",
      "Confusion matrix :\n",
      " [[26 18]\n",
      " [12 32]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize, brute\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "global data_train, y_train\n",
    "\n",
    "def f(lin):\n",
    "    #print \"Weights\"\n",
    "    #print lin\n",
    "    score = 1 - accuracy_score(y_train, linear_binary_pred(data_train, lin[0], lin[1], 'soac_prob_0', 'soac_prob_1', 'female', 'male'))\n",
    "    #print 'Score: ' + str(score)\n",
    "    return score\n",
    "\n",
    "# Linear Optimization\n",
    "lin = [0.6,2]\n",
    "options={'disp': True, 'maxiter': 1000000, 'xtol': 0.01, 'ftol': 0.1}\n",
    "minim = minimize(f, lin, args=(), method='Nelder-Mead', options=options)\n",
    "print 'Best Line: y=%0.4f*x + %0.4f with linear optim score: %0.5f' % (minim.x[0], minim.x[1], 1-minim.fun)\n",
    "predict = linear_binary_pred(data_cv, minim.x[0], minim.x[1], 'soac_prob_0', 'soac_prob_1', 'female', 'male')\n",
    "\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_train))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "\n",
    "# Brute Grid Search\n",
    "\n",
    "#rranges = [(0,1),(-10,10)]\n",
    "#minim = brute(f, rranges,args=(), Ns=100)\n",
    "#print 'Best Line: y=%0.4f*x + %0.4f with grid search score: %0.5f' % (minim[0], minim[1], 1-f(minim))\n",
    "#predict = linear_binary_pred(data_cv, minim[0], minim[1], 'soac_prob_0', 'soac_prob_1', 'female', 'male')\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_train))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_map(X, a ,b):\n",
    "    y = []\n",
    "    for x in X:\n",
    "        y.append(a*x+b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "xx = numpy.linspace(data['soac_prob_0'].min(), data['soac_prob_0'].max(), 1000)\n",
    "yy = linear_map(xx, minim.x[0],minim.x[1])\n",
    "#yy = linear_map(xx, minim[0],minim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.693181818182\n",
      "Confusion matrix :\n",
      " [[29 15]\n",
      " [12 32]]\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(a.transform(X_train),y_train)\n",
    "predict = clf.predict(a.transform(X_cv))\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=sorted(list(set(y_train))))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))\n",
    "\n",
    "w = clf.coef_[0]\n",
    "slope = -w[0] / w[1]\n",
    "yy_svm = slope * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "plt.plot(xx, yy_svm, 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RBF SCV\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rbf_svc = trained_models[0].steps[1][1]\n",
    "#rbf_svc = grid_search.best_estimator_.steps[1][1]\n",
    "gender2color = {'female':'r', 'male':'b'}\n",
    "gender2id = {'female':0, 'male':1}\n",
    "y_color = [gender2color[y]for y in list(data['class'])]\n",
    "y_id = [gender2id[y]for y in list(data['class'])]\n",
    "y_cv_id = [gender2id[y]for y in list(data_cv['class'])]\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = data['soac_prob_0'].min() - 1, data['soac_prob_0'].max() + 1\n",
    "y_min, y_max = data['soac_prob_1'].min() - 1, data['soac_prob_1'].max() + 1\n",
    "xxx, yyy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "Z = clf.predict(np.c_[xxx.ravel(), yyy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xxx.shape)\n",
    "Z = np.vectorize(gender2id.get)(Z)\n",
    "#plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "plt.contour(xxx, yyy, Z, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the convex hull of RBF CONTOUR\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "rbf_svc = trained_models[0].steps[1][1]\n",
    "#rbf_svc = grid_search.best_estimator_.steps[1][1]\n",
    "gender2color = {'female':'r', 'male':'b'}\n",
    "gender2id = {'female':0, 'male':1}\n",
    "y_color = [gender2color[y]for y in list(data['class'])]\n",
    "y_id = [gender2id[y]for y in list(data['class'])]\n",
    "y_cv_id = [gender2id[y]for y in list(data_cv['class'])]\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = data['soac_prob_0'].min() - 1, data['soac_prob_0'].max() + 1\n",
    "y_min, y_max = data['soac_prob_1'].min() - 1, data['soac_prob_1'].max() + 1\n",
    "xxx, yyy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "Z = clf.predict(np.c_[xxx.ravel(), yyy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xxx.shape)\n",
    "Z = np.vectorize(gender2id.get)(Z)\n",
    "points = np.vstack((xxx[Z.nonzero()], yyy[Z.nonzero()])).T\n",
    "hull = scipy.spatial.ConvexHull(points)\n",
    "xx_rbf = []\n",
    "yy_rbf = []\n",
    "for simplex in hull.simplices:\n",
    "    xx_rbf.extend(list(points[simplex, 0]))\n",
    "    yy_rbf.extend(list(points[simplex, 1]))\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Bogas/941.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "dffemale = data[data['class']=='female']\n",
    "dfmale = data[data['class']=='male']\n",
    "data.head(2)\n",
    "fig = {\n",
    "    'data': [\n",
    "  \t\t{\n",
    "  \t\t\t'x': data_train[data_train['class']=='female'].soac_prob_0, \n",
    "        \t'y': data_train[data_train['class']=='female'].soac_prob_1, \n",
    "            'text': data_train[data_train['class']=='female'].class_pred,\n",
    "            'marker': {'opacity': 0.6},\n",
    "        \t'mode': 'markers', \n",
    "        \t'name': 'female'},\n",
    "        {\n",
    "        \t'x': data_train[data_train['class']=='male'].soac_prob_0, \n",
    "        \t'y': data_train[data_train['class']=='male'].soac_prob_1, \n",
    "            'text': data_train[data_train['class']=='male'].class_pred,\n",
    "            'marker': {'opacity': 0.6},\n",
    "        \t'mode': 'markers', \n",
    "        \t'name': 'male'},\n",
    "        {\n",
    "  \t\t\t'x': data_cv[data_cv['class']=='female'].soac_prob_0, \n",
    "        \t'y': data_cv[data_cv['class']=='female'].soac_prob_1, \n",
    "            'text': data_cv[data_cv['class']=='female'].class_pred,\n",
    "            'marker': {'opacity': 0.6},\n",
    "        \t'mode': 'markers', \n",
    "        \t'name': 'female_test'},\n",
    "        {\n",
    "        \t'x': data_cv[data_train['class']=='male'].soac_prob_0, \n",
    "        \t'y': data_cv[data_train['class']=='male'].soac_prob_1, \n",
    "            'text': data_cv[data_cv['class']=='male'].class_pred,\n",
    "            'marker': {'opacity': 0.6},\n",
    "        \t'mode': 'markers', \n",
    "        \t'name': 'male_test'},\n",
    "        {\n",
    "            'x': xx_rbf,\n",
    "            'y': yy_rbf,\n",
    "            'mode': 'markers',\n",
    "            'fillcolor': 'black',\n",
    "            'marker': {'color': 'rgba(0, 0, 0, 1)'},\n",
    "            'name': 'SVM_RBF'\n",
    "        },\n",
    "        {\n",
    "            'x': xx,\n",
    "            'y': yy,\n",
    "            'name':'Lin_Pred'\n",
    "        },\n",
    "        {\n",
    "            'x': xx,\n",
    "            'y': xx,\n",
    "            'name':'Max_Bayes'\n",
    "        },\n",
    "        {\n",
    "            'x': xx,\n",
    "            'y': yy_svm,\n",
    "            'name':'Linear SVM'\n",
    "        },\n",
    "        #go.Contour(\n",
    "        #    z= Z,\n",
    "        #    colorscale='jet',\n",
    "        #    contours=dict(\n",
    "        #    coloring='lines',\n",
    "        #),\n",
    "        #)\n",
    "    ],\n",
    "    'layout': {\n",
    "        'xaxis': {'title': 'Complimentary Probability of Female'},\n",
    "        'yaxis': {'title': \"Complimentary Probability of Male\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# IPython notebook\n",
    "# py.iplot(fig, filename='pandas/multiple-scatter')\n",
    "py.iplot(fig, filename='Scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbf_svc = trained_models[1].steps[1][1]\n",
    "#rbf_svc = grid_search.best_estimator_.steps[1][1]\n",
    "gender2color = {'female':'r', 'male':'b'}\n",
    "gender2id = {'female':0, 'male':1}\n",
    "y_color = [gender2color[y]for y in list(data['class'])]\n",
    "y_id = [gender2id[y]for y in list(data['class'])]\n",
    "y_cv_id = [gender2id[y]for y in list(data_cv['class'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.cm.Paired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import some data to play with\n",
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = data_full['soac_prob_0'].min() - 1, data['soac_prob_0'].max() + 1\n",
    "y_min, y_max = data_full['soac_prob_1'].min() - 1, data['soac_prob_1'].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with RBF kernel']\n",
    "\n",
    "\n",
    "for i, clf in enumerate([rbf_svc]):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    Z = np.vectorize(gender2id.get)(Z)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(data['soac_prob_0'], data['soac_prob_1'], c=y_id, cmap=plt.cm.Paired)\n",
    "    plt.scatter(data_cv['soac_prob_0'], data_cv['soac_prob_1'], c=y_cv_id, s=80,cmap=plt.cm.Paired)\n",
    "    plt.xlabel('soac_0')\n",
    "    plt.ylabel('soac1')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(trained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = data['soac_prob_0'].min() - 1, data['soac_prob_0'].max() + 1\n",
    "y_min, y_max = data['soac_prob_1'].min() - 1, data['soac_prob_1'].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "\n",
    "for i, model in enumerate(trained_models+[space, Meta]):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    if hasattr(model, 'steps'):\n",
    "        clf = model.steps[1][1]\n",
    "        print clf\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    Z = np.vectorize(gender2id.get)(Z)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(data_train['soac_prob_0'], data_train['soac_prob_1'], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(model_names[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['soac_prob_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# we create 40 separable points\n",
    "rng = np.random.RandomState(0)\n",
    "n_samples_1 = 1000\n",
    "n_samples_2 = 100\n",
    "X = np.r_[1.5 * rng.randn(n_samples_1, 2),\n",
    "          0.5 * rng.randn(n_samples_2, 2) + [2, 2]]\n",
    "y = [0] * (n_samples_1) + [1] * (n_samples_2)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - clf.intercept_[0] / w[1]\n",
    "\n",
    "\n",
    "# get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10})\n",
    "wclf.fit(X, y)\n",
    "\n",
    "ww = wclf.coef_[0]\n",
    "wa = -ww[0] / ww[1]\n",
    "wyy = wa * xx - wclf.intercept_[0] / ww[1]\n",
    "\n",
    "# plot separating hyperplanes and samples\n",
    "h0 = plt.plot(xx, yy, 'k-', label='no weights')\n",
    "h1 = plt.plot(xx, wyy, 'k--', label='with weights')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.legend()\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "\n",
    "X_train = X[:.9 * n_sample]\n",
    "y_train = y[:.9 * n_sample]\n",
    "X_test = X[.9 * n_sample:]\n",
    "y_test = y[.9 * n_sample:]\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none', zorder=10)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    #plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "fig, ax = plt.subplots(nrows=nrow, ncols=ncol) # create the axes\n",
    "j = 0\n",
    "for i in feature_names: \n",
    "    ix = numpy.unravel_index(j, ax.shape)\n",
    "    #print ix\n",
    "    j += 1\n",
    "    ax[ix] = data.groupby('class').i.hist(alpha=0.4)   # go over a linear list of data # compute an appropriate index (1d or 2d)\n",
    "    #feat = feature_names[i]\n",
    "    #data.groupby('class').feat.hist(alpha=0.4, ax=ax[i])\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib outline\n",
    "plt.savefig('CameraEvolution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = grid_search.best_estimator_.steps[1][1]\n",
    "#import pydot\n",
    "import pyparsing\n",
    "\n",
    "#reload(pydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint, numpy\n",
    "from operator import itemgetter\n",
    "\n",
    "feat_importance = zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_[numpy.nonzero(clf.feature_importances_)]))\n",
    "feat_importance = sorted(feat_importance, key=itemgetter(1))[::-1]\n",
    "feat_importance\n",
    "#for i in zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_([numpy.nonzero(clf.feature_importances_)]))):\n",
    "#    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f, feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "#>>> import os\n",
    "#>>> os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydot\n",
    ">>> from IPython.display import Image  \n",
    ">>> dot_data = StringIO()  \n",
    ">>> tree.export_graphviz(clf,  out_file=dot_data,\n",
    "                         feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    ">>> graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#>>> Image(graph.create_png())   \n",
    ">>> graph.write_pdf(\"iris.pdf\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
