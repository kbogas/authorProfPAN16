{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 152 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'createDocProfiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-01dea240557b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"age\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mtictac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_recipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecipes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtictac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;31m# print results at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n--------------- Thy time of Judgement ---------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-01dea240557b>\u001b[0m in \u001b[0;36mcross_val\u001b[1;34m(dataset, task, model, num_folds)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#X, y = dataset.get_data(task)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateDocProfiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_target_prof_trainset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'createDocProfiles' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd\\n@username @username @username @username @', u'Everyday I come up with a new optimum solution. It proves optimum is only dependent on the time\\nRT @']\n"
     ]
    }
   ],
   "source": [
    "import pan\n",
    "reload(pan.preprocess)\n",
    "dataset = ProfilingDataset(infolder)\n",
    "X, y = dataset.get_data(task)\n",
    "b = [X[0][0:100]]\n",
    "b.append(X[1][0:100])\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__class__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                     \u001b[1;31m# printer registered in self.type_pprinters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                     \u001b[1;31m# deferred printer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tictacs/parse.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m                                \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                                else key, val)\n\u001b[1;32m--> 257\u001b[1;33m                               \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m                               ])\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tictacs/wrappers.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'%(__class__)s wrapping function %(function)s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__class__'"
     ]
    }
   ],
   "source": [
    "tictac.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocProfile(object):\n",
    "    \n",
    "    \"\"\" Per Document Representation. Returns an instance of a document profile.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, entry, prof_id, doc_id):\n",
    "        \"\"\" Initialization.\n",
    "            -entry : contains most information. Comes from ProfilingDataset Class.\n",
    "            -prof_id: index for intra-profile document position\n",
    "            -doc_id: index for global documend indexing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.userid = entry.userid\n",
    "        self.lang = entry.lang\n",
    "        self.media = entry.media\n",
    "        self.gender = entry.gender\n",
    "        self.age = entry.age\n",
    "        self.prof_id = prof_id\n",
    "        self.doc_id = doc_id\n",
    "        self.text = entry.texts[prof_id]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" IPython friendly output\n",
    "        :returns: str\n",
    "\n",
    "        \"\"\"\n",
    "        # automatically capture all non iterables\n",
    "        # (we want custom formatting for text list)\n",
    "        attr_string = '\\n'.join(['%s : %s' % (key, value)\n",
    "                                 for key, value in self.__dict__.items()\n",
    "                                 if not hasattr(value, '__iter__')])\n",
    "        # print a snippet\n",
    "        return attr_string\n",
    "    \n",
    "    def datafy(self, feature='none'):\n",
    "        \"\"\"Return a tuple of data - training and label if feature is not none\n",
    "\n",
    "        :feature: the feature we want the label for\n",
    "        :returns: tuple of data, label\n",
    "\n",
    "        \"\"\"\n",
    "        if feature == 'none':\n",
    "            return self.text\n",
    "        else:\n",
    "            return [self.text, self.__dict__[feature]]\n",
    "\n",
    "def createDocProfiles(dataset):\n",
    "    \"\"\" Create a list of the DocProfiles classes.\n",
    "        -dataset: ProfilingDataset Object\n",
    "        \n",
    "        returns:\n",
    "        -a list of DocProfile Objects\n",
    "    \"\"\"\n",
    "    docs = []       \n",
    "    doc_id = 0\n",
    "    for entry in dataset.entries:\n",
    "        for prof_id in range(0, len(entry.texts)):\n",
    "            docs.append(DocProfile(entry, prof_id, doc_id))\n",
    "            doc_id += 1\n",
    "    return docs\n",
    "    \n",
    "def create_target_prof_trainset(docs, target_feature):\n",
    "    \"\"\" Create a dataset according to train a specifici model regardin a certain feature.\n",
    "        Like get_data() method from ProfilingDataset class.\n",
    "        -docs: list of documents. Expects instances of class DocProfile. \n",
    "        -target_feature: filter feature\n",
    "        \n",
    "        returns:\n",
    "        (X,y) : returns tuple - list of texts, list of labels \n",
    "        \n",
    "    \"\"\"\n",
    "    wanted = []\n",
    "    for doc in docs:\n",
    "        if target_feature in doc.__dict__:\n",
    "            wanted.append(doc.datafy(feature=target_feature))\n",
    "        else:\n",
    "            raise KeyError(\"task doesn't exist in DocProfile dic()\")\n",
    "    # zip produces tuples, we want to be able to modify\n",
    "    # the contents in preprocessing in place\n",
    "    # therefore we create we replace tuples with lists using map\n",
    "    # returns tuple - list of texts, list of labels\n",
    "    return map(list, zip(*wanted))\n",
    "\n",
    "        \n",
    "docs = createDocProfiles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45,  0.5 ],\n",
       "       [ 0.55,  0.  ],\n",
       "       [ 0.25,  0.2 ],\n",
       "       [ 0.75,  0.25]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "a = [[0.25,0.25,0.25,0.25], [0.5,0,0.2,0.25], [0.2,0.3,0,0.5]]\n",
    "b = [[1,0], [0,1],[1,0]]\n",
    "numpy.dot(numpy.array(a).T,numpy.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'age'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import *\n",
    "class SOA_Model2(object):\n",
    "\n",
    "\n",
    "    \"\"\" Models that extracts Second Order Attributes (SOA) base on PAN 2013-2015 Winners\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "        \n",
    "        #stop_list = []\n",
    "        #with open(stopwords_path, 'r') as stop_inp:\n",
    "       # for w in stop_inp:\n",
    "       # stop_list.append(w.replace(\"\\n\", \"\"))\n",
    "        self.term_table = None\n",
    "        self.labels = None\n",
    "        #self.counter = CountVectorizer()\n",
    "        self.counter = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy\n",
    "        from math import log\n",
    "        \n",
    "        if y:\n",
    "            #tokens = [_twokenize.tokenizeRawTweetText(text) for text in X]\n",
    "            #voc = set()\n",
    "            #for token in tokens:\n",
    "            #    voc = voc.union(token)\n",
    "            #print len(voc)\n",
    "            #print list(voc)[:100]\n",
    "            parameters = {\n",
    "                'input':'content', \n",
    "                'encoding':'utf-8', \n",
    "                'decode_error':'ignore', \n",
    "                #'vocabulary':list(voc),\n",
    "                'tokenizer':lambda text:_twokenize.tokenizeRawTweetText(text)\n",
    "                #'max_df':0.9,\n",
    "                #'min_df':5\n",
    "                #'max_features':20000\n",
    "               }\n",
    "            self.counter.set_params(**parameters) \n",
    "            #print \"Oleeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
    "            #print texts\n",
    "            #print tokens\n",
    "            #print list(voc)\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            print len(target_profiles)\n",
    "            #return\n",
    "            doc_term = self.counter.fit_transform(X)\n",
    "            print \"Doc_Terms\"\n",
    "            print doc_term.shape\n",
    "            #return \n",
    "            #X1 = X.toarray()\n",
    "            #X1 = X1.astype('float', casting='unsafe')\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            self.labels = target_profiles\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], len(target_profiles)])\n",
    "            for i in range(0, doc_term.shape[0]):\n",
    "                tmp = numpy.zeros([1,len(target_profiles)])\n",
    "                tmp[0, target_profiles.index(y[i])] = 1\n",
    "                doc_prof[i,:] = tmp\n",
    "            print \"Doc_Prof\"\n",
    "            print doc_prof.shape\n",
    "            term_prof = numpy.zeros([doc_term.shape[1], len(target_profiles)])\n",
    "            term_prof = numpy.dot(numpy.log2(doc_term.toarray().astype('float', casting='unsafe').T + 1), doc_prof)\n",
    "            print \"Term_Prof\"\n",
    "            print term_prof.shape\n",
    "            term_prof = term_prof / numpy.reshape(term_prof.sum(axis=1), (term_prof.sum(axis=1).shape[0], 1))\n",
    "            #term_prof = term_prof / term_prof.sum(axis=0)\n",
    "            self.term_table = term_prof\n",
    "            print \"GG\"\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        if self.labels==None:\n",
    "            raise AttributeError('term_table was no found! Probably model was not fitted first. Run model.fit(X,y)!')\n",
    "        else:\n",
    "            doc_term = self.counter.transform(X)\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], self.term_table.shape[1]])\n",
    "            doc_prof = numpy.dot(doc_term.toarray().astype('float', casting='unsafe'), self.term_table)\n",
    "            return doc_prof\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        doc_prof = self.transform(X)\n",
    "        y_pred = []\n",
    "        for i in range(0, doc_prof.shape[0]):\n",
    "            y_pred.append(self.labels[numpy.argmax(doc_prof[i])])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Doc_Terms\n",
      "(14166, 28850)\n",
      "Doc_Prof\n",
      "(14166, 4)\n",
      "Term_Prof\n",
      "(28850, 4)\n",
      "GG\n"
     ]
    }
   ],
   "source": [
    "from pan.misc import _twokenize\n",
    "import pan\n",
    "reload(pan)\n",
    "c = SOA_Model2()\n",
    "c.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = c.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in c.counter.vocabulary_.iteritems():\n",
    "    if v>8000 and v< 9000:\n",
    "        pass\n",
    "        #print k, v\n",
    "top_words = [[] for i in range(0, c.term_table.shape[1])]\n",
    "cc= 0\n",
    "for i in range(0, c.term_table.shape[0]):\n",
    "    if max(c.term_table[i]) > 0.7:\n",
    "        #print c.term_table[i], c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)]\n",
    "        top_words[list(c.term_table[i]).index(max(c.term_table[i]))].append(c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)])\n",
    "        cc += 1\n",
    "top_words\n",
    "        #c.term_table /= c.term_table[8411].sum(axis= 0)\n",
    "#c.term_table[8411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  0. ,  0.5],\n",
       "       [ 0. ,  0. ,  1. ,  0. ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "tmp = numpy.zeros([2,4])\n",
    "tmp[0,1]=1\n",
    "tmp[0,3]= 1\n",
    "tmp[1,2] = 1\n",
    "tmp / numpy.reshape(tmp.sum(axis=1), (tmp.sum(axis=1).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Doc_Terms\n",
      "(14166, 28850)\n",
      "Doc_Prof\n",
      "(14166, 4)\n",
      "Term_Prof\n",
      "(28850, 4)\n",
      "Model Fitted!\n"
     ]
    }
   ],
   "source": [
    "import pan\n",
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model2()\n",
    "c.fit_transform(X, y)\n",
    "a = [\"I am very good!\"]\n",
    "#c.transform(X, y)\n",
    "#from pprint import pprint\n",
    "#pprint(dataset.get_data()[0])\n",
    "#pprint(dataset.entries[0].texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  7.]]\n",
      "[[ 0.33333333  0.66666667]\n",
      " [ 0.42857143  0.57142857]]\n",
      "[[ 0.25        0.33333333]\n",
      " [ 0.75        0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "aaa = numpy.asarray([[1, 2], [3, 4]], dtype=float)\n",
    "bb = aaa.sum(axis=1)\n",
    "print numpy.reshape(bb, (1,2))\n",
    "print aaa/numpy.reshape(bb, (bb.shape[0],1))\n",
    "print aaa/aaa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci-kit\n",
      "[[ 0.07142857  0.07142857  0.28571429  0.07142857  0.07142857  0.07142857\n",
      "   0.07142857  0.07142857  0.07142857  0.07142857  0.07142857]\n",
      " [ 0.07142857  0.07142857  0.28571429  0.07142857  0.07142857  0.07142857\n",
      "   0.07142857  0.07142857  0.07142857  0.07142857  0.07142857]]\n",
      "[[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]]\n",
      "[[ 14.]\n",
      " [ 14.]]\n",
      "[ 5.09901951  5.09901951]\n",
      "[[ 0.14285714  0.14285714  0.57142857  0.14285714  0.14285714  0.14285714\n",
      "   0.14285714  0.14285714  0.14285714  0.14285714  0.14285714]]\n",
      "[[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import normalize\n",
    "aaa = numpy.asarray([[1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "print \"sci-kit\"\n",
    "cc = normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(cc, axis=0, norm='l1')\n",
    "print numpy.sum(aaa,axis=1, keepdims=True)\n",
    "print numpy.linalg.norm(aaa, axis=1)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=1, keepdims=True), dtype=float)\n",
    "print numpy.sum(aaa,axis=0, keepdims=True)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=0, keepdims=True), dtype=float)\n",
    "print aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pan\n",
    "reload(pan.features)\n",
    "log = []\n",
    "#import logging\n",
    "#log = logging.getLogger()\n",
    "#log.setLevel(logging.INFO)\n",
    "#log.addHandler(logging.StreamHandler())\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "modelfile\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    if task == \"age\":\n",
    "        X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)\n",
    "print('Writing model to {}'.format(modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tictacs\n",
    "tictacs.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-50feede7335e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "a.add(2)\n",
    "a.add(3)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd\n",
      "@username @username @username @username @\n",
      "\n",
      "{u'username': 10, u'jtrdxtnd': 6, u'http': 4, u'for': 2, u'how': 3, u'startup': 7, u'idea': 5, u'50': 0, u'to': 9, u'test': 8, u'co': 1, u'your': 11}\n",
      "11\n",
      "Oleeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "types\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "values\n",
      "shape:\n",
      "(1, 12)\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model()\n",
    "a = [\"I am very good!\"]\n",
    "#aa = c.fit_transform(a)\n",
    "print b\n",
    "c.fit([b])\n",
    "print aa\n",
    "print c.counter.vocabulary_\n",
    "kk = c.transform([b])\n",
    "print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "            \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    " # remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "from pprint import pprint   # pretty-printer\n",
    "pprint(texts)\n",
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "INFO:gensim.models.ldamodel:topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer',\n",
       " u'0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey',\n",
       " u'0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees',\n",
       " u'0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps',\n",
       " u'0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "model = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.631169731543713"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16666667         nan]\n",
      " [ 0.83333333         nan]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "all_models = {}\n",
    "docs = createDocProfiles(dataset)\n",
    "for task in tasks:\n",
    "    if task =='age':\n",
    "        print('Learning to judge %s..' % task)\n",
    "        # load data\n",
    "        X, y = create_target_prof_trainset(docs, task)\n",
    "        #X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model =gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100, minimum_probability=0)\n",
    "a = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "lsi[corpus[2]]\n",
    "import numpy\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.33498192e-01  -1.05089526e-01]\n",
      " [  2.03199237e+00   4.71453141e-02]\n",
      " [  1.53513428e+00  -1.34887841e-01]\n",
      " [  1.95400772e+00  -2.17804986e-01]\n",
      " [  1.29024730e+00   2.25214375e-03]\n",
      " [  2.27830819e-02   7.77805260e-01]\n",
      " [  5.67156758e-02   1.18277034e+00]\n",
      " [  1.23600033e-01   2.63430686e+00]\n",
      " [  2.35606272e-01   9.40793620e-01]]\n"
     ]
    }
   ],
   "source": [
    "c = lsi[corpus]\n",
    "l = [list(zip(*cc)[1]) for cc in c]\n",
    "#l = []\n",
    "#for cc in c:\n",
    "    #print cc\n",
    "#    l.append(list(zip(*cc)[1]))\n",
    "print numpy.array(l)\n",
    "    #print list(zip(*cc)[1])\n",
    "    #for k in cc:\n",
    "    #    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Task:age, Pipeline:clean html+detwittify+3grams+soa_model+svm\n",
      "\n",
      "Creating model for en - age\n",
      "Trainining instances: 436\n",
      "\n",
      "Using 4 fold validation\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  2.0min remaining:  -24.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  2.4min remaining:  -28.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  2.6min remaining:  -31.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  2.6min finished\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(328, 16869)\n",
      "(326, 15803)\n",
      "(326, 16338)\n",
      "(328, 16922)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(328, 16869) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 15803) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 16338) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16922) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(16869, 5) <type 'numpy.ndarray'>\n",
      "(15803, 5) <type 'numpy.ndarray'>\n",
      "(16338, 5) <type 'numpy.ndarray'>\n",
      "(16922, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.11381009  0.21871329  0.11842051  0.32757622  0.22147989]\n",
      "[ 0.09137995  0.17525753  0.13927527  0.34455378  0.24953348]\n",
      "[ 0.10422603  0.36144616  0.21477427  0.31955353  0.        ]\n",
      "[ 0.07834422  0.21757473  0.14706788  0.34090986  0.21610331]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(328, 16869) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 15803) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 16338) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16922) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "Len Voc: 16869\n",
      "Len Voc: 15803\n",
      "Len Voc: 16338\n",
      "Len Voc: 16922\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(108, 16869) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(110, 15803) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(110, 16338) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(108, 16922) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "Len Voc: 16869\n",
      "Len Voc: 15803\n",
      "Len Voc: 16338\n",
      "Len Voc: 16922\n",
      "\n",
      "(436, 19902)\n",
      "Doc_Prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(19902, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.09622991  0.2293526   0.14707442  0.33196514  0.19537794]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Len Voc: 19902\n",
      "[mean: 0.46560, std: 0.04954, params: {}]\n",
      "Task:gender, Pipeline:clean html+detwittify+soa model+svm\n",
      "\n",
      "Creating model for en - gender\n",
      "Trainining instances: 436\n",
      "\n",
      "Using 4 fold validation\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  1.9min remaining:  -23.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  1.9min remaining:  -23.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   4 | elapsed:  2.0min remaining:  -23.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  2.0min finished\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(326, 16262)\n",
      "(326, 16070)\n",
      "(328, 16735)\n",
      "(328, 16905)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(326, 2) <type 'numpy.ndarray'>\n",
      "(326, 2) <type 'numpy.ndarray'>\n",
      "(328, 2) <type 'numpy.ndarray'>\n",
      "(328, 2) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(326, 16262) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 16070) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16735) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16905) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(16262, 2) <type 'numpy.ndarray'>\n",
      "(16070, 2) <type 'numpy.ndarray'>\n",
      "(16735, 2) <type 'numpy.ndarray'>\n",
      "(16905, 2) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.58110425  0.41889575]\n",
      "[ 0.54854169  0.45145831]\n",
      "[ 0.6605806  0.3394194]\n",
      "[ 0.66124399  0.33875601]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(326, 16262) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(326, 16070) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16735) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(328, 16905) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(326, 2) <type 'numpy.ndarray'>\n",
      "(326, 2) <type 'numpy.ndarray'>\n",
      "(328, 2) <type 'numpy.ndarray'>\n",
      "(328, 2) <type 'numpy.ndarray'>\n",
      "Len Voc: 16262\n",
      "Len Voc: 16070\n",
      "Len Voc: 16735\n",
      "Len Voc: 16905\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(110, 16262) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(110, 16070) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(108, 16735) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(108, 16905) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(110, 2) <type 'numpy.ndarray'>\n",
      "(110, 2) <type 'numpy.ndarray'>\n",
      "(108, 2) <type 'numpy.ndarray'>\n",
      "(108, 2) <type 'numpy.ndarray'>\n",
      "Len Voc: 16262\n",
      "Len Voc: 16070\n",
      "Len Voc: 16735\n",
      "Len Voc: 16905\n",
      "\n",
      "(436, 19902)\n",
      "Doc_Prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(19902, 2) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.61705318  0.38294682]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "Len Voc: 19902\n",
      "[mean: 0.72706, std: 0.03444, params: {}]\n",
      "\n",
      "--------------- Thy time of Judgement ---------------\n",
      "Time: 553.212698936 seconds.\n",
      "\n",
      "\n",
      "Results for en - age with classifier Tictac\n",
      "best params: {}\n",
      "Accuracy mean : 0.465596330275\n",
      "\n",
      "Results for en - gender with classifier Tictac\n",
      "best params: {}\n",
      "Accuracy mean : 0.727064220183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from tictacs import from_recipe\n",
    "from json import dumps\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if (task != \"age\") and (task !=\"gender\"):\n",
    "    #    X, y = dataset.get_data(task)\n",
    "    # else:\n",
    "    #    docs = createDocProfiles(dataset)\n",
    "    #    X, y = create_target_prof_trainset(docs, task)\n",
    "    X, y = dataset.get_data(task)\n",
    "    # y = [yy.lower() for yy in y]\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    # from collections import Counter\n",
    "    # import pprint\n",
    "    # pprint.pprint(Counter(y))\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Trainining instances: %s\\n' % (len(X))\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    log.append('\\nResults for %s - %s with classifier %s' %\n",
    "               (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        # y_pred = grid_cv.best_estimator_.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(y)\n",
    "        # conf = confusion_matrix(y, y_pred, labels=list(set(y)))\n",
    "        accuracy = grid_cv.best_score_\n",
    "        # accuracy2 = accuracy_score(y, y_pred)\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "        import pprint\n",
    "        pprint.pprint(grid_cv.grid_scores_)\n",
    "        with open('./comb_res/res.txt', 'a') as out:\n",
    "            out.write(' Results: %s - %s, params: %s ,Accuracy_Mean: %s\\n' %\n",
    "                      (dataset.lang, task,\n",
    "                       dumps(grid_cv.best_params_), grid_cv.best_score_))\n",
    "        # log.append('Best accuracy: {} '.format(accuracy2))\n",
    "        # log.append('Best Confusion matrix :\\n {}'.format(conf))\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        raise KeyError('task %s was not found in task list!' % task)\n",
    "\n",
    "\n",
    "\n",
    "infolder = '../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/'\n",
    "num_folds = 4\n",
    "time_start = time.time()\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    import pprint\n",
    "    #pprint.pprint(tictac.__dict__)\n",
    "    #exit(1)\n",
    "    steps = tictac.steps\n",
    "    #print type(steps)\n",
    "    #pprint.pprint(steps)\n",
    "    outline = \"\"\n",
    "    for step in steps:\n",
    "        if step[0]==\"features\":\n",
    "            # print type(step[1])\n",
    "            for tf in step[1].transformer_list:\n",
    "                outline += tf[0] + \"+\"\n",
    "        else:\n",
    "            outline += step[0]+ \"+\"\n",
    "    outline = outline[:-1]\n",
    "    print('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    with open('./comb_res/res.txt', 'a') as out:\n",
    "        out.write('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    cross_val(dataset, task, tictac, num_folds)\n",
    "# print results at end\n",
    "print('\\n--------------- Thy time of Judgement ---------------')\n",
    "print ('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "with open('./comb_res/res.txt', 'a') as out:\n",
    "        out.write('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "for message in log:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_cleanup',\n",
       " '__module__',\n",
       " '__repr__',\n",
       " 'load_recipe',\n",
       " '__reduce__',\n",
       " '__doc__',\n",
       " '__init__']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "dill.pickles(tictac)\n",
    "dill.detect.badtypes(tictac).__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "We are fitting!\n",
      "Doc_Terms\n",
      "(436, 19902)\n",
      "Doc_Prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(19902, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.09622991  0.2293526   0.14707442  0.33196514  0.19537794]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Len Voc: 19902\n",
      "Learning to judge gender..\n",
      "We are fitting!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.py:717: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  if limit is not None and mask.sum() > limit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doc_Terms\n",
      "(436, 19902)\n",
      "Doc_Prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(19902, 2) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.61705318  0.38294682]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(436, 19902) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "Len Voc: 19902\n",
      "Writing model to models/en2.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/en2.bin']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### TRAIN ############\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    all_models[task] = tictac.fit(X, y)\n",
    "modelfile = os.path.join(outfolder, '%s2.bin' % dataset.lang)\n",
    "print('Writing model to {}'.format(modelfile))\n",
    "#fo = open(modelfile,  'wb')\n",
    "#import pprint\n",
    "#print type(all_models)\n",
    "#print modelfile\n",
    "#dill.dump(all_models, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#fo.close()\n",
    "# pickle.dump(all_models, modelfile)\n",
    "# dill.dump(all_models, modelfile)\n",
    "joblib.dump(all_models, modelfile, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
