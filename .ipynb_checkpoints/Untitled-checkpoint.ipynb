{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.preprocess)\n",
    "dataset = ProfilingDataset(infolder)\n",
    "X, y = dataset.get_data(task)\n",
    "b = [X[0][0:100]]\n",
    "b.append(X[1][0:100])\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tictac.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocProfile(object):\n",
    "    \n",
    "    \"\"\" Per Document Representation. Returns an instance of a document profile.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, entry, prof_id, doc_id):\n",
    "        \"\"\" Initialization.\n",
    "            -entry : contains most information. Comes from ProfilingDataset Class.\n",
    "            -prof_id: index for intra-profile document position\n",
    "            -doc_id: index for global documend indexing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.userid = entry.userid\n",
    "        self.lang = entry.lang\n",
    "        self.media = entry.media\n",
    "        self.gender = entry.gender\n",
    "        self.age = entry.age\n",
    "        self.prof_id = prof_id\n",
    "        self.doc_id = doc_id\n",
    "        self.text = entry.texts[prof_id]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" IPython friendly output\n",
    "        :returns: str\n",
    "\n",
    "        \"\"\"\n",
    "        # automatically capture all non iterables\n",
    "        # (we want custom formatting for text list)\n",
    "        attr_string = '\\n'.join(['%s : %s' % (key, value)\n",
    "                                 for key, value in self.__dict__.items()\n",
    "                                 if not hasattr(value, '__iter__')])\n",
    "        # print a snippet\n",
    "        return attr_string\n",
    "    \n",
    "    def datafy(self, feature='none'):\n",
    "        \"\"\"Return a tuple of data - training and label if feature is not none\n",
    "\n",
    "        :feature: the feature we want the label for\n",
    "        :returns: tuple of data, label\n",
    "\n",
    "        \"\"\"\n",
    "        if feature == 'none':\n",
    "            return self.text\n",
    "        else:\n",
    "            return [self.text, self.__dict__[feature]]\n",
    "\n",
    "def createDocProfiles(dataset):\n",
    "    \"\"\" Create a list of the DocProfiles classes.\n",
    "        -dataset: ProfilingDataset Object\n",
    "        \n",
    "        returns:\n",
    "        -a list of DocProfile Objects\n",
    "    \"\"\"\n",
    "    docs = []       \n",
    "    doc_id = 0\n",
    "    for entry in dataset.entries:\n",
    "        for prof_id in range(0, len(entry.texts)):\n",
    "            docs.append(DocProfile(entry, prof_id, doc_id))\n",
    "            doc_id += 1\n",
    "    return docs\n",
    "    \n",
    "def create_target_prof_trainset(docs, target_feature):\n",
    "    \"\"\" Create a dataset according to train a specifici model regardin a certain feature.\n",
    "        Like get_data() method from ProfilingDataset class.\n",
    "        -docs: list of documents. Expects instances of class DocProfile. \n",
    "        -target_feature: filter feature\n",
    "        \n",
    "        returns:\n",
    "        (X,y) : returns tuple - list of texts, list of labels \n",
    "        \n",
    "    \"\"\"\n",
    "    wanted = []\n",
    "    for doc in docs:\n",
    "        if target_feature in doc.__dict__:\n",
    "            wanted.append(doc.datafy(feature=target_feature))\n",
    "        else:\n",
    "            raise KeyError(\"task doesn't exist in DocProfile dic()\")\n",
    "    # zip produces tuples, we want to be able to modify\n",
    "    # the contents in preprocessing in place\n",
    "    # therefore we create we replace tuples with lists using map\n",
    "    # returns tuple - list of texts, list of labels\n",
    "    return map(list, zip(*wanted))\n",
    "\n",
    "        \n",
    "docs = createDocProfiles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = [[0.25,0.25,0.25,0.25], [0.5,0,0.2,0.25], [0.2,0.3,0,0.5]]\n",
    "b = [[1,0], [0,1],[1,0]]\n",
    "numpy.dot(numpy.array(a).T,numpy.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'age'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import *\n",
    "class SOA_Model2(object):\n",
    "\n",
    "\n",
    "    \"\"\" Models that extracts Second Order Attributes (SOA) base on PAN 2013-2015 Winners\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "        \n",
    "        #stop_list = []\n",
    "        #with open(stopwords_path, 'r') as stop_inp:\n",
    "       # for w in stop_inp:\n",
    "       # stop_list.append(w.replace(\"\\n\", \"\"))\n",
    "        self.term_table = None\n",
    "        self.labels = None\n",
    "        #self.counter = CountVectorizer()\n",
    "        self.counter = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy\n",
    "        from math import log\n",
    "        \n",
    "        if y:\n",
    "            #tokens = [_twokenize.tokenizeRawTweetText(text) for text in X]\n",
    "            #voc = set()\n",
    "            #for token in tokens:\n",
    "            #    voc = voc.union(token)\n",
    "            #print len(voc)\n",
    "            #print list(voc)[:100]\n",
    "            parameters = {\n",
    "                'input':'content', \n",
    "                'encoding':'utf-8', \n",
    "                'decode_error':'ignore', \n",
    "                #'vocabulary':list(voc),\n",
    "                'tokenizer':lambda text:_twokenize.tokenizeRawTweetText(text)\n",
    "                #'max_df':0.9,\n",
    "                #'min_df':5\n",
    "                #'max_features':20000\n",
    "               }\n",
    "            self.counter.set_params(**parameters) \n",
    "            #print \"Oleeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
    "            #print texts\n",
    "            #print tokens\n",
    "            #print list(voc)\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            print len(target_profiles)\n",
    "            #return\n",
    "            doc_term = self.counter.fit_transform(X)\n",
    "            print \"Doc_Terms\"\n",
    "            print doc_term.shape\n",
    "            #return \n",
    "            #X1 = X.toarray()\n",
    "            #X1 = X1.astype('float', casting='unsafe')\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            self.labels = target_profiles\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], len(target_profiles)])\n",
    "            for i in range(0, doc_term.shape[0]):\n",
    "                tmp = numpy.zeros([1,len(target_profiles)])\n",
    "                tmp[0, target_profiles.index(y[i])] = 1\n",
    "                doc_prof[i,:] = tmp\n",
    "            print \"Doc_Prof\"\n",
    "            print doc_prof.shape\n",
    "            term_prof = numpy.zeros([doc_term.shape[1], len(target_profiles)])\n",
    "            term_prof = numpy.dot(numpy.log2(doc_term.toarray().astype('float', casting='unsafe').T + 1), doc_prof)\n",
    "            print \"Term_Prof\"\n",
    "            print term_prof.shape\n",
    "            term_prof = term_prof / numpy.reshape(term_prof.sum(axis=1), (term_prof.sum(axis=1).shape[0], 1))\n",
    "            #term_prof = term_prof / term_prof.sum(axis=0)\n",
    "            self.term_table = term_prof\n",
    "            print \"GG\"\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        if self.labels==None:\n",
    "            raise AttributeError('term_table was no found! Probably model was not fitted first. Run model.fit(X,y)!')\n",
    "        else:\n",
    "            doc_term = self.counter.transform(X)\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], self.term_table.shape[1]])\n",
    "            doc_prof = numpy.dot(doc_term.toarray().astype('float', casting='unsafe'), self.term_table)\n",
    "            return doc_prof\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        doc_prof = self.transform(X)\n",
    "        y_pred = []\n",
    "        for i in range(0, doc_prof.shape[0]):\n",
    "            y_pred.append(self.labels[numpy.argmax(doc_prof[i])])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import _twokenize\n",
    "import pan\n",
    "reload(pan)\n",
    "c = SOA_Model2()\n",
    "c.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = c.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in c.counter.vocabulary_.iteritems():\n",
    "    if v>8000 and v< 9000:\n",
    "        pass\n",
    "        #print k, v\n",
    "top_words = [[] for i in range(0, c.term_table.shape[1])]\n",
    "cc= 0\n",
    "for i in range(0, c.term_table.shape[0]):\n",
    "    if max(c.term_table[i]) > 0.7:\n",
    "        #print c.term_table[i], c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)]\n",
    "        top_words[list(c.term_table[i]).index(max(c.term_table[i]))].append(c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)])\n",
    "        cc += 1\n",
    "top_words\n",
    "        #c.term_table /= c.term_table[8411].sum(axis= 0)\n",
    "#c.term_table[8411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "tmp = numpy.zeros([2,4])\n",
    "tmp[0,1]=1\n",
    "tmp[0,3]= 1\n",
    "tmp[1,2] = 1\n",
    "tmp / numpy.reshape(tmp.sum(axis=1), (tmp.sum(axis=1).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model2()\n",
    "c.fit_transform(X, y)\n",
    "a = [\"I am very good!\"]\n",
    "#c.transform(X, y)\n",
    "#from pprint import pprint\n",
    "#pprint(dataset.get_data()[0])\n",
    "#pprint(dataset.entries[0].texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "aaa = numpy.asarray([[1, 2], [3, 4]], dtype=float)\n",
    "bb = aaa.sum(axis=1)\n",
    "print numpy.reshape(bb, (1,2))\n",
    "print aaa/numpy.reshape(bb, (bb.shape[0],1))\n",
    "print aaa/aaa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import normalize\n",
    "aaa = numpy.asarray([[1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "print \"sci-kit\"\n",
    "cc = normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(cc, axis=0, norm='l1')\n",
    "print numpy.sum(aaa,axis=1, keepdims=True)\n",
    "print numpy.linalg.norm(aaa, axis=1)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=1, keepdims=True), dtype=float)\n",
    "print numpy.sum(aaa,axis=0, keepdims=True)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=0, keepdims=True), dtype=float)\n",
    "print aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pan\n",
    "reload(pan.features)\n",
    "log = []\n",
    "#import logging\n",
    "#log = logging.getLogger()\n",
    "#log.setLevel(logging.INFO)\n",
    "#log.addHandler(logging.StreamHandler())\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "modelfile\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    if task == \"age\":\n",
    "        X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)\n",
    "print('Writing model to {}'.format(modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tictacs\n",
    "tictacs.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "a.add(2)\n",
    "a.add(3)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model()\n",
    "a = [\"I am very good!\"]\n",
    "#aa = c.fit_transform(a)\n",
    "print b\n",
    "c.fit([b])\n",
    "print aa\n",
    "print c.counter.vocabulary_\n",
    "kk = c.transform([b])\n",
    "print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "            \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    " # remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "from pprint import pprint   # pretty-printer\n",
    "pprint(texts)\n",
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "model = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pow(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "all_models = {}\n",
    "docs = createDocProfiles(dataset)\n",
    "for task in tasks:\n",
    "    if task =='age':\n",
    "        print('Learning to judge %s..' % task)\n",
    "        # load data\n",
    "        X, y = create_target_prof_trainset(docs, task)\n",
    "        #X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model =gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100, minimum_probability=0)\n",
    "a = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "lsi[corpus[2]]\n",
    "import numpy\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = lsi[corpus]\n",
    "l = [list(zip(*cc)[1]) for cc in c]\n",
    "#l = []\n",
    "#for cc in c:\n",
    "    #print cc\n",
    "#    l.append(list(zip(*cc)[1]))\n",
    "print numpy.array(l)\n",
    "    #print list(zip(*cc)[1])\n",
    "    #for k in cc:\n",
    "    #    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan.features\n",
    "reload(pan.features)\n",
    "pan.features.TWCNB.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from tictacs import from_recipe\n",
    "from json import dumps\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if (task != \"age\") and (task !=\"gender\"):\n",
    "    #    X, y = dataset.get_data(task)\n",
    "    # else:\n",
    "    #    docs = createDocProfiles(dataset)\n",
    "    #    X, y = create_target_prof_trainset(docs, task)\n",
    "    X, y = dataset.get_data(task)\n",
    "    # y = [yy.lower() for yy in y]\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    # from collections import Counter\n",
    "    # import pprint\n",
    "    # pprint.pprint(Counter(y))\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Trainining instances: %s\\n' % (len(X))\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    log.append('\\nResults for %s - %s with classifier %s' %\n",
    "               (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        # y_pred = grid_cv.best_estimator_.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(y)\n",
    "        # conf = confusion_matrix(y, y_pred, labels=list(set(y)))\n",
    "        accuracy = grid_cv.best_score_\n",
    "        # accuracy2 = accuracy_score(y, y_pred)\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "        import pprint\n",
    "        pprint.pprint(grid_cv.grid_scores_)\n",
    "        with open('./comb_res/res.txt', 'a') as out:\n",
    "            out.write(' Results: %s - %s, params: %s ,Accuracy_Mean: %s\\n' %\n",
    "                      (dataset.lang, task,\n",
    "                       dumps(grid_cv.best_params_), grid_cv.best_score_))\n",
    "        # log.append('Best accuracy: {} '.format(accuracy2))\n",
    "        # log.append('Best Confusion matrix :\\n {}'.format(conf))\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        raise KeyError('task %s was not found in task list!' % task)\n",
    "\n",
    "\n",
    "\n",
    "infolder = '../DATA/pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/'\n",
    "num_folds = 3\n",
    "time_start = time.time()\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    import pprint\n",
    "    #pprint.pprint(tictac.__dict__)\n",
    "    #exit(1)\n",
    "    steps = tictac.steps\n",
    "    #print type(steps)\n",
    "    outline = \"\"\n",
    "    for step in steps:\n",
    "        if step[0]==\"features\":\n",
    "            # print type(step[1])\n",
    "            for tf in step[1].transformer_list:\n",
    "                #print type(tf[1])\n",
    "                #print type(tf[1].get_params())\n",
    "                outline += tf[0] + \" with Params:[\" + str(tf[1].get_params()) + \"]+\"\n",
    "        else:\n",
    "#            if hasattr(step[1], 'get_params'):\n",
    "#                outline += step[0] + \" with Params:[\" + str(step[1].get_params()) + \"]+\"\n",
    "#            else:\n",
    "#                outline += step[0]+ \"+\"\n",
    "            outline += step[0]+ \"+\"\n",
    "    outline = outline[:-1] + \"\\n\"\n",
    "    print('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    with open('./comb_res/res.txt', 'a') as out:\n",
    "        out.write('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    cross_val(dataset, task, tictac, num_folds)\n",
    "# print results at end\n",
    "print('\\n--------------- Thy time of Judgement ---------------')\n",
    "print ('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "with open('./comb_res/res.txt', 'a') as out:\n",
    "    out.write('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "for message in log:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.pickles(tictac)\n",
    "dill.detect.badtypes(tictac).__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### TRAIN ############\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    all_models[task] = tictac.fit(X, y)\n",
    "modelfile = os.path.join(outfolder, '%s2.bin' % dataset.lang)\n",
    "print('Writing model to {}'.format(modelfile))\n",
    "#fo = open(modelfile,  'wb')\n",
    "#import pprint\n",
    "#print type(all_models)\n",
    "#print modelfile\n",
    "#dill.dump(all_models, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#fo.close()\n",
    "# pickle.dump(all_models, modelfile)\n",
    "# dill.dump(all_models, modelfile)\n",
    "joblib.dump(all_models, modelfile, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "a = numpy.array([[1,2],[3,4]], dtype=float)\n",
    "b = numpy.array([[0.1,0.2],[0.3,0.4]], dtype=float)\n",
    "type(a[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "print a.shape\n",
    "b = numpy.tile(a, (5, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = b.sum(axis=1)\n",
    "print c.shape, type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import pprint\n",
    "pprint.pprint(a)\n",
    "normalize(a, norm='l1', axis=1, copy=False)\n",
    "pprint.pprint(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "Learning to judge gender..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 436\n",
      "Counter({'35-49': 182, '25-34': 140, '50-64': 80, '18-24': 28, '65-xx': 6})\n",
      "436\n",
      "87 87 262 436\n",
      "Counter({'35-49': 182, '25-34': 140, '50-64': 80, '18-24': 28, '65-xx': 6})\n",
      "Counter({'35-49': 36, '25-34': 28, '50-64': 16, '18-24': 6, '65-xx': 1})\n",
      "Counter({'35-49': 37, '25-34': 28, '50-64': 16, '18-24': 5, '65-xx': 1})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "import pprint\n",
    "print \"Num of samples: \" + str(len(y))\n",
    "pprint.pprint(Counter(y))\n",
    "X, y = dataset.get_data('age')\n",
    "print len(X)\n",
    "\n",
    "X, X_cv, X, y_cv = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.5, random_state=42, stratify=y_cv)\n",
    "\n",
    "print len(X_cv), len(X_test), len(X) , len(X)+ len(X_cv) + len(X_test)\n",
    "pprint.pprint(Counter(y))\n",
    "pprint.pprint(Counter(y_cv))\n",
    "pprint.pprint(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "    -Cleaning html\n",
      "    -Detwittifying\n",
      "    -Removing Numbers\n",
      "    -Removing Punctuation\n",
      "    -Removing Links\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "X, y = dataset.get_data('age')\n",
    "#X, y = dataset.get_data('gender')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams+soa+soac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smo...ulary=None)), ('soa', SOA_Model2(max_df=1.0, max_features=None, min_df=5, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + SOA+SOAC. Ommit preprocess!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Complementary of SOA model 22'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(features)\n",
    "features.SOAC_Model2.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3grams',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "scaler = StandardScaler()#MinMaxScaler()#StandardScaler()\n",
    "#svm = DecisionTreeClassifier()\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe = Pipeline([('3grams', grams3), ('svm', svm)])\n",
    "#pipe = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pan.features import LDA\n",
    "\n",
    "LDAmodel = LDA(num_topics=30, lib='sklearn')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "#svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced')\n",
    "svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('LDA', LDAmodel)])#, ('soa', soa), ('soac', soac)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDAA = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1]\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\" \".join([feature_names[i]\n",
    "        #                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "#print_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "     \n",
    "    feat = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        feat.append(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\"#%d: \" % topic_idx + topic_words)\n",
    "    return feat\n",
    "get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "print len(feature_names)\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "feature_names = copy.deepcopy(countTokens.l)\n",
    "feature_names += ['numHash', 'numUrl', 'numRep']\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(countTokens.l), len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "#features.SOAC_Model2.__doc__\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "#y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = [#\"I like playing video games very much :).\", \n",
    "     #\"Football games are the best!\",\n",
    "     #\"Being young forever is very funny and entertaining\",\n",
    "     # \"Football games are the best!\",\n",
    "      \"best games\",\n",
    "      \"best games\",\n",
    "     #\"World leaders should gather and decide for todays meeting!\",\n",
    "     #\"Problems nowadays seem to thrive everywhere\",\n",
    "     #\"Just got off from work today! Weekend is coming though, so it's alright...\",\n",
    "     #\"This weekend we are going of for 3 days..\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\"]\n",
    "yy = [\"18-24\",\n",
    "     \"18-24\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "    ]\n",
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "XX = preprocess.preprocess(XX)\n",
    "num_folds = 2\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(XX,yy)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = soac.fit_transform(X[0:10], y[0:10])\n",
    "print xx\n",
    "print y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
       "        tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soac', soac)])\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soa', SOA_Model2(max_df=1.0, max_features=None, min_df=5, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soa', soa)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe2= Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe2.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search1 = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search1.fit(X,y)\n",
    "print(grid_search1.best_estimator_)\n",
    "print(grid_search1.best_score_)\n",
    "grid_search2 = GridSearchCV(estimator=pipe2, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search2.fit(X,y)\n",
    "print(grid_search2.best_estimator_)\n",
    "print(grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "We are fitting!\n",
      "[[ 15.57142857   3.11428571   2.3956044    5.45        72.66666667]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, thres=0.1,\n",
      "      tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.447247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X,y)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 88 436 436\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537)\n",
      "(261, 14138)\n",
      "(262, 14058)\n",
      "(262, 13356)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(13537, 5) <type 'numpy.ndarray'>\n",
      "(14138, 5) <type 'numpy.ndarray'>\n",
      "(14058, 5) <type 'numpy.ndarray'>\n",
      "(13356, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.          0.44151325  0.06550793  0.49297881  0.        ]\n",
      "[ 0.          0.72245332  0.27754668  0.          0.        ]\n",
      "[ 0.          0.34643333  0.17271636  0.48085031  0.        ]\n",
      "[ 0.          0.30669112  0.21100297  0.48230591  0.        ]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(89, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(87, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "[ 1.26691404  1.66449085  2.30417331  1.78089942  1.03220281]\n",
      "[ 2.37359272  2.92592043  2.90394709  3.1043561   1.68510674]\n",
      "[ 1.59815326  1.92811313  2.18654839  2.30936014  1.40540878]\n",
      "[ 2.26109734  2.51535375  2.34143872  2.25845794  1.45798678]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "\n",
      "(348, 16756)\n",
      "Doc_Prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(16756, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.          0.43153198  0.17457671  0.39389131  0.        ]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "0.456896551724\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngra...',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.454022988506\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537)\n",
      "(261, 14138)\n",
      "(262, 14058)\n",
      "(262, 13356)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(13537, 5) <type 'numpy.ndarray'>\n",
      "(14138, 5) <type 'numpy.ndarray'>\n",
      "(14058, 5) <type 'numpy.ndarray'>\n",
      "(13356, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.          0.44151325  0.06550793  0.49297881  0.        ]\n",
      "[ 0.          0.72245332  0.27754668  0.          0.        ]\n",
      "[ 0.          0.34643333  0.17271636  0.48085031  0.        ]\n",
      "[ 0.          0.30669112  0.21100297  0.48230591  0.        ]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are fitting!We are fitting!We are fitting!We are fitting!\n",
      "\n",
      "\n",
      "\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(89, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(87, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "[ 1.26691404  1.66449085  2.30417331  1.78089942  1.03220281]\n",
      "[ 2.37359272  2.92592043  2.90394709  3.1043561   1.68510674]\n",
      "[ 1.59815326  1.92811313  2.18654839  2.30936014  1.40540878]\n",
      "[ 2.26109734  2.51535375  2.34143872  2.25845794  1.45798678]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(348, 16756)\n",
      "Doc_Prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(16756, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.          0.43153198  0.17457671  0.39389131  0.        ]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.471264367816\n",
      "VotingClassifier(estimators=[('0', Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]))],\n",
      "         voting='soft', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "trained_models = []\n",
    "for model in [pipe, pipe1, eclf]:\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "Accuracy : 0.534090909091\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 6 29  2  0  0]\n",
      " [ 4 10  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.511363636364\n",
      "Confusion matrix :\n",
      " [[ 9 17  0  2  0]\n",
      " [ 2 33  0  2  0]\n",
      " [ 1 14  1  0  0]\n",
      " [ 2  2  0  2  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.568181818182\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 5 32  0  0  0]\n",
      " [ 5  9  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for model in trained_models:\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['35-49', '25-34', '25-34', '25-34', '35-49', '50-64', '35-49',\n",
       "       '35-49', '35-49', '25-34', '35-49', '25-34', '50-64', '35-49',\n",
       "       '35-49', '25-34', '25-34', '35-49', '35-49', '35-49', '25-34',\n",
       "       '25-34', '35-49', '25-34', '25-34', '35-49', '35-49', '35-49',\n",
       "       '35-49', '35-49', '35-49', '25-34', '35-49', '25-34', '25-34',\n",
       "       '25-34', '35-49', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '35-49', '35-49', '25-34', '25-34', '35-49', '35-49', '35-49',\n",
       "       '25-34', '50-64', '25-34', '35-49', '25-34', '35-49', '25-34',\n",
       "       '25-34', '25-34', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '18-24', '35-49', '35-49', '25-34', '35-49', '50-64', '25-34',\n",
       "       '35-49', '35-49', '25-34', '50-64', '35-49', '35-49', '35-49',\n",
       "       '35-49', '18-24', '35-49', '35-49', '35-49', '25-34', '25-34',\n",
       "       '25-34', '18-24', '50-64', '50-64', '35-49', '25-34', '35-49',\n",
       "       '35-49', '25-34', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '25-34', '25-34', '25-34', '35-49', '35-49', '25-34', '35-49',\n",
       "       '35-49', '25-34', '18-24', '35-49', '35-49', '25-34', '35-49',\n",
       "       '50-64', '35-49', '35-49', '18-24', '25-34', '35-49', '35-49',\n",
       "       '25-34', '35-49', '18-24', '35-49', '25-34', '35-49', '18-24',\n",
       "       '35-49', '35-49', '25-34', '25-34', '35-49'], \n",
       "      dtype='|S5')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#feature_names = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1].get_feature_names()\n",
    "#print len(set(y))\n",
    "feature_names = []\n",
    "soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "feature_names += soac_feat_names\n",
    "print len(feature_names)\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = grid_search.best_estimator_.steps[0][1]\n",
    "#print a.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "       soac_prob_0  soac_prob_1  soac_prob_2  soac_prob_3  soac_prob_4\n",
      "count   436.000000   436.000000   436.000000   436.000000   436.000000\n",
      "mean      0.334800     0.333926     0.323147     0.335459     0.333121\n",
      "std       0.245069     0.370890     0.390482     0.307089     0.231141\n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000\n",
      "25%       0.189950     0.000000     0.000000     0.141166     0.190086\n",
      "50%       0.289293     0.261512     0.263432     0.289500     0.284627\n",
      "75%       0.428288     0.512928     0.523927     0.448032     0.394424\n",
      "max       1.692613     2.068010     3.497002     2.356757     1.905468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(a.transform(X), columns=feature_names)\n",
    "data[\"class\"] = y\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voc: 125532\n",
      "(125532, 5)\n",
      "fic\n",
      "[0.2043907252514684, 0.28704097801964457, 0.30305073020109663, 0.012805472795373671, 0.19271209373241674]\n",
      "pinoy\n",
      "[0.20463188045707323, 0.28737965007037575, 0.29925827359601481, 0.015790726246659309, 0.19293946962987688]\n",
      "hau\n",
      "[0.20482151808954271, 0.28764597219153065, 0.29627599299366542, 0.018138245121083925, 0.19311827160417727]\n",
      "directmarketing\n",
      "[0.20405919797315172, 0.26927285675575857, 0.32042252787399861, 0.013845907887149334, 0.19239950950994181]\n",
      "inspector\n",
      "[0.2041459623102034, 0.2866972393595012, 0.30689992280281309, 0.009775559286662806, 0.19248131624081946]\n",
      "revision\n",
      "[0.20477137581790666, 0.28757555369933724, 0.29706454072077326, 0.017517535362481074, 0.19307099439950182]\n",
      "producción\n",
      "[0.20435280604767755, 0.27848828975660639, 0.30961943253292062, 0.01486313047808446, 0.19267634118471083]\n",
      "bocetos\n",
      "[0.20352640402345179, 0.28163933767385241, 0.31958591190228791, 0.003351187657352997, 0.19189715874305496]\n",
      "abbe\n",
      "[0.20416766387170535, 0.27359334048821976, 0.31578789319781009, 0.013949324640143325, 0.19250177780212155]\n",
      "personajes\n",
      "[0.2009918215045533, 0.2865720119304716, 0.30696743823875355, 0.013071486631857169, 0.19239724169436434]\n",
      "horseback\n",
      "[0.20476628511370426, 0.28756840444776888, 0.29714459818720174, 0.017454517679526788, 0.19306619457179824]\n",
      "nottingham\n",
      "[0.20392198958515698, 0.28638269793416038, 0.31042216416737356, 0.0070030072749335962, 0.19227014103837545]\n",
      "phonebloks\n",
      "[0.20440720079222424, 0.28706411583730301, 0.3027916324420209, 0.013009423047161585, 0.19272762788129025]\n",
      "privé\n",
      "[0.20379193719524807, 0.27547614662412462, 0.320002863507442, 0.0085815329931098715, 0.19214751968007551]\n",
      "woord\n",
      "[0.20433952254161586, 0.2627663481350489, 0.32086270556627922, 0.019367607075412137, 0.19266381668164392]\n",
      "havana\n",
      "[0.20391369597158795, 0.28637105060061702, 0.31055259124847634, 0.0069003408677606451, 0.19226232131155802]\n",
      "unpublished\n",
      "[0.20435613151145512, 0.2623808435535821, 0.32088878568496126, 0.019694762614372158, 0.19267947663562923]\n",
      "corina\n",
      "[0.20406862961555713, 0.26905394243456732, 0.32043733784449518, 0.014031687865335063, 0.19240840224004516]\n",
      "reservoirs\n",
      "[0.20484958529214689, 0.28768538903530316, 0.29583460236460801, 0.018485688226166024, 0.19314473508177593]\n",
      "compay\n",
      "[0.20475517408286673, 0.28755280040725045, 0.29731933255457144, 0.017316974543885009, 0.19305571841142652]\n",
      "lectores\n",
      "[0.20377645564124472, 0.2758354831786643, 0.31997855370558814, 0.0082765847517135647, 0.19213292272278917]\n",
      "blogchat\n",
      "[0.20412641183172642, 0.28666978317989283, 0.30720737766801748, 0.0095335444680261939, 0.19246288285233698]\n",
      "pollan\n",
      "[0.20273674447683382, 0.28471817076607342, 0.31834595452423115, 0.018920465615015723, 0.17527866461784589]\n",
      "machina\n",
      "[0.19294977728726342, 0.28522928378102302, 0.31891743459582639, 0.011407736552247876, 0.19149576778363939]\n",
      "yielding\n",
      "[0.20496142524636893, 0.28784245413599235, 0.2940757841295315, 0.019870151847822409, 0.19325018464028476]\n",
      "cpr\n",
      "[0.20442670263357293, 0.2870915037122031, 0.30248494245434793, 0.013250835788166647, 0.19274601541170941]\n",
      "по\n",
      "[0.20419796884783831, 0.28677027597800619, 0.30608205724330184, 0.010419346741197391, 0.19253035118965614]\n",
      "torrent\n",
      "[0.20483713111559834, 0.28479354140034069, 0.29805021060061071, 0.01918612436208364, 0.19313299252136654]\n",
      "bernanke\n",
      "[0.20464562939391742, 0.28739895871695759, 0.29904205497358527, 0.015960923945948807, 0.19295243296959094]\n",
      "informate\n",
      "[0.20367785914729217, 0.27812396949076024, 0.31982373325081043, 0.0063344782014156309, 0.1920399599097217]\n",
      "echograph\n",
      "[0.20388800374860705, 0.28633496911598577, 0.31095663245711946, 0.0065822975680832835, 0.19223809711020448]\n",
      "potrero\n",
      "[0.20424309737317226, 0.26500443662357781, 0.32071129462018977, 0.017468270255810287, 0.19257290112724976]\n",
      "ajustes\n",
      "[0.20265127728962049, 0.28574561038900209, 0.31720045389708462, 0.0025602419413635054, 0.19184241648292924]\n",
      "aran\n",
      "[0.20410007811234637, 0.26832400314815941, 0.32048671962654246, 0.014651145304062082, 0.19243805380888973]\n",
      "hacku\n",
      "[0.20394811017559974, 0.28641938100682879, 0.31001138636349024, 0.0073263533232736577, 0.19229476913080759]\n",
      "prolog\n",
      "[0.19301445695497998, 0.28523151467356728, 0.31891992897689997, 0.011336833845764884, 0.19149726554878801]\n",
      "sandi\n",
      "[0.20402582648729567, 0.27004742982153696, 0.32037012653182378, 0.013188572330112532, 0.19236804482923101]\n",
      "eca\n",
      "[0.20395279681710934, 0.27174249415798962, 0.32025545220318125, 0.011750068838262436, 0.19229918798345741]\n",
      "shp\n",
      "[0.19956193860029586, 0.28545734650762039, 0.3191724335872666, 0.0041593979421823473, 0.19164888336263486]\n",
      "happyholidays\n",
      "[0.20280922361408013, 0.27925114629433212, 0.30732985183555006, 0.017866251836244174, 0.19274352641979339]\n",
      "cept\n",
      "[0.20466720510427217, 0.2874292590791393, 0.29870275089329795, 0.016228009052566935, 0.19297277587072362]\n",
      "emprendedora\n",
      "[0.20426157916111912, 0.26457546276209593, 0.3207403155184016, 0.017832315669535134, 0.19259032688884814]\n",
      "laurie\n",
      "[0.20406681231039689, 0.27334614063976442, 0.31744808512663819, 0.012732273149761816, 0.19240668877343869]\n",
      "treball\n",
      "[0.20390858500763087, 0.28636387289678011, 0.31063296732399515, 0.0068370723898770035, 0.1922575023817169]\n",
      "ess\n",
      "[0.20410129791559198, 0.26829569075165188, 0.32048863501405428, 0.014675172404604971, 0.19243920391409683]\n",
      "ene\n",
      "[0.20379773057812015, 0.27534167858300163, 0.32001196052636216, 0.0086956482762515219, 0.19215298203626457]\n",
      "parting\n",
      "[0.204040550027554, 0.26970568724027394, 0.3203932460678981, 0.013478589579540168, 0.19238192708473381]\n",
      "herbalife\n",
      "[0.20441990216652239, 0.28708195331449904, 0.30259188800469905, 0.013166652999401857, 0.19273960351487773]\n",
      "entrevistas\n",
      "[0.19233682439050714, 0.28520814217508023, 0.31889379597555179, 0.012079663617752579, 0.19148157384110825]\n",
      "internetmarketing\n",
      "[0.20425394976149577, 0.264752545900731, 0.32072833550702379, 0.017682035407130869, 0.19258313342361863]\n",
      "grenades\n",
      "[0.20401309216535232, 0.27034300140114292, 0.32035013055189066, 0.012937737751028288, 0.19235603813058588]\n",
      "isomorphic\n",
      "[0.20480875599209702, 0.28762804943633774, 0.29647669237575552, 0.017980263478722513, 0.19310623871708735]\n",
      "vau\n",
      "[0.20394081657290467, 0.28640913806234919, 0.31012608706690903, 0.0072360660223492424, 0.19228789227548795]\n",
      "sustancial\n",
      "[0.2042441653821403, 0.26497964746722391, 0.32071297165379936, 0.017489307385321139, 0.19257390811151534]\n",
      "orman\n",
      "[0.20413066481343556, 0.28667575595594613, 0.30714049439865759, 0.0095861920079933789, 0.19246689282396737]\n",
      "evicted\n",
      "[0.20418455168661168, 0.26636331863809082, 0.32061936366549532, 0.016315065341488279, 0.19251770066831397]\n",
      "peuvent\n",
      "[0.20452395105367632, 0.28722807684478041, 0.30095559370058672, 0.014454671222767957, 0.19283770717818871]\n",
      "ub\n",
      "[0.20456833028741989, 0.27437812917873922, 0.30933086296805323, 0.018843126928007353, 0.19287955063778037]\n",
      "tsla\n",
      "[0.20372047731419723, 0.27713477517259516, 0.31989065412920603, 0.007173950456360649, 0.192080142927641]\n",
      "burgermeister\n",
      "[0.20392032195616822, 0.27249625599851368, 0.3202044587800057, 0.011110394569681973, 0.1922685686956305]\n",
      "inalienable\n",
      "[0.20447954133733903, 0.28716570900301391, 0.30165399007826704, 0.013904924603639342, 0.19279583497774078]\n",
      "canticle\n",
      "[0.20411950144196428, 0.28666007840961344, 0.30731605188564981, 0.0094480009491318753, 0.19245636731364058]\n",
      "collectibles\n",
      "[0.20409764172444544, 0.26838055323568066, 0.32048289390548768, 0.014603154501226779, 0.19243575663315945]\n",
      "fundacion\n",
      "[0.20415764102689357, 0.26698793188695447, 0.32057710739035911, 0.015784992045611745, 0.19249232765018115]\n",
      "rankin\n",
      "[0.20459160155875586, 0.28732308344117891, 0.29989170787576053, 0.015292114906653612, 0.19290149221765118]\n",
      "polymer\n",
      "[0.20372108297841984, 0.28610054996087297, 0.31358166298811763, 0.004515990087625407, 0.19208071398496415]\n",
      "telefónica\n",
      "[0.20065931060637307, 0.28089041043049262, 0.31425843895446287, 0.012008551205900104, 0.19218328880277136]\n",
      "arbitration\n",
      "[0.20383616405455307, 0.28626216680823335, 0.31177187419999319, 0.0059405754655060478, 0.1921892194717143]\n",
      "jefa\n",
      "[0.19233682439050714, 0.28520814217508023, 0.31889379597555179, 0.012079663617752579, 0.19148157384110825]\n",
      "ocupada\n",
      "[0.20413775167965761, 0.26744957608018405, 0.32054587628202186, 0.015393221202657818, 0.1924735747554786]\n",
      "fredericksburg\n",
      "[0.20403417668780555, 0.28654025056100202, 0.30865788660439281, 0.0083917682371175192, 0.19237591790968206]\n",
      "teasers\n",
      "[0.20357953498796105, 0.28040613474590281, 0.31966934042756645, 0.0043977359681550083, 0.19194725387041459]\n",
      "bissell\n",
      "[0.20411742365471947, 0.27842986098982947, 0.31312988030088645, 0.01186842680599318, 0.19245440824857149]\n",
      "tahitian\n",
      "[0.20477065015604679, 0.2875745345988388, 0.29707595262916114, 0.017508552414896399, 0.19307031020105692]\n",
      "basso\n",
      "[0.20396951136247207, 0.27135453910256968, 0.32028169810109025, 0.012079303953355675, 0.19231494748051231]\n",
      "bong\n",
      "[0.20410802199331279, 0.28664395697277228, 0.30749658006770531, 0.0093058971798195937, 0.19244554378639003]\n",
      "manolo\n",
      "[0.18671874196166718, 0.28501436662480062, 0.31867713378517865, 0.018238279818362998, 0.19135147780999043]\n",
      "grupos\n",
      "[0.20382932996179326, 0.27460823711761317, 0.32006157923748324, 0.0093180778126058326, 0.19218277587050445]\n",
      "raccoon\n",
      "[0.20414947454193486, 0.2671774811122542, 0.32056428402449122, 0.015624132533316298, 0.19248462778800346]\n",
      "introductions\n",
      "[0.20450271739822162, 0.28158529883569217, 0.30389216415243081, 0.019189356547527459, 0.19083046306612797]\n",
      "corned\n",
      "[0.18872551267498508, 0.28508358296403802, 0.31875452519832209, 0.016038431243250131, 0.19139794791940459]\n",
      "consultar\n",
      "[0.20467012664497661, 0.28743336201433894, 0.29865680614035872, 0.016264174722095379, 0.19297553047823035]\n",
      "readily\n",
      "[0.2047925031062704, 0.28760522430942664, 0.29673228861739565, 0.017779069465989551, 0.19309091450091762]\n",
      "demasiada\n",
      "[0.20438809480221842, 0.27935513837876413, 0.30849018153620805, 0.015056971699048221, 0.19270961358376129]\n",
      "fotografía\n",
      "[0.20440165561438964, 0.28705632833487615, 0.30287883705471969, 0.012940779448002607, 0.19272239954801187]\n",
      "montes\n",
      "[0.20400571421911329, 0.27051424814940378, 0.32033854538343021, 0.012792410497045322, 0.19234908175100743]\n",
      "damepic\n",
      "[0.20460736318806352, 0.28734521866030927, 0.29964383723566779, 0.015487227668871482, 0.19291635324708775]\n",
      "trifecta\n",
      "[0.20271162619168845, 0.28468289530469687, 0.31830651271272686, 0.019687582430677059, 0.17461138336021068]\n",
      "raúl\n",
      "[0.19328126368472903, 0.28491032283253925, 0.31856080148271043, 0.018145783488820576, 0.18510182851120072]\n",
      "edo\n",
      "[0.20437655528698842, 0.28702107809288507, 0.30327356999114374, 0.01263006320692104, 0.19269873342206173]\n",
      "vat\n",
      "[0.20393875794004804, 0.28640624697231648, 0.31015846155268839, 0.0072105822645978906, 0.19228595127034923]\n",
      "longhorn\n",
      "[0.20487634293893811, 0.2877229667732118, 0.29541380608092305, 0.018816920376977058, 0.19316996382995003]\n",
      "concluding\n",
      "[0.2041375355153795, 0.28668540498969391, 0.30703244431985571, 0.0096712442325126817, 0.1924733709425582]\n",
      "pdt\n",
      "[0.20490815962408584, 0.28776764929200477, 0.2949134503144456, 0.019210778220134932, 0.19319996254932884]\n",
      "figurative\n",
      "[0.20410987170539882, 0.28664655465995004, 0.30746749111314409, 0.0093287947132763786, 0.19244728780823081]\n",
      "rasmus\n",
      "[0.20402647085389991, 0.2865294286898139, 0.30877907014102762, 0.008296377937728654, 0.19236865237752993]\n",
      "maryann\n",
      "[0.20362853059655675, 0.28597057182133001, 0.30910855848502172, 0.018081430277850735, 0.18321090881924088]\n",
      "siegel\n",
      "[0.20417526893474144, 0.26657877711680522, 0.32060478748931986, 0.016132218137807495, 0.19250894832132612]\n",
      "català\n",
      "[0.20443137729846655, 0.28709806868906951, 0.30241142770807478, 0.013308703332316846, 0.19275042297207223]\n",
      "raul\n",
      "[0.19997750354096591, 0.28087210734364798, 0.31949153704552691, 0.0078183612404847478, 0.19184049082937438]\n",
      "emociona\n",
      "[0.20476796612826739, 0.28757076522056646, 0.29711816220475273, 0.017475326911131035, 0.19306777953528248]\n",
      "jazzy\n",
      "[0.20469066982491793, 0.27678547628763256, 0.30583606085660064, 0.019692893184397403, 0.19299489984645166]\n",
      "nac\n",
      "[0.20361063311194061, 0.27968432783161906, 0.31971817203916081, 0.0050102919309638911, 0.19197657508631558]\n",
      "aeasf\n",
      "[0.20372656279361442, 0.28610824566972132, 0.31349548628180418, 0.004583824564517701, 0.19208588069034241]\n",
      "registrations\n",
      "[0.20419033635464925, 0.26622905287372883, 0.32062844700000759, 0.016429008963991017, 0.19252315480762336]\n",
      "roque\n",
      "[0.20284657933941749, 0.28487241996861362, 0.31851842194872027, 0.015566089727252111, 0.17819648901599652]\n",
      "glossary\n",
      "[0.20486083601888658, 0.28770118926108551, 0.29565767111061031, 0.018624960653417823, 0.19315534295599987]\n",
      "celebapprentice\n",
      "[0.20362882100247548, 0.27926217551294763, 0.31974673144701782, 0.0053685482941249075, 0.19199372374343412]\n",
      "fencing\n",
      "[0.20418982175348796, 0.26624099708864402, 0.32062763895113472, 0.01641887259660163, 0.19252266961013165]\n",
      "ofrece\n",
      "[0.20475106917385702, 0.28754703558061562, 0.29738388720205677, 0.017266159991664629, 0.19305184805180586]\n",
      "inicia\n",
      "[0.19233682439050714, 0.28520814217508023, 0.31889379597555179, 0.012079663617752579, 0.19148157384110825]\n",
      "slo\n",
      "[0.2040654806378652, 0.28658421300807457, 0.30816559421588274, 0.0087792789471601573, 0.19240543319101719]\n",
      "twbirthday\n",
      "[0.20452395105367632, 0.28722807684478041, 0.30095559370058672, 0.014454671222767957, 0.19283770717818871]\n",
      "empires\n",
      "[0.19631805447840045, 0.27758268148390219, 0.3195588412778827, 0.014659518725479026, 0.19188090403433566]\n",
      "driod\n",
      "[0.20494567541730654, 0.2878203354888173, 0.29432346919652685, 0.019675185160507137, 0.19323533473684221]\n",
      "horizonte\n",
      "[0.20413775167965761, 0.26744957608018405, 0.32054587628202186, 0.015393221202657818, 0.1924735747554786]\n",
      "pastels\n",
      "[0.19713051745623941, 0.28593284343429159, 0.31264148245285533, 0.012327036615876929, 0.19196812004073685]\n",
      "storydoers\n",
      "[0.20482302774910585, 0.28764809231785704, 0.29625225177536046, 0.018156933154003661, 0.19311969500367288]\n",
      "ssm\n",
      "[0.20472090557583453, 0.28750467461405849, 0.29785824617874362, 0.016892765667150797, 0.19302340796421252]\n",
      "nestor\n",
      "[0.20414231466318897, 0.2673436663775649, 0.32055304127498613, 0.015483100668446888, 0.19247787701581315]\n",
      "competencies\n",
      "[0.20433790019123879, 0.28696679188945889, 0.30388146801610272, 0.012151552872852401, 0.19266228703034718]\n",
      "usaid\n",
      "[0.20347490050151554, 0.28283476664146373, 0.31950503885732268, 0.0023366959314717259, 0.19184859806822627]\n",
      "firecrackers\n",
      "[0.19025972692686557, 0.28513650016749148, 0.31881369240074825, 0.014356605305927738, 0.19143347519896703]\n",
      "watercolor\n",
      "[0.20447005445650854, 0.28044732945663264, 0.30651468683328287, 0.015781039088108753, 0.19278689016546724]\n",
      "cpan\n",
      "[0.20415260194628393, 0.26710489210063287, 0.32056919480928886, 0.015685734647431747, 0.19248757649636253]\n",
      "sheri\n",
      "[0.20478321734999133, 0.28759218363666267, 0.29687831833981299, 0.017664121352344041, 0.19308215932118908]\n",
      "correcto\n",
      "[0.19769591137633927, 0.27937805493828766, 0.31104870113603134, 0.01950876993794981, 0.19236856261139201]\n",
      "captar\n",
      "[0.20381787653496369, 0.27487407832022986, 0.32004359457414028, 0.0090924736924448031, 0.19217197687822127]\n",
      "santjordi\n",
      "[0.20447501263457865, 0.28715934901154222, 0.30172520939386421, 0.013848863920598177, 0.19279156503941669]\n",
      "incrementar\n",
      "[0.20384696446248973, 0.27419892932332224, 0.32008926968881835, 0.0096654337675787013, 0.19219940275779085]\n",
      "foodsecurity\n",
      "[0.20463628752097196, 0.28738583923541799, 0.29918896719829574, 0.015845281165681926, 0.1929436248796324]\n",
      "frita\n",
      "[0.20292631690631391, 0.28498440131785874, 0.31864362930523854, 0.013130890506762555, 0.18031476196382618]\n",
      "indicating\n",
      "[0.20476977084023201, 0.28757329971075296, 0.29708978093140065, 0.017497667389361617, 0.19306948112825281]\n",
      "merida\n",
      "[0.19347059904409375, 0.28524724765460535, 0.31893752016488996, 0.010836804859829059, 0.19150782827658189]\n",
      "arcane\n",
      "[0.19581010026737602, 0.28532794033625669, 0.31902774337998818, 0.0082722127027095374, 0.19156200331366957]\n",
      "història\n",
      "[0.20394081657290467, 0.28640913806234919, 0.31012608706690903, 0.0072360660223492424, 0.19228789227548795]\n",
      "repubblica\n",
      "[0.20418049206460057, 0.28674573204164588, 0.30635690074858546, 0.010203002137118923, 0.19251387300804923]\n",
      "cinemagraphpic\n",
      "[0.2038801469186757, 0.28632393518993626, 0.31108019058846254, 0.0064850380931740486, 0.19223068920975153]\n",
      "rellenar\n",
      "[0.20409332131908245, 0.26848083254724098, 0.32047610981919511, 0.014518053224102554, 0.19243168309037884]\n",
      "twittear\n",
      "[0.20014465653762883, 0.28619157526868072, 0.31097661196534887, 0.010545330140947684, 0.19214182608739386]\n",
      "maxim\n",
      "[0.20488664432142864, 0.28773743376481031, 0.29525180441079657, 0.018944440898691385, 0.19317967660427299]\n",
      "promoter\n",
      "[0.20394667663282509, 0.28641736777692528, 0.31003393055344813, 0.0073086075379195778, 0.1922934174988819]\n",
      "binay\n",
      "[0.20477032352785576, 0.28757407589076739, 0.29708108925159993, 0.017504509093782872, 0.19307000223599402]\n",
      "ingles\n",
      "[0.20344269965760628, 0.2835821683752382, 0.31945447570747421, 0.0017024191192420324, 0.19181823714043925]\n",
      "investigar\n",
      "[0.19398168237195984, 0.27505264396296747, 0.31963013919635863, 0.019411819198118564, 0.19192371527059568]\n",
      "significado\n",
      "[0.20316785186432212, 0.28532360668291296, 0.31902289788310056, 0.00575437070115223, 0.18673127286851215]\n",
      "repeatable\n",
      "[0.19719363918791052, 0.28537566053599667, 0.31908109976569204, 0.0067555590547604509, 0.19159404145564032]\n",
      "ciutat\n",
      "[0.2048704846241606, 0.28771473950946869, 0.2955059351499062, 0.018744400464481035, 0.1931644402519837]\n",
      "reaper\n",
      "[0.20402150383733267, 0.28652245314191871, 0.30885718247014271, 0.0082348913805017666, 0.19236396917010404]\n",
      "equestrian\n",
      "[0.20427753754569028, 0.28688202017199083, 0.304830743455696, 0.011404325395425406, 0.19260537343119741]\n",
      "weet\n",
      "[0.20443802781823628, 0.27684393159529475, 0.30951877265488592, 0.016442574442159137, 0.19275669348942409]\n",
      "jewlery\n",
      "[0.19839642131299529, 0.28541714618009445, 0.31912748523850476, 0.0054370533946572494, 0.19162189387374828]\n",
      "thoughtleadership\n",
      "[0.20489461830140299, 0.28774863221331004, 0.29512640395366485, 0.019043150570660659, 0.19318719496096143]\n",
      "unseen\n",
      "[0.20434876014885056, 0.26255193749157019, 0.32087721085440668, 0.019549565041668163, 0.1926725264635045]\n",
      "blackpool\n",
      "[0.20431881145521558, 0.26324706540840759, 0.32083018412776881, 0.018959650007678443, 0.1926442890009297]\n",
      "clases\n",
      "[0.20127382923617587, 0.28177195483144263, 0.30556081844069638, 0.018691558932166841, 0.1927018385595182]\n",
      "dsc\n",
      "[0.20345087875365628, 0.28339232643862017, 0.31946731887581997, 0.0018635270387774888, 0.19182594889312615]\n",
      "sustenance\n",
      "[0.20421133209024872, 0.2657417287143633, 0.32066141540693166, 0.016842572915420299, 0.19254295087303605]\n",
      "girlsintech\n",
      "[0.20394371383712082, 0.2719533158063408, 0.32024118971740528, 0.011571156645498456, 0.1922906239936347]\n",
      "configurar\n",
      "[0.20391570425234554, 0.27260343579333041, 0.32019720786288686, 0.011019437249783227, 0.19226421484165393]\n",
      "horner\n",
      "[0.20428288444711856, 0.28688952922022903, 0.30474665697874181, 0.011470514536574069, 0.19261041481733646]\n",
      "arpa\n",
      "[0.20470361212477173, 0.28748038814460009, 0.2981302065643523, 0.016678690526867431, 0.19300710263940837]\n",
      "accord\n",
      "[0.20494310468058982, 0.28781672521354429, 0.29436389713345124, 0.01964336208359433, 0.19323291088882022]\n",
      "tht\n",
      "[0.20374113570798785, 0.276655280927673, 0.31992309282751497, 0.0075808696102884167, 0.19209962092653576]\n",
      "spc\n",
      "[0.20433991637194596, 0.2627572070866846, 0.32086332397559958, 0.01937536455677048, 0.1926641880089994]\n",
      "christmastime\n",
      "[0.19987569058152485, 0.2859175489503798, 0.31401300619968353, 0.0082359025595262481, 0.19195785170888563]\n",
      "daedalus\n",
      "[0.2040071122079859, 0.28650224191482943, 0.30908350820770047, 0.0080567378089477937, 0.19235039986053667]\n",
      "wintour\n",
      "[0.20437283581124893, 0.26941193736018459, 0.31570197080631557, 0.017818029549716761, 0.1926952264725342]\n",
      "frente\n",
      "[0.20415832059982236, 0.28671459501756502, 0.30670557378606528, 0.0099285422033883238, 0.19249296839315902]\n",
      "esc\n",
      "[0.20408479892321341, 0.26867864268744768, 0.32046272758671046, 0.014350183149031467, 0.19242364765359707]\n",
      "hecha\n",
      "[0.20377645564124472, 0.2758354831786643, 0.31997855370558814, 0.0082765847517135647, 0.19213292272278917]\n",
      "lloviendo\n",
      "[0.18965065432419689, 0.28511549239833939, 0.31879020342459635, 0.015024278741776169, 0.19141937111109125]\n",
      "evidentemente\n",
      "[0.19408136634817363, 0.28526831387638829, 0.31896107449745553, 0.010167273669898443, 0.19152197160808396]\n",
      "scribbles\n",
      "[0.2040679201579001, 0.28658763900607842, 0.3081272298196166, 0.0088094776964897474, 0.19240773331991515]\n",
      "método\n",
      "[0.20373891192915233, 0.2767068962257645, 0.31991960095435767, 0.007537066679071734, 0.19209752421165366]\n",
      "callan\n",
      "[0.20469455668822953, 0.28178025071468998, 0.30226904647662423, 0.018257581501222586, 0.19299856461923379]\n",
      "proofing\n",
      "[0.20453062401263603, 0.28723744817346347, 0.30085065336882461, 0.014537275592492828, 0.19284399885258313]\n",
      "niebla\n",
      "[0.20372589193469962, 0.27700909844304661, 0.31989915639916539, 0.0072806050596179103, 0.19208524816347058]\n",
      "babel\n",
      "[0.18666258887077511, 0.28501242982586167, 0.31867496823281755, 0.01829983557865358, 0.19135017749189209]\n",
      "fidel\n",
      "[0.18995295781356047, 0.28544946882905198, 0.31507841443799905, 0.017875564432025658, 0.19164359448736298]\n",
      "chet\n",
      "[0.20403389057370366, 0.26986025733066504, 0.3203827891070839, 0.013347414844763685, 0.19237564814378366]\n",
      "textos\n",
      "[0.2043117352295197, 0.28693004650293291, 0.30429294361184839, 0.011827657553740845, 0.1926376171019582]\n",
      "texier\n",
      "[0.2040532075279789, 0.26941189873617544, 0.32041312141937939, 0.013727910965119831, 0.19239386135134645]\n",
      "steinberg\n",
      "[0.20475907735487031, 0.28755828206015815, 0.29725794889231844, 0.017365293037324783, 0.19305939865532845]\n",
      "woodlands\n",
      "[0.20402183697921089, 0.28652292099764182, 0.30885194341211319, 0.0082390153343640977, 0.19236428327667018]\n",
      "lop\n",
      "[0.20407224493343584, 0.26897002864465946, 0.32044301477209891, 0.014102900666643594, 0.19241181098316232]\n",
      "imprescindibles\n",
      "[0.20287212837027613, 0.28604370593891065, 0.31386611418660321, 0.005175501165998098, 0.19204255033821199]\n",
      "maravilloso\n",
      "[0.19703141193921728, 0.28015565861575509, 0.31106744055120455, 0.019430020978667559, 0.19231546791515539]\n",
      "predicciones\n",
      "[0.20466905898374918, 0.28743186261889164, 0.29867359640148483, 0.016250958174038457, 0.19297452382183589]\n",
      "onderzoek\n",
      "[0.20470935663820811, 0.28748845558872216, 0.29803986715878072, 0.016749801695788505, 0.19301251891850055]\n",
      "chihuahua\n",
      "[0.20443528413795467, 0.287103555352059, 0.30234998794282275, 0.013357065987546456, 0.19275410657961708]\n",
      "educates\n",
      "[0.20400254454746913, 0.28649582721210565, 0.30915534018102575, 0.00800019486894556, 0.19234609319045387]\n",
      "storytellers\n",
      "[0.20482302774910585, 0.28764809231785704, 0.29625225177536046, 0.018156933154003661, 0.19311969500367288]\n",
      "genres\n",
      "[0.20425722785524636, 0.28685349777499308, 0.30515013784520506, 0.01115291231338102, 0.19258622421117441]\n",
      "unido\n",
      "[0.20467921221428317, 0.28744612154976518, 0.29851392459964621, 0.016376644726884756, 0.19298409690942073]\n",
      "tof\n",
      "[0.20489069009895736, 0.28774311554874282, 0.29518817967720257, 0.018994523463985374, 0.19318349121111184]\n",
      "bsr\n",
      "[0.20416120772939342, 0.28671864962667082, 0.30666017018972153, 0.0099642818984725864, 0.19249569055574164]\n",
      "beethoven\n",
      "[0.20409401416683401, 0.28662428474837243, 0.30771687004203624, 0.0091324946930847785, 0.19243233634967269]\n",
      "flagler\n",
      "[0.2037353373310008, 0.28612056840007, 0.31335749609335301, 0.0046924443139871258, 0.19209415386158918]\n",
      "fabrizio\n",
      "[0.20469434300487227, 0.28746737083553164, 0.29827597465962435, 0.016563948354494262, 0.19299836314547744]\n",
      "literatura\n",
      "[0.2041324931823765, 0.28667832366937024, 0.30711174109080625, 0.0096088253352631884, 0.19246861672218385]\n",
      "abb\n",
      "[0.20341594715757075, 0.28420311063891601, 0.31941246778147298, 0.0011754611770986186, 0.19179301324494163]\n",
      "auctioned\n",
      "[0.20467582340458887, 0.28744136239424184, 0.29856721772129569, 0.016334694747781292, 0.19298090173209234]\n",
      "inclusión\n",
      "[0.20455004193894458, 0.28726471820028021, 0.30054528304641703, 0.014777649551595197, 0.19286230726276296]\n",
      "homosexual\n",
      "[0.20374122133970513, 0.27665329336193917, 0.31992322729011985, 0.0075825563428724941, 0.19209970166536333]\n",
      "excerpts\n",
      "[0.20392608399069612, 0.28638844800999635, 0.31035777469963716, 0.0070536918049897068, 0.1922740014946808]\n",
      "bieten\n",
      "[0.20416838016082056, 0.26673866986950806, 0.32059397044026933, 0.015996526366033232, 0.1925024531633687]\n",
      "fraudster\n",
      "[0.20466162090726814, 0.28742141677921335, 0.29879056912952084, 0.016158882436215178, 0.19296751074778257]\n",
      "hoola\n",
      "[0.20404997700335226, 0.26948688123395581, 0.32040804871068751, 0.013664277637130367, 0.19239081541487413]\n",
      "utf\n",
      "[0.20410450400849847, 0.26822127532938145, 0.32049366935900864, 0.014738324488264284, 0.19244222681484718]\n",
      "hlf\n",
      "[0.20364823892144437, 0.28599824967630072, 0.3147272236834579, 0.0036142555721033541, 0.19201203214669371]\n",
      "thepitch\n",
      "[0.20387513591145193, 0.28631689786271602, 0.31115899472373398, 0.0064230069768576488, 0.19222596452524043]\n",
      "repo\n",
      "[0.20405402388949853, 0.28656812345091859, 0.30834576540856801, 0.0086374561840295416, 0.1923946310669854]\n",
      "mov\n",
      "[0.20409518134512566, 0.2866259239029767, 0.30769851475498999, 0.0091469431600575603, 0.19243343683685019]\n",
      "nube\n",
      "[0.18965065432419689, 0.28511549239833939, 0.31879020342459635, 0.015024278741776169, 0.19141937111109125]\n",
      "iker\n",
      "[0.20420107896356399, 0.28677464374302364, 0.30603314692060485, 0.010457846775565398, 0.19253328359724214]\n",
      "buckle\n",
      "[0.19443367733104203, 0.28528046557680203, 0.31897466142328074, 0.009781065714741315, 0.19153012995413371]\n",
      "equine\n",
      "[0.20325653404929414, 0.28739407031619507, 0.29849336527428066, 0.017906879339970937, 0.19294915102025936]\n",
      "fácilmente\n",
      "[0.20389157047530831, 0.27316359585779876, 0.32015931196835123, 0.010544061659958054, 0.1922414600385835]\n",
      "moneyball\n",
      "[0.20457279494914643, 0.28729667193151343, 0.30018746450541023, 0.015059308419634234, 0.19288376019429559]\n",
      "tokio\n",
      "[0.20420688812378301, 0.26584487595642498, 0.32065443729968207, 0.016755037790829687, 0.19253876082928029]\n",
      "cleantech\n",
      "[0.20491779595629198, 0.28778118230441307, 0.29476190736254365, 0.019330066103238733, 0.19320904827351257]\n",
      "elvira\n",
      "[0.20389792813377733, 0.28047285037036185, 0.31492954243210569, 0.0084522246353903666, 0.19224745442836469]\n",
      "booksellers\n",
      "[0.20404603473716482, 0.28655690369475506, 0.30847140446935845, 0.0085385586938543784, 0.19238709840486745]\n",
      "volatility\n",
      "[0.20412581515058287, 0.26772663038816513, 0.3205271330307588, 0.015158101165682206, 0.19246232026481097]\n"
     ]
    }
   ],
   "source": [
    "soacc = a.transformer_list[0][1]\n",
    "voc = soacc.counter.vocabulary_\n",
    "print 'Voc: ' + str(len(voc))\n",
    "print soacc.term_table.shape\n",
    "#terms= ['marriage', 'pension']\n",
    "#graph_matrix = numpy.zeros([len(terms), soacc.term_table.shape[1]])\n",
    "j = 0 \n",
    "for term, index in voc.iteritems():\n",
    "    l = list(soacc.term_table[index,:])\n",
    "    if l.index(min(l))==3 and  min(l)<0.02 and min(l)!=0:\n",
    "        print term\n",
    "        print l\n",
    "        j += 1\n",
    "    if j==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voc: 125532\n",
      "(125532, 5)\n",
      "dreamjob\n",
      "[ 0.01265381  0.26222892  0.31307008  0.22406249  0.18798469]\n",
      "lol\n",
      "[ 0.19276541  0.11180198  0.27522844  0.2184271   0.20177707]\n",
      "mortgage\n",
      "[ 0.2011231   0.2456243   0.14738652  0.20176227  0.2041038 ]\n",
      "booksellers\n",
      "[ 0.20404603  0.2865569   0.3084714   0.00853856  0.1923871 ]\n",
      "juvenile\n",
      "[ 0.19876243  0.27913675  0.27862587  0.22337202  0.02010292]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~Bogas/929.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy\n",
    "py.sign_in('Bogas', '9s60rarm2w')\n",
    "soacc = a.transformer_list[0][1]\n",
    "voc = soacc.counter.vocabulary_\n",
    "print 'Voc: ' + str(len(voc))\n",
    "print soacc.term_table.shape\n",
    "terms= ['dreamjob','lol', 'mortgage', 'booksellers', 'juvenile']\n",
    "graph_matrix = numpy.zeros([len(terms), soacc.term_table.shape[1]])\n",
    "j = 0\n",
    "for term in terms:\n",
    "    idx = voc[term]\n",
    "    print term\n",
    "    print soacc.term_table[idx,:]\n",
    "    graph_matrix[j, :] = soacc.term_table[idx,:]\n",
    "    j += 1\n",
    "    #plt.bar(numpy.arange(soacc.term_table.shape[1]), soacc.term_table[idx,:], color='r')\n",
    "    #plt.show()\n",
    "\n",
    "data = []\n",
    "names = sorted(list(set(y)))\n",
    "for i in range(0, soacc.term_table.shape[1]):\n",
    "    data.append(\n",
    "        go.Bar(\n",
    "        x=terms,\n",
    "        y=graph_matrix[:, i],\n",
    "        name=names[i]\n",
    "    )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    barmode='group'\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "#plot_url = py.plot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('25-34', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62e40e63d0>), ('35-49', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6f0c290>), ('50-64', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6eac590>), ('18-24', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6ebddd0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6e33390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6e05c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6d8c310>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6d02290>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6cd9790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6c4f810>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6bad110>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6b26350>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6bd6990>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6a799d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c69f4950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c69cfe50>]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "rowlength = grouped.ngroups/2                         # fix up if odd number of groups\n",
    "fig, axs = plt.subplots(figsize=(9,4), \n",
    "                        nrows=2, ncols=rowlength,     # fix as above\n",
    "                        gridspec_kw=dict(hspace=0.4)) # Much control of gridspec\n",
    "\n",
    "targets = zip(grouped.groups.keys(), axs.flatten())\n",
    "print targets\n",
    "grouped.get_group('18-24').hist(alpha=0.4)\n",
    "#for i, (key, ax) in enumerate(targets):\n",
    "#    ax.plot(grouped.get_group(key))\n",
    "#    ax.set_title('a=%s'%str(key))\n",
    "#ax.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = data.groupby('class')\n",
    "grouped.mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BAR PLOTS OF MEAN VALUE OF FEATURES FOR EACH CLASS ######\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "plt.figure()\n",
    "grouped.mean().T.plot(kind='bar', figsize=(60,10))\n",
    "plt.savefig('test1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Distribution over a feature for each class #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grouped = data.groupby('class')\n",
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "#fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(6,6)) # create the axes\n",
    "j = 0\n",
    "for key in list(data.columns.values):\n",
    "#    ix = numpy.unravel_index(j, ax.shape)\n",
    "#    print ix\n",
    "    print key\n",
    "    if key!='class':\n",
    "        j += 1\n",
    "        plt.figure(j, figsize=(10,10))\n",
    "        grouped[key].plot(kind='kde', alpha=0.8, legend=grouped.groups.keys(), title=key)\n",
    "    #g = grouped[key]\n",
    "    #print grouped[key].mean()\n",
    "    #if j==1:\n",
    "    #    tmp = g.mean()\n",
    "    #else:\n",
    "    #    print g.mean()\n",
    "    #    tmp.append(g.mean())\n",
    "    #print tmp\n",
    "        plt.show()\n",
    "    #if j==2:\n",
    "    #    break\n",
    "#tmp\n",
    "    #break\n",
    "    #ax[ix] = grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "    #break\n",
    "#for key in grouped.keys:\n",
    "#    grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "#for key in grouped.groups.keys():\n",
    "#    b = grouped.get_group(key)\n",
    "#    b.plot('kin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "fig, ax = plt.subplots(nrows=nrow, ncols=ncol) # create the axes\n",
    "j = 0\n",
    "for i in feature_names: \n",
    "    ix = numpy.unravel_index(j, ax.shape)\n",
    "    #print ix\n",
    "    j += 1\n",
    "    ax[ix] = data.groupby('class').i.hist(alpha=0.4)   # go over a linear list of data # compute an appropriate index (1d or 2d)\n",
    "    #feat = feature_names[i]\n",
    "    #data.groupby('class').feat.hist(alpha=0.4, ax=ax[i])\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib outline\n",
    "plt.savefig('CameraEvolution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = grid_search.best_estimator_.steps[1][1]\n",
    "#import pydot\n",
    "import pyparsing\n",
    "\n",
    "#reload(pydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint, numpy\n",
    "from operator import itemgetter\n",
    "\n",
    "feat_importance = zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_[numpy.nonzero(clf.feature_importances_)]))\n",
    "feat_importance = sorted(feat_importance, key=itemgetter(1))[::-1]\n",
    "feat_importance\n",
    "#for i in zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_([numpy.nonzero(clf.feature_importances_)]))):\n",
    "#    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f, feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "#>>> import os\n",
    "#>>> os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydot\n",
    ">>> from IPython.display import Image  \n",
    ">>> dot_data = StringIO()  \n",
    ">>> tree.export_graphviz(clf,  out_file=dot_data,\n",
    "                         feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    ">>> graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#>>> Image(graph.create_png())   \n",
    ">>> graph.write_pdf(\"iris.pdf\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
