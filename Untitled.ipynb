{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.preprocess)\n",
    "dataset = ProfilingDataset(infolder)\n",
    "X, y = dataset.get_data(task)\n",
    "b = [X[0][0:100]]\n",
    "b.append(X[1][0:100])\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tictac.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocProfile(object):\n",
    "    \n",
    "    \"\"\" Per Document Representation. Returns an instance of a document profile.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, entry, prof_id, doc_id):\n",
    "        \"\"\" Initialization.\n",
    "            -entry : contains most information. Comes from ProfilingDataset Class.\n",
    "            -prof_id: index for intra-profile document position\n",
    "            -doc_id: index for global documend indexing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.userid = entry.userid\n",
    "        self.lang = entry.lang\n",
    "        self.media = entry.media\n",
    "        self.gender = entry.gender\n",
    "        self.age = entry.age\n",
    "        self.prof_id = prof_id\n",
    "        self.doc_id = doc_id\n",
    "        self.text = entry.texts[prof_id]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" IPython friendly output\n",
    "        :returns: str\n",
    "\n",
    "        \"\"\"\n",
    "        # automatically capture all non iterables\n",
    "        # (we want custom formatting for text list)\n",
    "        attr_string = '\\n'.join(['%s : %s' % (key, value)\n",
    "                                 for key, value in self.__dict__.items()\n",
    "                                 if not hasattr(value, '__iter__')])\n",
    "        # print a snippet\n",
    "        return attr_string\n",
    "    \n",
    "    def datafy(self, feature='none'):\n",
    "        \"\"\"Return a tuple of data - training and label if feature is not none\n",
    "\n",
    "        :feature: the feature we want the label for\n",
    "        :returns: tuple of data, label\n",
    "\n",
    "        \"\"\"\n",
    "        if feature == 'none':\n",
    "            return self.text\n",
    "        else:\n",
    "            return [self.text, self.__dict__[feature]]\n",
    "\n",
    "def createDocProfiles(dataset):\n",
    "    \"\"\" Create a list of the DocProfiles classes.\n",
    "        -dataset: ProfilingDataset Object\n",
    "        \n",
    "        returns:\n",
    "        -a list of DocProfile Objects\n",
    "    \"\"\"\n",
    "    docs = []       \n",
    "    doc_id = 0\n",
    "    for entry in dataset.entries:\n",
    "        for prof_id in range(0, len(entry.texts)):\n",
    "            docs.append(DocProfile(entry, prof_id, doc_id))\n",
    "            doc_id += 1\n",
    "    return docs\n",
    "    \n",
    "def create_target_prof_trainset(docs, target_feature):\n",
    "    \"\"\" Create a dataset according to train a specifici model regardin a certain feature.\n",
    "        Like get_data() method from ProfilingDataset class.\n",
    "        -docs: list of documents. Expects instances of class DocProfile. \n",
    "        -target_feature: filter feature\n",
    "        \n",
    "        returns:\n",
    "        (X,y) : returns tuple - list of texts, list of labels \n",
    "        \n",
    "    \"\"\"\n",
    "    wanted = []\n",
    "    for doc in docs:\n",
    "        if target_feature in doc.__dict__:\n",
    "            wanted.append(doc.datafy(feature=target_feature))\n",
    "        else:\n",
    "            raise KeyError(\"task doesn't exist in DocProfile dic()\")\n",
    "    # zip produces tuples, we want to be able to modify\n",
    "    # the contents in preprocessing in place\n",
    "    # therefore we create we replace tuples with lists using map\n",
    "    # returns tuple - list of texts, list of labels\n",
    "    return map(list, zip(*wanted))\n",
    "\n",
    "        \n",
    "docs = createDocProfiles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = [[0.25,0.25,0.25,0.25], [0.5,0,0.2,0.25], [0.2,0.3,0,0.5]]\n",
    "b = [[1,0], [0,1],[1,0]]\n",
    "numpy.dot(numpy.array(a).T,numpy.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'age'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import *\n",
    "class SOA_Model2(object):\n",
    "\n",
    "\n",
    "    \"\"\" Models that extracts Second Order Attributes (SOA) base on PAN 2013-2015 Winners\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "        \n",
    "        #stop_list = []\n",
    "        #with open(stopwords_path, 'r') as stop_inp:\n",
    "       # for w in stop_inp:\n",
    "       # stop_list.append(w.replace(\"\\n\", \"\"))\n",
    "        self.term_table = None\n",
    "        self.labels = None\n",
    "        #self.counter = CountVectorizer()\n",
    "        self.counter = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy\n",
    "        from math import log\n",
    "        \n",
    "        if y:\n",
    "            #tokens = [_twokenize.tokenizeRawTweetText(text) for text in X]\n",
    "            #voc = set()\n",
    "            #for token in tokens:\n",
    "            #    voc = voc.union(token)\n",
    "            #print len(voc)\n",
    "            #print list(voc)[:100]\n",
    "            parameters = {\n",
    "                'input':'content', \n",
    "                'encoding':'utf-8', \n",
    "                'decode_error':'ignore', \n",
    "                #'vocabulary':list(voc),\n",
    "                'tokenizer':lambda text:_twokenize.tokenizeRawTweetText(text)\n",
    "                #'max_df':0.9,\n",
    "                #'min_df':5\n",
    "                #'max_features':20000\n",
    "               }\n",
    "            self.counter.set_params(**parameters) \n",
    "            #print \"Oleeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
    "            #print texts\n",
    "            #print tokens\n",
    "            #print list(voc)\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            print len(target_profiles)\n",
    "            #return\n",
    "            doc_term = self.counter.fit_transform(X)\n",
    "            print \"Doc_Terms\"\n",
    "            print doc_term.shape\n",
    "            #return \n",
    "            #X1 = X.toarray()\n",
    "            #X1 = X1.astype('float', casting='unsafe')\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            self.labels = target_profiles\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], len(target_profiles)])\n",
    "            for i in range(0, doc_term.shape[0]):\n",
    "                tmp = numpy.zeros([1,len(target_profiles)])\n",
    "                tmp[0, target_profiles.index(y[i])] = 1\n",
    "                doc_prof[i,:] = tmp\n",
    "            print \"Doc_Prof\"\n",
    "            print doc_prof.shape\n",
    "            term_prof = numpy.zeros([doc_term.shape[1], len(target_profiles)])\n",
    "            term_prof = numpy.dot(numpy.log2(doc_term.toarray().astype('float', casting='unsafe').T + 1), doc_prof)\n",
    "            print \"Term_Prof\"\n",
    "            print term_prof.shape\n",
    "            term_prof = term_prof / numpy.reshape(term_prof.sum(axis=1), (term_prof.sum(axis=1).shape[0], 1))\n",
    "            #term_prof = term_prof / term_prof.sum(axis=0)\n",
    "            self.term_table = term_prof\n",
    "            print \"GG\"\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        if self.labels==None:\n",
    "            raise AttributeError('term_table was no found! Probably model was not fitted first. Run model.fit(X,y)!')\n",
    "        else:\n",
    "            doc_term = self.counter.transform(X)\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], self.term_table.shape[1]])\n",
    "            doc_prof = numpy.dot(doc_term.toarray().astype('float', casting='unsafe'), self.term_table)\n",
    "            return doc_prof\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        doc_prof = self.transform(X)\n",
    "        y_pred = []\n",
    "        for i in range(0, doc_prof.shape[0]):\n",
    "            y_pred.append(self.labels[numpy.argmax(doc_prof[i])])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import _twokenize\n",
    "import pan\n",
    "reload(pan)\n",
    "c = SOA_Model2()\n",
    "c.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = c.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in c.counter.vocabulary_.iteritems():\n",
    "    if v>8000 and v< 9000:\n",
    "        pass\n",
    "        #print k, v\n",
    "top_words = [[] for i in range(0, c.term_table.shape[1])]\n",
    "cc= 0\n",
    "for i in range(0, c.term_table.shape[0]):\n",
    "    if max(c.term_table[i]) > 0.7:\n",
    "        #print c.term_table[i], c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)]\n",
    "        top_words[list(c.term_table[i]).index(max(c.term_table[i]))].append(c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)])\n",
    "        cc += 1\n",
    "top_words\n",
    "        #c.term_table /= c.term_table[8411].sum(axis= 0)\n",
    "#c.term_table[8411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "tmp = numpy.zeros([2,4])\n",
    "tmp[0,1]=1\n",
    "tmp[0,3]= 1\n",
    "tmp[1,2] = 1\n",
    "tmp / numpy.reshape(tmp.sum(axis=1), (tmp.sum(axis=1).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model2()\n",
    "c.fit_transform(X, y)\n",
    "a = [\"I am very good!\"]\n",
    "#c.transform(X, y)\n",
    "#from pprint import pprint\n",
    "#pprint(dataset.get_data()[0])\n",
    "#pprint(dataset.entries[0].texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "aaa = numpy.asarray([[1, 2], [3, 4]], dtype=float)\n",
    "bb = aaa.sum(axis=1)\n",
    "print numpy.reshape(bb, (1,2))\n",
    "print aaa/numpy.reshape(bb, (bb.shape[0],1))\n",
    "print aaa/aaa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import normalize\n",
    "aaa = numpy.asarray([[1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "print \"sci-kit\"\n",
    "cc = normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(cc, axis=0, norm='l1')\n",
    "print numpy.sum(aaa,axis=1, keepdims=True)\n",
    "print numpy.linalg.norm(aaa, axis=1)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=1, keepdims=True), dtype=float)\n",
    "print numpy.sum(aaa,axis=0, keepdims=True)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=0, keepdims=True), dtype=float)\n",
    "print aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pan\n",
    "reload(pan.features)\n",
    "log = []\n",
    "#import logging\n",
    "#log = logging.getLogger()\n",
    "#log.setLevel(logging.INFO)\n",
    "#log.addHandler(logging.StreamHandler())\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "modelfile\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    if task == \"age\":\n",
    "        X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)\n",
    "print('Writing model to {}'.format(modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tictacs\n",
    "tictacs.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "a.add(2)\n",
    "a.add(3)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model()\n",
    "a = [\"I am very good!\"]\n",
    "#aa = c.fit_transform(a)\n",
    "print b\n",
    "c.fit([b])\n",
    "print aa\n",
    "print c.counter.vocabulary_\n",
    "kk = c.transform([b])\n",
    "print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "            \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    " # remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "from pprint import pprint   # pretty-printer\n",
    "pprint(texts)\n",
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "model = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pow(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "all_models = {}\n",
    "docs = createDocProfiles(dataset)\n",
    "for task in tasks:\n",
    "    if task =='age':\n",
    "        print('Learning to judge %s..' % task)\n",
    "        # load data\n",
    "        X, y = create_target_prof_trainset(docs, task)\n",
    "        #X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model =gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100, minimum_probability=0)\n",
    "a = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "lsi[corpus[2]]\n",
    "import numpy\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = lsi[corpus]\n",
    "l = [list(zip(*cc)[1]) for cc in c]\n",
    "#l = []\n",
    "#for cc in c:\n",
    "    #print cc\n",
    "#    l.append(list(zip(*cc)[1]))\n",
    "print numpy.array(l)\n",
    "    #print list(zip(*cc)[1])\n",
    "    #for k in cc:\n",
    "    #    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan.features\n",
    "reload(pan.features)\n",
    "pan.features.TWCNB.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from tictacs import from_recipe\n",
    "from json import dumps\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if (task != \"age\") and (task !=\"gender\"):\n",
    "    #    X, y = dataset.get_data(task)\n",
    "    # else:\n",
    "    #    docs = createDocProfiles(dataset)\n",
    "    #    X, y = create_target_prof_trainset(docs, task)\n",
    "    X, y = dataset.get_data(task)\n",
    "    # y = [yy.lower() for yy in y]\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    # from collections import Counter\n",
    "    # import pprint\n",
    "    # pprint.pprint(Counter(y))\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Trainining instances: %s\\n' % (len(X))\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    log.append('\\nResults for %s - %s with classifier %s' %\n",
    "               (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        # y_pred = grid_cv.best_estimator_.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(y)\n",
    "        # conf = confusion_matrix(y, y_pred, labels=list(set(y)))\n",
    "        accuracy = grid_cv.best_score_\n",
    "        # accuracy2 = accuracy_score(y, y_pred)\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "        import pprint\n",
    "        pprint.pprint(grid_cv.grid_scores_)\n",
    "        with open('./comb_res/res.txt', 'a') as out:\n",
    "            out.write(' Results: %s - %s, params: %s ,Accuracy_Mean: %s\\n' %\n",
    "                      (dataset.lang, task,\n",
    "                       dumps(grid_cv.best_params_), grid_cv.best_score_))\n",
    "        # log.append('Best accuracy: {} '.format(accuracy2))\n",
    "        # log.append('Best Confusion matrix :\\n {}'.format(conf))\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        raise KeyError('task %s was not found in task list!' % task)\n",
    "\n",
    "\n",
    "\n",
    "infolder = '/media/bogas/My Passport/work/workspace/PAN16/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29'\n",
    "num_folds = 3\n",
    "time_start = time.time()\n",
    "print('Loading dataset...')\n",
    "#dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    import pprint\n",
    "    #pprint.pprint(tictac.__dict__)\n",
    "    #exit(1)\n",
    "    steps = tictac.steps\n",
    "    #print type(steps)\n",
    "    outline = \"\"\n",
    "    for step in steps:\n",
    "        if step[0]==\"features\":\n",
    "            # print type(step[1])\n",
    "            for tf in step[1].transformer_list:\n",
    "                #print type(tf[1])\n",
    "                #print type(tf[1].get_params())\n",
    "                outline += tf[0] + \" with Params:[\" + str(tf[1].get_params()) + \"]+\"\n",
    "        else:\n",
    "#            if hasattr(step[1], 'get_params'):\n",
    "#                outline += step[0] + \" with Params:[\" + str(step[1].get_params()) + \"]+\"\n",
    "#            else:\n",
    "#                outline += step[0]+ \"+\"\n",
    "            outline += step[0]+ \"+\"\n",
    "            outline += str(step[1].__dict__)\n",
    "    \n",
    "    outline = outline[:-1] + \"\\n\"\n",
    "    print('Task:{}, Pipeline:{}'.format(task, outline))\n",
    " #   with open('./comb_res/res.txt', 'a') as out:\n",
    " #       out.write('Task:{}, Pipeline:{}'.format(task, outline))\n",
    " #   cross_val(dataset, task, tictac, num_folds)\n",
    "# print results at end\n",
    "print('\\n--------------- Thy time of Judgement ---------------')\n",
    "print ('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "#with open('./comb_res/res.txt', 'a') as out:\n",
    "#    out.write('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "for message in log:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.pickles(tictac)\n",
    "dill.detect.badtypes(tictac).__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### TRAIN ############\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"./media/bogas/My Passport/work/workspace/PAN16/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    all_models[task] = tictac.fit(X, y)\n",
    "modelfile = os.path.join(outfolder, '%s2.bin' % dataset.lang)\n",
    "print('Writing model to {}'.format(modelfile))\n",
    "#fo = open(modelfile,  'wb')\n",
    "#import pprint\n",
    "#print type(all_models)\n",
    "#print modelfile\n",
    "#dill.dump(all_models, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#fo.close()\n",
    "# pickle.dump(all_models, modelfile)\n",
    "# dill.dump(all_models, modelfile)\n",
    "joblib.dump(all_models, modelfile, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "a = numpy.array([[1,2],[3,4]], dtype=float)\n",
    "b = numpy.array([[0.1,0.2],[0.3,0.4]], dtype=float)\n",
    "type(a[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "print a.shape\n",
    "b = numpy.tile(a, (5, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = b.sum(axis=1)\n",
    "print c.shape, type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import pprint\n",
    "pprint.pprint(a)\n",
    "normalize(a, norm='l1', axis=1, copy=False)\n",
    "pprint.pprint(a)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": null,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"/media/bogas/My Passport/work/workspace/PAN16/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "import pprint\n",
    "print \"Num of samples: \" + str(len(y))\n",
    "pprint.pprint(Counter(y))\n",
    "X, y = dataset.get_data('age')\n",
    "print len(X)\n",
    "\n",
    "X, X_cv, X, y_cv = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.5, random_state=42, stratify=y_cv)\n",
    "\n",
    "print len(X_cv), len(X_test), len(X) , len(X)+ len(X_cv) + len(X_test)\n",
    "pprint.pprint(Counter(y))\n",
    "pprint.pprint(Counter(y_cv))\n",
    "pprint.pprint(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 172,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "    -Cleaning html\n",
      "    -Detwittifying\n",
      "    -Removing Numbers\n",
      "    -Removing Punctuation\n",
      "    -Removing Links\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "X, y = dataset.get_data('age')\n",
    "#X, y = dataset.get_data('gender')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams+soa+soac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smo...ulary=None)), ('soa', SOA_Model2(max_df=1.0, max_features=None, min_df=5, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000)\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
<<<<<<< HEAD
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
=======
    "#svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('3grams', grams3), ('soac', soac)])\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + SOA+SOAC. Ommit preprocess!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "features.SOAC_Model2.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "scaler = StandardScaler()#MinMaxScaler()#StandardScaler()\n",
    "#svm = DecisionTreeClassifier()\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe = Pipeline([('3grams', grams3), ('svm', svm)])\n",
    "#pipe = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pan.features import LDA\n",
    "\n",
    "LDAmodel = LDA(num_topics=30, lib='sklearn')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "#svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced')\n",
    "svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('LDA', LDAmodel)])#, ('soa', soa), ('soac', soac)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDAA = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1]\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\" \".join([feature_names[i]\n",
    "        #                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "#print_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "     \n",
    "    feat = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        feat.append(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\"#%d: \" % topic_idx + topic_words)\n",
    "    return feat\n",
    "get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "print len(feature_names)\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "feature_names = copy.deepcopy(countTokens.l)\n",
    "feature_names += ['numHash', 'numUrl', 'numRep']\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(countTokens.l), len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "#features.SOAC_Model2.__doc__\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "#y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = [#\"I like playing video games very much :).\", \n",
    "     #\"Football games are the best!\",\n",
    "     #\"Being young forever is very funny and entertaining\",\n",
    "     # \"Football games are the best!\",\n",
    "      \"best games\",\n",
    "      \"best games\",\n",
    "     #\"World leaders should gather and decide for todays meeting!\",\n",
    "     #\"Problems nowadays seem to thrive everywhere\",\n",
    "     #\"Just got off from work today! Weekend is coming though, so it's alright...\",\n",
    "     #\"This weekend we are going of for 3 days..\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\"]\n",
    "yy = [\"18-24\",\n",
    "     \"18-24\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "    ]\n",
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "XX = preprocess.preprocess(XX)\n",
    "num_folds = 2\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(XX,yy)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = soac.fit_transform(X[0:10], y[0:10])\n",
    "print xx\n",
    "print y[0:10]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 173,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 173,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soac', soac)])\n",
    "svm = SVC(kernel='linear', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soa', soa)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe2= Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe2.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search1 = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search1.fit(X,y)\n",
    "print(grid_search1.best_estimator_)\n",
    "print(grid_search1.best_score_)\n",
    "grid_search2 = GridSearchCV(estimator=pipe2, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search2.fit(X,y)\n",
    "print(grid_search2.best_estimator_)\n",
    "print(grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 174,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "We are fitting!\n",
      "[[ 15.57142857   3.11428571   2.3956044    5.45        72.66666667]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_profDoc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!Doc_profDoc_profDoc_profDoc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Doc_prof(110, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are fitting!We are fitting!We are fitting!We are fitting!We are fitting!We are fitting!We are fitting!(108, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We are fitting![[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]]We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "\n",
      "Doc_profDoc_profDoc_profDoc_profDoc_profDoc_profDoc_profWe are transforming!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Doc_prof(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "Doc_profDoc_profDoc_profDoc_profDoc_profDoc_profDoc_profWe are transforming!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Doc_prof(110, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
<<<<<<< HEAD
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
=======
      "       transformer_weights=None)), ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='linear',\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.474770642202\n",
      "{'svm__C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.3s finished\n"
=======
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   20.4s finished\n"
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "params={'svm__C':[0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(estimator=pipe1, param_grid=params, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X,y)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1), ('2', pipe2)], voting='soft')\n",
    "trained_models = []\n",
    "for model in [pipe, pipe1, pipe2, eclf]:\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for model in trained_models:\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 88 436 436\n",
<<<<<<< HEAD
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
=======
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!We are transforming!We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "\n",
      "Doc_profDoc_prof\n",
      "Doc_profDoc_prof\n",
      "Doc_profDoc_prof\n",
      "\n",
      "Doc_prof\n",
      "\n",
      "Doc_prof\n",
      "\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profWe are transforming!Doc_profDoc_profWe are transforming!\n",
      "Doc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Doc_prof\n",
      "\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "Doc_prof(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "We are fitting!We are fitting!\n",
      "We are fitting!We are fitting!(86, 5) <type 'numpy.ndarray'>\n",
      "We are fitting!We are fitting!\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "We are fitting!\n",
      "\n",
      "[[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]]We are fitting![[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]]\n",
      "[[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]]\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
=======
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "\n",
      "\n",
      "[[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "We are transforming!\n",
<<<<<<< HEAD
      "Doc_Terms\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "0.456896551724\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngra...',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
=======
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "We are transforming!\n",
      "[[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]We are transforming!\n",
      "We are transforming!\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_prof\n",
      "Doc_profDoc_profWe are transforming!\n",
      "Doc_profDoc_prof\n",
      "\n",
      "We are transforming!\n",
      "\n",
      "\n",
<<<<<<< HEAD
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.454022988506\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537)\n",
      "(261, 14138)\n",
      "(262, 14058)\n",
      "(262, 13356)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(13537, 5) <type 'numpy.ndarray'>\n",
      "(14138, 5) <type 'numpy.ndarray'>\n",
      "(14058, 5) <type 'numpy.ndarray'>\n",
      "(13356, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.          0.44151325  0.06550793  0.49297881  0.        ]\n",
      "[ 0.          0.72245332  0.27754668  0.          0.        ]\n",
      "[ 0.          0.34643333  0.17271636  0.48085031  0.        ]\n",
      "[ 0.          0.30669112  0.21100297  0.48230591  0.        ]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
=======
      "Doc_prof\n",
      "\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "Doc_prof(262, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "We are transforming!\n",
      "We are transforming!\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
<<<<<<< HEAD
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are fitting!We are fitting!We are fitting!We are fitting!\n",
      "\n",
      "\n",
      "\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
=======
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_prof(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_profDoc_profWe are transforming!\n",
      "Doc_profDoc_prof\n",
      "\n",
      "We are transforming!\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "\n",
      "\n",
      "Doc_prof\n",
      "\n",
<<<<<<< HEAD
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(89, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(87, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "[ 1.26691404  1.66449085  2.30417331  1.78089942  1.03220281]\n",
      "[ 2.37359272  2.92592043  2.90394709  3.1043561   1.68510674]\n",
      "[ 1.59815326  1.92811313  2.18654839  2.30936014  1.40540878]\n",
      "[ 2.26109734  2.51535375  2.34143872  2.25845794  1.45798678]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(348, 16756)\n",
      "Doc_Prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(16756, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.          0.43153198  0.17457671  0.39389131  0.        ]\n",
      "SOA Model Fitted!\n",
=======
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "Doc_prof(86, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.451149425287\n",
      "{'svm__C': 10}\n",
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
      "We are transforming!\n",
      "Doc_prof\n",
<<<<<<< HEAD
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.471264367816\n",
      "VotingClassifier(estimators=[('0', Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]))],\n",
      "         voting='soft', weights=None)\n"
=======
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.534090909091\n",
      "Confusion matrix :\n",
      " [[14 13  1  0  0]\n",
      " [ 5 31  1  0  0]\n",
      " [ 4 11  1  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n"
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.8s finished\n"
=======
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   16.3s finished\n"
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
<<<<<<< HEAD
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "trained_models = []\n",
    "for model in [pipe, pipe1, eclf]:\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
=======
    "params={'svm__C':[0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(estimator=pipe1, param_grid=params, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "predict = grid_search.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, predict)\n",
    "conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Confusion matrix :\\n {}'.format(conf))"
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 189,
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "Accuracy : 0.534090909091\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 6 29  2  0  0]\n",
      " [ 4 10  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.511363636364\n",
      "Confusion matrix :\n",
      " [[ 9 17  0  2  0]\n",
      " [ 2 33  0  2  0]\n",
      " [ 1 14  1  0  0]\n",
      " [ 2  2  0  2  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.568181818182\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 5 32  0  0  0]\n",
      " [ 5  9  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n"
=======
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "(436, 5)\n",
      "2\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Sample: 0 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.03680145  0.          0.09673187  0.08319149  0.06251936]\n",
      "Ok!\n",
      "Sample: 1 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.15388624  0.23611646  0.          0.04165323  0.11786924]\n",
      "Sample: 2 Predicted: 25-34 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05564795  0.02475178  0.13712722  0.          0.03522449]\n",
      "Ok!\n",
      "Sample: 3 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07454545  0.17993111  0.          0.10979615  0.07791177]\n",
      "Ok!\n",
      "Sample: 4 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.0515752   0.          0.13030045  0.08300473  0.07463363]\n",
      "Ok!\n",
      "Sample: 5 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.12377488  0.          0.26252535  0.20889583  0.15512157]\n",
      "Ok!\n",
      "Sample: 6 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.2419666   0.37239063  0.          0.14155962  0.20672269]\n",
      "Ok!\n",
      "Sample: 7 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.0528674   0.09427916  0.          0.02972267  0.0465439 ]\n",
      "Ok!\n",
      "Sample: 8 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.21518202  0.03940951  0.2073064   0.12341516]\n",
      "Sample: 9 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.03578942  0.01157736  0.          0.01336465  0.02000112]\n",
      "Ok!\n",
      "Sample: 10 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.0304605   0.          0.02176718  0.03469181  0.0302083 ]\n",
      "Sample: 11 Predicted: 25-34 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05180941  0.          0.15048616  0.02937731  0.05457928]\n",
      "Sample: 12 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07262933  0.03578586  0.          0.06395965  0.0558737 ]\n",
      "Ok!\n",
      "Sample: 13 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.13833393  0.21796129  0.03968174  0.          0.10616056]\n",
      "Ok!\n",
      "Sample: 14 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.01192026  0.07956867  0.05268871  0.          0.03243631]\n",
      "Sample: 15 Predicted: 25-34 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05182951  0.          0.14821246  0.02500735  0.04969501]\n",
      "Sample: 16 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06428769  0.          0.1207258   0.11861918  0.08697641]\n",
      "Ok!\n",
      "Sample: 17 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.16517649  0.31057735  0.          0.18816511  0.17067304]\n",
      "Ok!\n",
      "Sample: 18 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.1703819   0.          0.20879825  0.2237213   0.14784517]\n",
      "Sample: 19 Predicted: 25-34 Truth: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04608255  0.          0.22197549  0.17291697  0.1161271 ]\n",
      "Sample: 20 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.15840766  0.24467513  0.          0.08184186  0.13221784]\n",
      "Ok!\n",
      "Sample: 21 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.16768683  0.27107663  0.          0.12607659  0.14308292]\n",
      "Ok!\n",
      "Sample: 22 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.0553131   0.06297005  0.          0.01933403  0.04237562]\n",
      "Ok!\n",
      "Sample: 23 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.10841498  0.          0.27488914  0.16648824  0.12680052]\n",
      "Ok!\n",
      "Sample: 24 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07431622  0.          0.17138269  0.11516956  0.09746752]\n",
      "Ok!\n",
      "Sample: 25 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.02565676  0.          0.14773632  0.12165595  0.08016098]\n",
      "Ok!\n",
      "Sample: 26 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.13845563  0.          0.20430532  0.25604146  0.16856503]\n",
      "Ok!\n",
      "Sample: 27 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07057962  0.          0.02618362  0.03782988  0.04685337]\n",
      "Sample: 28 Predicted: 25-34 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.16186103  0.          0.26018171  0.20196475  0.16787779]\n",
      "Sample: 29 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.02612502  0.06466065  0.01624989  0.          0.03415758]\n",
      "Ok!\n",
      "Sample: 30 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.0789096   0.0585934   0.          0.04412078  0.05763058]\n",
      "Ok!\n",
      "Sample: 31 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.23292571  0.35183203  0.          0.20584906  0.20811416]\n",
      "Sample: 32 Predicted: 25-34 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07670743  0.          0.18630443  0.13168588  0.09499016]\n",
      "Sample: 33 Predicted: 25-34 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07866692  0.          0.11318104  0.03192692  0.05950996]\n",
      "Ok!\n",
      "Sample: 34 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.13883473  0.          0.20376681  0.15255422  0.13753546]\n",
      "Ok!\n",
      "Sample: 35 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.00618155  0.          0.05480068  0.01121333  0.02082185]\n",
      "Ok!\n",
      "Sample: 36 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04782548  0.08080339  0.          0.00203204  0.03873207]\n",
      "Sample: 37 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07540885  0.          0.02793855  0.05843635  0.05273762]\n",
      "Ok!\n",
      "Sample: 38 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.00810065  0.01953054  0.01830458  0.          0.02097051]\n",
      "Sample: 39 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.2091262   0.03910935  0.11053748  0.0918059 ]\n",
      "Ok!\n",
      "Sample: 40 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.11780322  0.          0.31920186  0.17244313  0.1479788 ]\n",
      "Sample: 41 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07134513  0.04016761  0.          0.0382951   0.04971714]\n",
      "Sample: 42 Predicted: 50-64 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.10683257  0.24909912  0.09783207  0.          0.10347628]\n",
      "Sample: 43 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06851451  0.09979841  0.04529163  0.          0.05743345]\n",
      "Ok!\n",
      "Sample: 44 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04011713  0.          0.03718953  0.02843048  0.02874874]\n",
      "Sample: 45 Predicted: 25-34 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.19344939  0.          0.20817344  0.17162632  0.15986619]\n",
      "Ok!\n",
      "Sample: 46 Predicted: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.33765281  0.27865253  0.20528592  0.18633088]\n",
      "Sample: 47 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05133885  0.          0.11883451  0.05208384  0.04819827]\n",
      "Ok!\n",
      "Sample: 48 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05196943  0.1029946   0.          0.0545805   0.05543737]\n",
      "Sample: 49 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.03286696  0.          0.09935352  0.06884397  0.05191714]\n",
      "Ok!\n",
      "Sample: 50 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.07624381  0.05462116  0.          0.05717915  0.06019089]\n",
      "Sample: 51 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.00343032  0.          0.05177403  0.14866893  0.05783985]\n",
      "Ok!\n",
      "Sample: 52 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.09089944  0.          0.1881581   0.17514699  0.12772817]\n",
      "Sample: 53 Predicted: 25-34 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.57867885  0.          0.74356329  0.7052022   0.53810774]\n",
      "Sample: 54 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04970258  0.          0.04399696  0.05409794  0.04438919]\n",
      "Sample: 55 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04601669  0.11576659  0.02957851  0.          0.04514468]\n",
      "Sample: 56 Predicted: 35-49 Truth: 65-xx\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.1297301   0.23007792  0.          0.09128972  0.12888069]\n",
      "Ok!\n",
      "Sample: 57 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.03475594  0.00778311  0.08932912  0.04681485]\n",
      "Ok!\n",
      "Sample: 58 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06557935  0.          0.11877156  0.07511478  0.07370854]\n",
      "Sample: 59 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.09499377  0.13246957  0.          0.04446876  0.0683635 ]\n",
      "Sample: 60 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.05192904  0.06827189  0.          0.05415324  0.05248534]\n",
      "Ok!\n",
      "Sample: 61 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.18534376  0.30230459  0.          0.16857649  0.16176682]\n",
      "Sample: 62 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.1627994   0.01086857  0.1748898   0.09165537]\n",
      "Sample: 63 Predicted: 35-49 Truth: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06446761  0.05639285  0.          0.08255198  0.0515336 ]\n",
      "Sample: 64 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04635019  0.13520895  0.          0.15211858  0.08619877]\n",
      "Ok!\n",
      "Sample: 65 Predicted: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.19694156  0.25960583  0.36804945  0.          0.19624963]\n",
      "Ok!\n",
      "Sample: 66 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.43186254  0.57559635  0.          0.60568422  0.44908212]\n",
      "Sample: 67 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.08147844  0.08923595  0.01105708  0.          0.05577827]\n",
      "Ok!\n",
      "Sample: 68 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06620733  0.          0.16080911  0.13469318  0.09641571]\n",
      "Sample: 69 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.02290084  0.01092433  0.05453653  0.          0.02535086]\n",
      "Ok!\n",
      "Sample: 70 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.10972946  0.03386     0.10983409  0.0565942 ]\n",
      "Sample: 71 Predicted: 35-49 Truth: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.10535416  0.11495843  0.          0.02054714  0.07290108]\n",
      "Ok!\n",
      "Sample: 72 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.14549153  0.20746974  0.          0.07890062  0.11249725]\n",
      "Sample: 73 Predicted: 50-64 Truth: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.          0.09943468  0.16161259  0.00535309  0.00340991]\n",
      "Ok!\n",
      "Sample: 74 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.04751908  0.          0.07827923  0.06411227  0.05834091]\n",
      "Sample: 75 Predicted: 25-34 Truth: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.12666745  0.          0.33019955  0.23029994  0.17112489]\n",
      "Ok!\n",
      "Sample: 76 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.10200099  0.          0.1988818   0.18985681  0.13237703]\n",
      "Ok!\n",
      "Sample: 77 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.15822566  0.31788858  0.          0.20098806  0.17744356]\n",
      "Sample: 78 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.06076201  0.          0.0709151   0.09156475  0.06618816]\n",
      "Sample: 79 Predicted: 35-49 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.08021924  0.10799633  0.          0.00623092  0.0551591 ]\n",
      "Ok!\n",
      "Sample: 80 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.08050761  0.          0.1905234   0.14413602  0.11170545]\n",
      "Ok!\n",
      "Sample: 81 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.03748335  0.03459487  0.          0.00262007  0.01650322]\n",
      "Ok!\n",
      "Sample: 82 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.11269818  0.          0.190212    0.16954887  0.1305221 ]\n",
      "Sample: 83 Predicted: 25-34 Truth: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.13878919  0.          0.21978542  0.2135918   0.14985015]\n",
      "Ok!\n",
      "Sample: 84 Predicted: 25-34\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.10042161  0.          0.21094014  0.15249021  0.11563271]\n",
      "Sample: 85 Predicted: 35-49 Truth: 18-24\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.02103452  0.01837953  0.          0.07005778  0.03870532]\n",
      "Sample: 86 Predicted: 25-34 Truth: 50-64\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.08560146  0.          0.14347621  0.03128011  0.06671699]\n",
      "Ok!\n",
      "Sample: 87 Predicted: 35-49\n",
      "['18-24', '25-34', '35-49', '50-64', '65-xx']\n",
      "[ 0.03558772  0.          0.12163984  0.11285125  0.0444011 ]\n"
>>>>>>> 40143e9b194945fa5180cf1cf1f0fa9683a57761
     ]
    }
   ],
   "source": [
    "a = grid_search.best_estimator_.steps[0][1]\n",
    "print a.transform(X).shape\n",
    "print(len(feature_names))\n",
    "transformed = a.transform(X_cv)\n",
    "for i, k in enumerate(predict):\n",
    "    if k!=y_cv[i]:\n",
    "        print \"Sample: \" + str(i) + \" Predicted: \" + str(k)+ \" Truth: \" + str(y_cv[i])\n",
    "        #print X[i]\n",
    "        print sorted(list(set(y)))\n",
    "        print transformed[i]\n",
    "    else:\n",
    "        print \"Ok!\"\n",
    "        print \"Sample: \" + str(i) + \" Predicted: \" + str(k)\n",
    "        #print X[i]\n",
    "        print sorted(list(set(y)))\n",
    "        print transformed[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#feature_names = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1].get_feature_names()\n",
    "feature_names = []\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "feature_names += soac_feat_names\n",
    "print len(feature_names)\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "(436, 2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = grid_search.best_estimator_.steps[0][1]\n",
    "print a.transform(X).shape\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "       soac_prob_0  soac_prob_1\n",
      "count   436.000000   436.000000\n",
      "mean      0.948026     0.899543\n",
      "std       1.365312     1.236423\n",
      "min       0.000000     0.000000\n",
      "25%       0.000000     0.000000\n",
      "50%       0.065739     0.000000\n",
      "75%       1.575124     1.472582\n",
      "max      11.153732     5.961482\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(a.transform(X), columns=feature_names)\n",
    "data[\"class\"] = y\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('25-34', <matplotlib.axes._subplots.AxesSubplot object at 0x7f4418480f90>), ('35-49', <matplotlib.axes._subplots.AxesSubplot object at 0x7f43f1215090>), ('50-64', <matplotlib.axes._subplots.AxesSubplot object at 0x7f44191255d0>), ('18-24', <matplotlib.axes._subplots.AxesSubplot object at 0x7f441a0aabd0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f43f12a0b50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f4419895390>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f44180a1c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f441a2b0a10>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f4417fd5390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f44186a1dd0>]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "rowlength = grouped.ngroups/2                         # fix up if odd number of groups\n",
    "fig, axs = plt.subplots(figsize=(9,4), \n",
    "                        nrows=2, ncols=rowlength,     # fix as above\n",
    "                        gridspec_kw=dict(hspace=0.4)) # Much control of gridspec\n",
    "\n",
    "targets = zip(grouped.groups.keys(), axs.flatten())\n",
    "print targets\n",
    "grouped.get_group('18-24').hist(alpha=0.4)\n",
    "#for i, (key, ax) in enumerate(targets):\n",
    "#    ax.plot(grouped.get_group(key))\n",
    "#    ax.set_title('a=%s'%str(key))\n",
    "#ax.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = data.groupby('class')\n",
    "grouped.mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BAR PLOTS OF MEAN VALUE OF FEATURES FOR EACH CLASS ######\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "plt.figure()\n",
    "grouped.mean().T.plot(kind='bar', figsize=(60,10))\n",
    "plt.savefig('test1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Distribution over a feature for each class #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soac_prob_0\n",
      "soac_prob_1\n",
      "class\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grouped = data.groupby('class')\n",
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "#fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(6,6)) # create the axes\n",
    "j = 0\n",
    "for key in list(data.columns.values):\n",
    "#    ix = numpy.unravel_index(j, ax.shape)\n",
    "#    print ix\n",
    "    print key\n",
    "    if key!='class':\n",
    "        j += 1\n",
    "        plt.figure(j, figsize=(10,10))\n",
    "        grouped[key].plot(kind='hist', alpha=0.8, legend=grouped.groups.keys(), title=key)\n",
    "    #g = grouped[key]\n",
    "    #print grouped[key].mean()\n",
    "    #if j==1:\n",
    "    #    tmp = g.mean()\n",
    "    #else:\n",
    "    #    print g.mean()\n",
    "    #    tmp.append(g.mean())\n",
    "    #print tmp\n",
    "        plt.show()\n",
    "    #if j==2:\n",
    "    #    break\n",
    "#tmp\n",
    "    #break\n",
    "    #ax[ix] = grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "    #break\n",
    "#for key in grouped.keys:\n",
    "#    grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "#for key in grouped.groups.keys():\n",
    "#    b = grouped.get_group(key)\n",
    "#    b.plot('kin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "plt.figure(15, figsize=(10,10))\n",
    "radviz(data, 'class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "fig, ax = plt.subplots(nrows=nrow, ncols=ncol) # create the axes\n",
    "j = 0\n",
    "for i in feature_names: \n",
    "    ix = numpy.unravel_index(j, ax.shape)\n",
    "    #print ix\n",
    "    j += 1\n",
    "    ax[ix] = data.groupby('class').i.hist(alpha=0.4)   # go over a linear list of data # compute an appropriate index (1d or 2d)\n",
    "    #feat = feature_names[i]\n",
    "    #data.groupby('class').feat.hist(alpha=0.4, ax=ax[i])\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib outline\n",
    "plt.savefig('CameraEvolution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = grid_search.best_estimator_.steps[1][1]\n",
    "#import pydot\n",
    "import pyparsing\n",
    "\n",
    "#reload(pydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint, numpy\n",
    "from operator import itemgetter\n",
    "\n",
    "feat_importance = zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_[numpy.nonzero(clf.feature_importances_)]))\n",
    "feat_importance = sorted(feat_importance, key=itemgetter(1))[::-1]\n",
    "feat_importance\n",
    "#for i in zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_([numpy.nonzero(clf.feature_importances_)]))):\n",
    "#    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f, feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "#>>> import os\n",
    "#>>> os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydot\n",
    ">>> from IPython.display import Image  \n",
    ">>> dot_data = StringIO()  \n",
    ">>> tree.export_graphviz(clf,  out_file=dot_data,\n",
    "                         feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    ">>> graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#>>> Image(graph.create_png())   \n",
    ">>> graph.write_pdf(\"iris.pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 2) <type 'numpy.ndarray'>\n",
      "       soac_prob_0  soac_prob_1       class\n",
      "count   436.000000   436.000000  436.000000\n",
      "mean      0.948026     0.899543    0.500000\n",
      "std       1.365312     1.236423    0.500574\n",
      "min       0.000000     0.000000    0.000000\n",
      "25%       0.000000     0.000000    0.000000\n",
      "50%       0.065739     0.000000    0.500000\n",
      "75%       1.575124     1.472582    1.000000\n",
      "max      11.153732     5.961482    1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(a.transform(X), columns=feature_names)\n",
    "label2num = dict((label, i) for i, label in enumerate(sorted(set(y))))\n",
    "yy = [label2num[y_ent] for y_ent in y]\n",
    "data[\"class\"] = yy\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       soac_prob_0  soac_prob_1       class\n",
      "count   436.000000   436.000000  436.000000\n",
      "mean      0.948026     0.899543    0.500000\n",
      "std       1.365312     1.236423    0.500574\n",
      "min       0.000000     0.000000    0.000000\n",
      "25%       0.000000     0.000000    0.000000\n",
      "50%       0.065739     0.000000    0.500000\n",
      "75%       1.575124     1.472582    1.000000\n",
      "max      11.153732     5.961482    1.000000\n"
     ]
    }
   ],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "#%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = data\n",
    "print(data.describe())\n",
    "target = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, target, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        print xgb_param\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=[\"auc\"], early_stopping_rounds=early_stopping_rounds, show_progress=False) \n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label2num = dict((label, float(i)) for i, label in enumerate(sorted(set(y))))\n",
    "yy = [label2num[y_ent] for y_ent in y]\n",
    "xgbl_params = {\n",
    " 'learning_rate' : 0.1,\n",
    " 'n_estimators':1000,\n",
    " 'max_depth':5,\n",
    " 'min_child_weight':1,\n",
    " 'gamma':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'objective': 'binary:logistic',\n",
    " 'nthread':4,\n",
    " 'scale_pos_weight':1,\n",
    " 'seed':27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0, 'colsample_bytree': 0.8, 'silent': 1, 'colsample_bylevel': 1, 'scale_pos_weight': 1, 'learning_rate': 0.1, 'missing': None, 'max_delta_step': 0, 'nthread': 4, 'base_score': 0.5, 'n_estimators': 1000, 'subsample': 0.8, 'reg_lambda': 1, 'seed': 27, 'min_child_weight': 1, 'objective': 'rank:pairwise', 'max_depth': 5, 'gamma': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "colsample_bytree=0 is too small that no feature can be included",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-99c6581c1137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m  seed=27,base_score=0.5)\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-166-b257434022d5>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, predictors, target, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mxgtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n\u001b[1;32m----> 8\u001b[1;33m             metrics=[\"auc\"], early_stopping_rounds=early_stopping_rounds, show_progress=False) \n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, show_progress, show_stdv, seed)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[0;32m    420\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \"\"\"\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: colsample_bytree=0 is too small that no feature can be included"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'rank:pairwise', \n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,base_score=0.5)\n",
    "modelfit(xgb1, train, predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 1000,\n",
       " 'nthread': 4,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 27,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
