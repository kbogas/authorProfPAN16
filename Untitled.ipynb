{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 152 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'createDocProfiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-01dea240557b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"age\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mtictac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_recipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecipes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtictac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;31m# print results at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n--------------- Thy time of Judgement ---------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-01dea240557b>\u001b[0m in \u001b[0;36mcross_val\u001b[1;34m(dataset, task, model, num_folds)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#X, y = dataset.get_data(task)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateDocProfiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_target_prof_trainset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'createDocProfiles' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd\\n@username @username @username @username @', u'Everyday I come up with a new optimum solution. It proves optimum is only dependent on the time\\nRT @']\n"
     ]
    }
   ],
   "source": [
    "import pan\n",
    "reload(pan.preprocess)\n",
    "dataset = ProfilingDataset(infolder)\n",
    "X, y = dataset.get_data(task)\n",
    "b = [X[0][0:100]]\n",
    "b.append(X[1][0:100])\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__class__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                     \u001b[1;31m# printer registered in self.type_pprinters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                     \u001b[1;31m# deferred printer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tictacs/parse.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m                                \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                                else key, val)\n\u001b[1;32m--> 257\u001b[1;33m                               \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m                               ])\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tictacs/wrappers.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'%(__class__)s wrapping function %(function)s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__class__'"
     ]
    }
   ],
   "source": [
    "tictac.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocProfile(object):\n",
    "    \n",
    "    \"\"\" Per Document Representation. Returns an instance of a document profile.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, entry, prof_id, doc_id):\n",
    "        \"\"\" Initialization.\n",
    "            -entry : contains most information. Comes from ProfilingDataset Class.\n",
    "            -prof_id: index for intra-profile document position\n",
    "            -doc_id: index for global documend indexing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.userid = entry.userid\n",
    "        self.lang = entry.lang\n",
    "        self.media = entry.media\n",
    "        self.gender = entry.gender\n",
    "        self.age = entry.age\n",
    "        self.prof_id = prof_id\n",
    "        self.doc_id = doc_id\n",
    "        self.text = entry.texts[prof_id]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" IPython friendly output\n",
    "        :returns: str\n",
    "\n",
    "        \"\"\"\n",
    "        # automatically capture all non iterables\n",
    "        # (we want custom formatting for text list)\n",
    "        attr_string = '\\n'.join(['%s : %s' % (key, value)\n",
    "                                 for key, value in self.__dict__.items()\n",
    "                                 if not hasattr(value, '__iter__')])\n",
    "        # print a snippet\n",
    "        return attr_string\n",
    "    \n",
    "    def datafy(self, feature='none'):\n",
    "        \"\"\"Return a tuple of data - training and label if feature is not none\n",
    "\n",
    "        :feature: the feature we want the label for\n",
    "        :returns: tuple of data, label\n",
    "\n",
    "        \"\"\"\n",
    "        if feature == 'none':\n",
    "            return self.text\n",
    "        else:\n",
    "            return [self.text, self.__dict__[feature]]\n",
    "\n",
    "def createDocProfiles(dataset):\n",
    "    \"\"\" Create a list of the DocProfiles classes.\n",
    "        -dataset: ProfilingDataset Object\n",
    "        \n",
    "        returns:\n",
    "        -a list of DocProfile Objects\n",
    "    \"\"\"\n",
    "    docs = []       \n",
    "    doc_id = 0\n",
    "    for entry in dataset.entries:\n",
    "        for prof_id in range(0, len(entry.texts)):\n",
    "            docs.append(DocProfile(entry, prof_id, doc_id))\n",
    "            doc_id += 1\n",
    "    return docs\n",
    "    \n",
    "def create_target_prof_trainset(docs, target_feature):\n",
    "    \"\"\" Create a dataset according to train a specifici model regardin a certain feature.\n",
    "        Like get_data() method from ProfilingDataset class.\n",
    "        -docs: list of documents. Expects instances of class DocProfile. \n",
    "        -target_feature: filter feature\n",
    "        \n",
    "        returns:\n",
    "        (X,y) : returns tuple - list of texts, list of labels \n",
    "        \n",
    "    \"\"\"\n",
    "    wanted = []\n",
    "    for doc in docs:\n",
    "        if target_feature in doc.__dict__:\n",
    "            wanted.append(doc.datafy(feature=target_feature))\n",
    "        else:\n",
    "            raise KeyError(\"task doesn't exist in DocProfile dic()\")\n",
    "    # zip produces tuples, we want to be able to modify\n",
    "    # the contents in preprocessing in place\n",
    "    # therefore we create we replace tuples with lists using map\n",
    "    # returns tuple - list of texts, list of labels\n",
    "    return map(list, zip(*wanted))\n",
    "\n",
    "        \n",
    "docs = createDocProfiles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45,  0.5 ],\n",
       "       [ 0.55,  0.  ],\n",
       "       [ 0.25,  0.2 ],\n",
       "       [ 0.75,  0.25]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "a = [[0.25,0.25,0.25,0.25], [0.5,0,0.2,0.25], [0.2,0.3,0,0.5]]\n",
    "b = [[1,0], [0,1],[1,0]]\n",
    "numpy.dot(numpy.array(a).T,numpy.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'age'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import *\n",
    "class SOA_Model2(object):\n",
    "\n",
    "\n",
    "    \"\"\" Models that extracts Second Order Attributes (SOA) base on PAN 2013-2015 Winners\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "        \n",
    "        #stop_list = []\n",
    "        #with open(stopwords_path, 'r') as stop_inp:\n",
    "       # for w in stop_inp:\n",
    "       # stop_list.append(w.replace(\"\\n\", \"\"))\n",
    "        self.term_table = None\n",
    "        self.labels = None\n",
    "        #self.counter = CountVectorizer()\n",
    "        self.counter = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy\n",
    "        from math import log\n",
    "        \n",
    "        if y:\n",
    "            #tokens = [_twokenize.tokenizeRawTweetText(text) for text in X]\n",
    "            #voc = set()\n",
    "            #for token in tokens:\n",
    "            #    voc = voc.union(token)\n",
    "            #print len(voc)\n",
    "            #print list(voc)[:100]\n",
    "            parameters = {\n",
    "                'input':'content', \n",
    "                'encoding':'utf-8', \n",
    "                'decode_error':'ignore', \n",
    "                #'vocabulary':list(voc),\n",
    "                'tokenizer':lambda text:_twokenize.tokenizeRawTweetText(text)\n",
    "                #'max_df':0.9,\n",
    "                #'min_df':5\n",
    "                #'max_features':20000\n",
    "               }\n",
    "            self.counter.set_params(**parameters) \n",
    "            #print \"Oleeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
    "            #print texts\n",
    "            #print tokens\n",
    "            #print list(voc)\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            print len(target_profiles)\n",
    "            #return\n",
    "            doc_term = self.counter.fit_transform(X)\n",
    "            print \"Doc_Terms\"\n",
    "            print doc_term.shape\n",
    "            #return \n",
    "            #X1 = X.toarray()\n",
    "            #X1 = X1.astype('float', casting='unsafe')\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            self.labels = target_profiles\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], len(target_profiles)])\n",
    "            for i in range(0, doc_term.shape[0]):\n",
    "                tmp = numpy.zeros([1,len(target_profiles)])\n",
    "                tmp[0, target_profiles.index(y[i])] = 1\n",
    "                doc_prof[i,:] = tmp\n",
    "            print \"Doc_Prof\"\n",
    "            print doc_prof.shape\n",
    "            term_prof = numpy.zeros([doc_term.shape[1], len(target_profiles)])\n",
    "            term_prof = numpy.dot(numpy.log2(doc_term.toarray().astype('float', casting='unsafe').T + 1), doc_prof)\n",
    "            print \"Term_Prof\"\n",
    "            print term_prof.shape\n",
    "            term_prof = term_prof / numpy.reshape(term_prof.sum(axis=1), (term_prof.sum(axis=1).shape[0], 1))\n",
    "            #term_prof = term_prof / term_prof.sum(axis=0)\n",
    "            self.term_table = term_prof\n",
    "            print \"GG\"\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        if self.labels==None:\n",
    "            raise AttributeError('term_table was no found! Probably model was not fitted first. Run model.fit(X,y)!')\n",
    "        else:\n",
    "            doc_term = self.counter.transform(X)\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], self.term_table.shape[1]])\n",
    "            doc_prof = numpy.dot(doc_term.toarray().astype('float', casting='unsafe'), self.term_table)\n",
    "            return doc_prof\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        doc_prof = self.transform(X)\n",
    "        y_pred = []\n",
    "        for i in range(0, doc_prof.shape[0]):\n",
    "            y_pred.append(self.labels[numpy.argmax(doc_prof[i])])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Doc_Terms\n",
      "(14166, 28850)\n",
      "Doc_Prof\n",
      "(14166, 4)\n",
      "Term_Prof\n",
      "(28850, 4)\n",
      "GG\n"
     ]
    }
   ],
   "source": [
    "from pan.misc import _twokenize\n",
    "import pan\n",
    "reload(pan)\n",
    "c = SOA_Model2()\n",
    "c.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = c.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in c.counter.vocabulary_.iteritems():\n",
    "    if v>8000 and v< 9000:\n",
    "        pass\n",
    "        #print k, v\n",
    "top_words = [[] for i in range(0, c.term_table.shape[1])]\n",
    "cc= 0\n",
    "for i in range(0, c.term_table.shape[0]):\n",
    "    if max(c.term_table[i]) > 0.7:\n",
    "        #print c.term_table[i], c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)]\n",
    "        top_words[list(c.term_table[i]).index(max(c.term_table[i]))].append(c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)])\n",
    "        cc += 1\n",
    "top_words\n",
    "        #c.term_table /= c.term_table[8411].sum(axis= 0)\n",
    "#c.term_table[8411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  0. ,  0.5],\n",
       "       [ 0. ,  0. ,  1. ,  0. ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "tmp = numpy.zeros([2,4])\n",
    "tmp[0,1]=1\n",
    "tmp[0,3]= 1\n",
    "tmp[1,2] = 1\n",
    "tmp / numpy.reshape(tmp.sum(axis=1), (tmp.sum(axis=1).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Doc_Terms\n",
      "(14166, 28850)\n",
      "Doc_Prof\n",
      "(14166, 4)\n",
      "Term_Prof\n",
      "(28850, 4)\n",
      "Model Fitted!\n"
     ]
    }
   ],
   "source": [
    "import pan\n",
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model2()\n",
    "c.fit_transform(X, y)\n",
    "a = [\"I am very good!\"]\n",
    "#c.transform(X, y)\n",
    "#from pprint import pprint\n",
    "#pprint(dataset.get_data()[0])\n",
    "#pprint(dataset.entries[0].texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  7.]]\n",
      "[[ 0.33333333  0.66666667]\n",
      " [ 0.42857143  0.57142857]]\n",
      "[[ 0.25        0.33333333]\n",
      " [ 0.75        0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "aaa = numpy.asarray([[1, 2], [3, 4]], dtype=float)\n",
    "bb = aaa.sum(axis=1)\n",
    "print numpy.reshape(bb, (1,2))\n",
    "print aaa/numpy.reshape(bb, (bb.shape[0],1))\n",
    "print aaa/aaa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci-kit\n",
      "[[ 0.07142857  0.07142857  0.28571429  0.07142857  0.07142857  0.07142857\n",
      "   0.07142857  0.07142857  0.07142857  0.07142857  0.07142857]\n",
      " [ 0.07142857  0.07142857  0.28571429  0.07142857  0.07142857  0.07142857\n",
      "   0.07142857  0.07142857  0.07142857  0.07142857  0.07142857]]\n",
      "[[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]]\n",
      "[[ 14.]\n",
      " [ 14.]]\n",
      "[ 5.09901951  5.09901951]\n",
      "[[ 0.14285714  0.14285714  0.57142857  0.14285714  0.14285714  0.14285714\n",
      "   0.14285714  0.14285714  0.14285714  0.14285714  0.14285714]]\n",
      "[[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import normalize\n",
    "aaa = numpy.asarray([[1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "print \"sci-kit\"\n",
    "cc = normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(cc, axis=0, norm='l1')\n",
    "print numpy.sum(aaa,axis=1, keepdims=True)\n",
    "print numpy.linalg.norm(aaa, axis=1)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=1, keepdims=True), dtype=float)\n",
    "print numpy.sum(aaa,axis=0, keepdims=True)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=0, keepdims=True), dtype=float)\n",
    "print aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pan\n",
    "reload(pan.features)\n",
    "log = []\n",
    "#import logging\n",
    "#log = logging.getLogger()\n",
    "#log.setLevel(logging.INFO)\n",
    "#log.addHandler(logging.StreamHandler())\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "modelfile\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    if task == \"age\":\n",
    "        X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)\n",
    "print('Writing model to {}'.format(modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tictacs\n",
    "tictacs.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-50feede7335e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "a.add(2)\n",
    "a.add(3)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Test Your Startup Idea for $50 http://t.co/JTRdxtnd\n",
      "@username @username @username @username @\n",
      "\n",
      "{u'username': 10, u'jtrdxtnd': 6, u'http': 4, u'for': 2, u'how': 3, u'startup': 7, u'idea': 5, u'50': 0, u'to': 9, u'test': 8, u'co': 1, u'your': 11}\n",
      "11\n",
      "Oleeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "types\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "values\n",
      "shape:\n",
      "(1, 12)\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model()\n",
    "a = [\"I am very good!\"]\n",
    "#aa = c.fit_transform(a)\n",
    "print b\n",
    "c.fit([b])\n",
    "print aa\n",
    "print c.counter.vocabulary_\n",
    "kk = c.transform([b])\n",
    "print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
      "built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "            \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    " # remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "from pprint import pprint   # pretty-printer\n",
    "pprint(texts)\n",
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "using symmetric alpha at 0.2\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "running online LDA training, 5 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-4.927 per-word bound, 30.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "PROGRESS: pass 0, at document #9/9\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "INFO:gensim.models.ldamodel:topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "topic diff=2.500150, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "topic #0 (0.200): 0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "topic #1 (0.200): 0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "topic #2 (0.200): 0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "topic #3 (0.200): 0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n",
      "topic #4 (0.200): 0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0.339*trees + 0.187*graph + 0.187*minors + 0.032*user + 0.032*system + 0.032*human + 0.032*interface + 0.032*response + 0.032*eps + 0.032*computer',\n",
       " u'0.087*trees + 0.084*graph + 0.084*system + 0.083*human + 0.083*user + 0.083*time + 0.083*interface + 0.083*minors + 0.083*computer + 0.083*survey',\n",
       " u'0.256*system + 0.134*user + 0.134*eps + 0.073*survey + 0.073*computer + 0.073*time + 0.073*response + 0.073*human + 0.073*interface + 0.013*trees',\n",
       " u'0.221*graph + 0.220*minors + 0.220*survey + 0.039*trees + 0.038*user + 0.038*human + 0.038*system + 0.038*time + 0.037*interface + 0.037*eps',\n",
       " u'0.115*trees + 0.115*user + 0.115*interface + 0.115*response + 0.115*computer + 0.115*time + 0.115*graph + 0.115*human + 0.020*minors + 0.020*system']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "model = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "-3.631 per-word bound, 12.4 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.631169731543713"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16666667         nan]\n",
      " [ 0.83333333         nan]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "all_models = {}\n",
    "docs = createDocProfiles(dataset)\n",
    "for task in tasks:\n",
    "    if task =='age':\n",
    "        print('Learning to judge %s..' % task)\n",
    "        # load data\n",
    "        X, y = create_target_prof_trainset(docs, task)\n",
    "        #X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model =gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100, minimum_probability=0)\n",
    "a = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "lsi[corpus[2]]\n",
    "import numpy\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.33498192e-01  -1.05089526e-01]\n",
      " [  2.03199237e+00   4.71453141e-02]\n",
      " [  1.53513428e+00  -1.34887841e-01]\n",
      " [  1.95400772e+00  -2.17804986e-01]\n",
      " [  1.29024730e+00   2.25214375e-03]\n",
      " [  2.27830819e-02   7.77805260e-01]\n",
      " [  5.67156758e-02   1.18277034e+00]\n",
      " [  1.23600033e-01   2.63430686e+00]\n",
      " [  2.35606272e-01   9.40793620e-01]]\n"
     ]
    }
   ],
   "source": [
    "c = lsi[corpus]\n",
    "l = [list(zip(*cc)[1]) for cc in c]\n",
    "#l = []\n",
    "#for cc in c:\n",
    "    #print cc\n",
    "#    l.append(list(zip(*cc)[1]))\n",
    "print numpy.array(l)\n",
    "    #print list(zip(*cc)[1])\n",
    "    #for k in cc:\n",
    "    #    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dictproxy {'__doc__': ' Models that extracts Second Order Attributes\\n     based on Rennie, Shih, Teevan and Karger </Paper>',\n",
       " '__init__': <function pan.features.__init__>,\n",
       " '__module__': 'pan.features',\n",
       " 'fit': <function pan.features.fit>,\n",
       " 'transform': <function pan.features.transform>}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pan.features\n",
    "reload(pan.features)\n",
    "pan.features.TWCNB.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Task:age, Pipeline:clean html+detwittify+twcnb with Params:[{'max_features': 5000, 'max_df': 1.0, 'min_df': 5}]+soa_model with Params:[{'max_features': 5000, 'max_df': 1.0, 'min_df': 5}]+svm\n",
      "\n",
      "\n",
      "Creating model for en - age\n",
      "Trainining instances: 436\n",
      "\n",
      "Using 3 fold validation\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-569b12b5c471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./comb_res/res.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Task:{}, Pipeline:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mcross_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtictac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;31m# print results at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n--------------- Thy time of Judgement ---------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-569b12b5c471>\u001b[0m in \u001b[0;36mcross_val\u001b[1;34m(dataset, task, model, num_folds)\u001b[0m\n\u001b[0;32m     39\u001b[0m         grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n\u001b[0;32m     40\u001b[0m                                n_jobs=-1)\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mgrid_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# y_pred = grid_cv.best_estimator_.predict(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# pprint.pprint(y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from tictacs import from_recipe\n",
    "from json import dumps\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if (task != \"age\") and (task !=\"gender\"):\n",
    "    #    X, y = dataset.get_data(task)\n",
    "    # else:\n",
    "    #    docs = createDocProfiles(dataset)\n",
    "    #    X, y = create_target_prof_trainset(docs, task)\n",
    "    X, y = dataset.get_data(task)\n",
    "    # y = [yy.lower() for yy in y]\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    # from collections import Counter\n",
    "    # import pprint\n",
    "    # pprint.pprint(Counter(y))\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Trainining instances: %s\\n' % (len(X))\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    log.append('\\nResults for %s - %s with classifier %s' %\n",
    "               (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        # y_pred = grid_cv.best_estimator_.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(y)\n",
    "        # conf = confusion_matrix(y, y_pred, labels=list(set(y)))\n",
    "        accuracy = grid_cv.best_score_\n",
    "        # accuracy2 = accuracy_score(y, y_pred)\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "        import pprint\n",
    "        pprint.pprint(grid_cv.grid_scores_)\n",
    "        with open('./comb_res/res.txt', 'a') as out:\n",
    "            out.write(' Results: %s - %s, params: %s ,Accuracy_Mean: %s\\n' %\n",
    "                      (dataset.lang, task,\n",
    "                       dumps(grid_cv.best_params_), grid_cv.best_score_))\n",
    "        # log.append('Best accuracy: {} '.format(accuracy2))\n",
    "        # log.append('Best Confusion matrix :\\n {}'.format(conf))\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        raise KeyError('task %s was not found in task list!' % task)\n",
    "\n",
    "\n",
    "\n",
    "infolder = '../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/'\n",
    "num_folds = 3\n",
    "time_start = time.time()\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    import pprint\n",
    "    #pprint.pprint(tictac.__dict__)\n",
    "    #exit(1)\n",
    "    steps = tictac.steps\n",
    "    #print type(steps)\n",
    "    outline = \"\"\n",
    "    for step in steps:\n",
    "        if step[0]==\"features\":\n",
    "            # print type(step[1])\n",
    "            for tf in step[1].transformer_list:\n",
    "                #print type(tf[1])\n",
    "                #print type(tf[1].get_params())\n",
    "                outline += tf[0] + \" with Params:[\" + str(tf[1].get_params()) + \"]+\"\n",
    "        else:\n",
    "#            if hasattr(step[1], 'get_params'):\n",
    "#                outline += step[0] + \" with Params:[\" + str(step[1].get_params()) + \"]+\"\n",
    "#            else:\n",
    "#                outline += step[0]+ \"+\"\n",
    "            outline += step[0]+ \"+\"\n",
    "    outline = outline[:-1] + \"\\n\"\n",
    "    print('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    with open('./comb_res/res.txt', 'a') as out:\n",
    "        out.write('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    cross_val(dataset, task, tictac, num_folds)\n",
    "# print results at end\n",
    "print('\\n--------------- Thy time of Judgement ---------------')\n",
    "print ('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "with open('./comb_res/res.txt', 'a') as out:\n",
    "    out.write('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "for message in log:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_cleanup',\n",
       " '__module__',\n",
       " '__repr__',\n",
       " 'load_recipe',\n",
       " '__reduce__',\n",
       " '__doc__',\n",
       " '__init__']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "dill.pickles(tictac)\n",
    "dill.detect.badtypes(tictac).__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-95b228baecda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0moutfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading dataset->Grouping User texts.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProfilingDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loaded {} users...\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# get config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bogas/workspace/GIT/PAN16/authorProfPAN16/pan/dataset.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# pprint.pprint(self.truth_mapping)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_entries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;31m# TODO see where you are going to put this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# self.discard_empty()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bogas/workspace/GIT/PAN16/authorProfPAN16/pan/dataset.pyc\u001b[0m in \u001b[0;36m_read_entries\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;31m# print line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mentries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bogas/workspace/GIT/PAN16/authorProfPAN16/pan/dataset.pyc\u001b[0m in \u001b[0;36m_new_instance\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0map_attrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEXTS_LABEL\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mAuthorProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0map_attrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bogas/workspace/GIT/PAN16/authorProfPAN16/pan/preprocess.pyc\u001b[0m in \u001b[0;36mget_docs\u001b[1;34m(xml)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;31m# remove right tabs - why do you add tabs in CDATA?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'document'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1520\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'smartQuotesTo'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTML_ENTITIES\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'isHTML'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m         \u001b[0mBeautifulStoneSoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m     SELF_CLOSING_TAGS = buildTagMap(None,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, parseOnlyThese, fromEncoding, markupMassage, smartQuotesTo, convertEntities, selfClosingTags, isHTML)\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkupMassage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarkupMassage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misHTML\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misHTML\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopParsing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self, inDocumentEncoding, isHTML)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mSGMLParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    172\u001b[0m                     \u001b[1;31m# deployed,\" this should only be the document type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                     \u001b[1;31m# declaration (\"<!DOCTYPE html...>\").\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_declaration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36mparse_declaration\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   1458\u001b[0m              \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m              \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1460\u001b[1;33m              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_toStringSubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1461\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m_toStringSubclass\u001b[1;34m(self, text, subclass)\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle_pi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36mendData\u001b[1;34m(self, containerClass)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentData\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m             \u001b[0mcurrentData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m             if (currentData.translate(self.STRIP_ASCII_SPACES) == '' and\n\u001b[0m\u001b[0;32m   1243\u001b[0m                 not set([tag.name for tag in self.tagStack]).intersection(\n\u001b[0;32m   1244\u001b[0m                     self.PRESERVE_WHITESPACE_TAGS)):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### TRAIN ############\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    all_models[task] = tictac.fit(X, y)\n",
    "modelfile = os.path.join(outfolder, '%s2.bin' % dataset.lang)\n",
    "print('Writing model to {}'.format(modelfile))\n",
    "#fo = open(modelfile,  'wb')\n",
    "#import pprint\n",
    "#print type(all_models)\n",
    "#print modelfile\n",
    "#dill.dump(all_models, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#fo.close()\n",
    "# pickle.dump(all_models, modelfile)\n",
    "# dill.dump(all_models, modelfile)\n",
    "joblib.dump(all_models, modelfile, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "a = numpy.array([[1,2],[3,4]], dtype=float)\n",
    "b = numpy.array([[0.1,0.2],[0.3,0.4]], dtype=float)\n",
    "type(a[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "print a.shape\n",
    "b = numpy.tile(a, (5, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,) <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "c = b.sum(axis=1)\n",
    "print c.shape, type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.,  2.],\n",
      "       [ 3.,  4.]])\n",
      "array([[ 0.33333333,  0.66666667],\n",
      "       [ 0.42857143,  0.57142857]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import pprint\n",
    "pprint.pprint(a)\n",
    "normalize(a, norm='l1', axis=1, copy=False)\n",
    "pprint.pprint(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
