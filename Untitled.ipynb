{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.preprocess)\n",
    "dataset = ProfilingDataset(infolder)\n",
    "X, y = dataset.get_data(task)\n",
    "b = [X[0][0:100]]\n",
    "b.append(X[1][0:100])\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tictac.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DocProfile(object):\n",
    "    \n",
    "    \"\"\" Per Document Representation. Returns an instance of a document profile.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, entry, prof_id, doc_id):\n",
    "        \"\"\" Initialization.\n",
    "            -entry : contains most information. Comes from ProfilingDataset Class.\n",
    "            -prof_id: index for intra-profile document position\n",
    "            -doc_id: index for global documend indexing\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.userid = entry.userid\n",
    "        self.lang = entry.lang\n",
    "        self.media = entry.media\n",
    "        self.gender = entry.gender\n",
    "        self.age = entry.age\n",
    "        self.prof_id = prof_id\n",
    "        self.doc_id = doc_id\n",
    "        self.text = entry.texts[prof_id]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" IPython friendly output\n",
    "        :returns: str\n",
    "\n",
    "        \"\"\"\n",
    "        # automatically capture all non iterables\n",
    "        # (we want custom formatting for text list)\n",
    "        attr_string = '\\n'.join(['%s : %s' % (key, value)\n",
    "                                 for key, value in self.__dict__.items()\n",
    "                                 if not hasattr(value, '__iter__')])\n",
    "        # print a snippet\n",
    "        return attr_string\n",
    "    \n",
    "    def datafy(self, feature='none'):\n",
    "        \"\"\"Return a tuple of data - training and label if feature is not none\n",
    "\n",
    "        :feature: the feature we want the label for\n",
    "        :returns: tuple of data, label\n",
    "\n",
    "        \"\"\"\n",
    "        if feature == 'none':\n",
    "            return self.text\n",
    "        else:\n",
    "            return [self.text, self.__dict__[feature]]\n",
    "\n",
    "def createDocProfiles(dataset):\n",
    "    \"\"\" Create a list of the DocProfiles classes.\n",
    "        -dataset: ProfilingDataset Object\n",
    "        \n",
    "        returns:\n",
    "        -a list of DocProfile Objects\n",
    "    \"\"\"\n",
    "    docs = []       \n",
    "    doc_id = 0\n",
    "    for entry in dataset.entries:\n",
    "        for prof_id in range(0, len(entry.texts)):\n",
    "            docs.append(DocProfile(entry, prof_id, doc_id))\n",
    "            doc_id += 1\n",
    "    return docs\n",
    "    \n",
    "def create_target_prof_trainset(docs, target_feature):\n",
    "    \"\"\" Create a dataset according to train a specifici model regardin a certain feature.\n",
    "        Like get_data() method from ProfilingDataset class.\n",
    "        -docs: list of documents. Expects instances of class DocProfile. \n",
    "        -target_feature: filter feature\n",
    "        \n",
    "        returns:\n",
    "        (X,y) : returns tuple - list of texts, list of labels \n",
    "        \n",
    "    \"\"\"\n",
    "    wanted = []\n",
    "    for doc in docs:\n",
    "        if target_feature in doc.__dict__:\n",
    "            wanted.append(doc.datafy(feature=target_feature))\n",
    "        else:\n",
    "            raise KeyError(\"task doesn't exist in DocProfile dic()\")\n",
    "    # zip produces tuples, we want to be able to modify\n",
    "    # the contents in preprocessing in place\n",
    "    # therefore we create we replace tuples with lists using map\n",
    "    # returns tuple - list of texts, list of labels\n",
    "    return map(list, zip(*wanted))\n",
    "\n",
    "        \n",
    "docs = createDocProfiles(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = [[0.25,0.25,0.25,0.25], [0.5,0,0.2,0.25], [0.2,0.3,0,0.5]]\n",
    "b = [[1,0], [0,1],[1,0]]\n",
    "numpy.dot(numpy.array(a).T,numpy.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'age'\n",
    "docs = createDocProfiles(dataset)\n",
    "X, y = create_target_prof_trainset(docs, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import *\n",
    "class SOA_Model2(object):\n",
    "\n",
    "\n",
    "    \"\"\" Models that extracts Second Order Attributes (SOA) base on PAN 2013-2015 Winners\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "        \n",
    "        #stop_list = []\n",
    "        #with open(stopwords_path, 'r') as stop_inp:\n",
    "       # for w in stop_inp:\n",
    "       # stop_list.append(w.replace(\"\\n\", \"\"))\n",
    "        self.term_table = None\n",
    "        self.labels = None\n",
    "        #self.counter = CountVectorizer()\n",
    "        self.counter = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        import numpy\n",
    "        from math import log\n",
    "        \n",
    "        if y:\n",
    "            #tokens = [_twokenize.tokenizeRawTweetText(text) for text in X]\n",
    "            #voc = set()\n",
    "            #for token in tokens:\n",
    "            #    voc = voc.union(token)\n",
    "            #print len(voc)\n",
    "            #print list(voc)[:100]\n",
    "            parameters = {\n",
    "                'input':'content', \n",
    "                'encoding':'utf-8', \n",
    "                'decode_error':'ignore', \n",
    "                #'vocabulary':list(voc),\n",
    "                'tokenizer':lambda text:_twokenize.tokenizeRawTweetText(text)\n",
    "                #'max_df':0.9,\n",
    "                #'min_df':5\n",
    "                #'max_features':20000\n",
    "               }\n",
    "            self.counter.set_params(**parameters) \n",
    "            #print \"Oleeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
    "            #print texts\n",
    "            #print tokens\n",
    "            #print list(voc)\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            print len(target_profiles)\n",
    "            #return\n",
    "            doc_term = self.counter.fit_transform(X)\n",
    "            print \"Doc_Terms\"\n",
    "            print doc_term.shape\n",
    "            #return \n",
    "            #X1 = X.toarray()\n",
    "            #X1 = X1.astype('float', casting='unsafe')\n",
    "            target_profiles = sorted(list(set(y)))\n",
    "            self.labels = target_profiles\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], len(target_profiles)])\n",
    "            for i in range(0, doc_term.shape[0]):\n",
    "                tmp = numpy.zeros([1,len(target_profiles)])\n",
    "                tmp[0, target_profiles.index(y[i])] = 1\n",
    "                doc_prof[i,:] = tmp\n",
    "            print \"Doc_Prof\"\n",
    "            print doc_prof.shape\n",
    "            term_prof = numpy.zeros([doc_term.shape[1], len(target_profiles)])\n",
    "            term_prof = numpy.dot(numpy.log2(doc_term.toarray().astype('float', casting='unsafe').T + 1), doc_prof)\n",
    "            print \"Term_Prof\"\n",
    "            print term_prof.shape\n",
    "            term_prof = term_prof / numpy.reshape(term_prof.sum(axis=1), (term_prof.sum(axis=1).shape[0], 1))\n",
    "            #term_prof = term_prof / term_prof.sum(axis=0)\n",
    "            self.term_table = term_prof\n",
    "            print \"GG\"\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        if self.labels==None:\n",
    "            raise AttributeError('term_table was no found! Probably model was not fitted first. Run model.fit(X,y)!')\n",
    "        else:\n",
    "            doc_term = self.counter.transform(X)\n",
    "            doc_prof = numpy.zeros([doc_term.shape[0], self.term_table.shape[1]])\n",
    "            doc_prof = numpy.dot(doc_term.toarray().astype('float', casting='unsafe'), self.term_table)\n",
    "            return doc_prof\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        import numpy\n",
    "        \n",
    "        doc_prof = self.transform(X)\n",
    "        y_pred = []\n",
    "        for i in range(0, doc_prof.shape[0]):\n",
    "            y_pred.append(self.labels[numpy.argmax(doc_prof[i])])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pan.misc import _twokenize\n",
    "import pan\n",
    "reload(pan)\n",
    "c = SOA_Model2()\n",
    "c.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = c.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in c.counter.vocabulary_.iteritems():\n",
    "    if v>8000 and v< 9000:\n",
    "        pass\n",
    "        #print k, v\n",
    "top_words = [[] for i in range(0, c.term_table.shape[1])]\n",
    "cc= 0\n",
    "for i in range(0, c.term_table.shape[0]):\n",
    "    if max(c.term_table[i]) > 0.7:\n",
    "        #print c.term_table[i], c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)]\n",
    "        top_words[list(c.term_table[i]).index(max(c.term_table[i]))].append(c.counter.vocabulary_.keys()[c.counter.vocabulary_.values().index(i)])\n",
    "        cc += 1\n",
    "top_words\n",
    "        #c.term_table /= c.term_table[8411].sum(axis= 0)\n",
    "#c.term_table[8411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "tmp = numpy.zeros([2,4])\n",
    "tmp[0,1]=1\n",
    "tmp[0,3]= 1\n",
    "tmp[1,2] = 1\n",
    "tmp / numpy.reshape(tmp.sum(axis=1), (tmp.sum(axis=1).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan\n",
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model2()\n",
    "c.fit_transform(X, y)\n",
    "a = [\"I am very good!\"]\n",
    "#c.transform(X, y)\n",
    "#from pprint import pprint\n",
    "#pprint(dataset.get_data()[0])\n",
    "#pprint(dataset.entries[0].texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "aaa = numpy.asarray([[1, 2], [3, 4]], dtype=float)\n",
    "bb = aaa.sum(axis=1)\n",
    "print numpy.reshape(bb, (1,2))\n",
    "print aaa/numpy.reshape(bb, (bb.shape[0],1))\n",
    "print aaa/aaa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.preprocessing import normalize\n",
    "aaa = numpy.asarray([[1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "print \"sci-kit\"\n",
    "cc = normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(aaa, axis=1, norm='l1')\n",
    "print normalize(cc, axis=0, norm='l1')\n",
    "print numpy.sum(aaa,axis=1, keepdims=True)\n",
    "print numpy.linalg.norm(aaa, axis=1)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=1, keepdims=True), dtype=float)\n",
    "print numpy.sum(aaa,axis=0, keepdims=True)\n",
    "aaa = numpy.true_divide(aaa, numpy.sum(aaa,axis=0, keepdims=True), dtype=float)\n",
    "print aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pan\n",
    "reload(pan.features)\n",
    "log = []\n",
    "#import logging\n",
    "#log = logging.getLogger()\n",
    "#log.setLevel(logging.INFO)\n",
    "#log.addHandler(logging.StreamHandler())\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "modelfile\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    if task == \"age\":\n",
    "        X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)\n",
    "print('Writing model to {}'.format(modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tictacs\n",
    "tictacs.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "a.add(2)\n",
    "a.add(3)\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "a = CountVectorizer(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(pan.features)\n",
    "c = pan.features.SOA_Model()\n",
    "a = [\"I am very good!\"]\n",
    "#aa = c.fit_transform(a)\n",
    "print b\n",
    "c.fit([b])\n",
    "print aa\n",
    "print c.counter.vocabulary_\n",
    "kk = c.transform([b])\n",
    "print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "            \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    " # remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "from pprint import pprint   # pretty-printer\n",
    "pprint(texts)\n",
    "dictionary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "model = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pow(2,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset\n",
    "from tictacs import from_recipe\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#reload(pan.features)\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #X, y = dataset.get_data(task)\n",
    "    docs = createDocProfiles(dataset)\n",
    "    X, y = create_target_prof_trainset(docs, task)\n",
    "    del docs\n",
    "    #return X\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    #log.append('\\nResults for %s - %s with classifier %s' %\n",
    "    #           (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        grid_cv = GridSearchCV(model, params, scoring='mean_squared_error',\n",
    "                               cv=num_folds, verbose=1, n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        accuracy = grid_cv.best_score_\n",
    "        log.append('root mean squared error : %s' % accuracy)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Train a model with crossvalidation'\n",
    "                            ' on pan dataset - used for testing purposes ')\n",
    "    parser.add_argument('-i', '--input', type=str,\n",
    "                        required=True, dest='infolder',\n",
    "                        help='path to folder with pan dataset for a language')\n",
    "    parser.add_argument('-n', '--numfolds', type=int,\n",
    "                        dest='num_folds', default=4,\n",
    "                        help='Number of folds to use in cross validation')\n",
    "\n",
    "num_folds = 2\n",
    "infolder = \"./pan15-author-profiling-training-dataset-2015-04-23/pan15-author-profiling-training-dataset-english-2015-04-23/\"\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    if task == \"age\":\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        z = cross_val(dataset, task, tictac, num_folds)\n",
    "        # print results at end\n",
    "        print('\\n--------------- Thy time of Judgement ---------------')\n",
    "    for message in log:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "all_models = {}\n",
    "docs = createDocProfiles(dataset)\n",
    "for task in tasks:\n",
    "    if task =='age':\n",
    "        print('Learning to judge %s..' % task)\n",
    "        # load data\n",
    "        X, y = create_target_prof_trainset(docs, task)\n",
    "        #X, y = dataset.get_data(task)\n",
    "        tictac = from_recipe(config.recipes[task])\n",
    "        all_models[task] = tictac.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "          for document in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model =gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100, minimum_probability=0)\n",
    "a = model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "lsi[corpus[2]]\n",
    "import numpy\n",
    "#len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = lsi[corpus]\n",
    "l = [list(zip(*cc)[1]) for cc in c]\n",
    "#l = []\n",
    "#for cc in c:\n",
    "    #print cc\n",
    "#    l.append(list(zip(*cc)[1]))\n",
    "print numpy.array(l)\n",
    "    #print list(zip(*cc)[1])\n",
    "    #for k in cc:\n",
    "    #    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pan.features\n",
    "reload(pan.features)\n",
    "pan.features.TWCNB.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from argparse import ArgumentParser\n",
    "from pan import ProfilingDataset, createDocProfiles, create_target_prof_trainset\n",
    "from tictacs import from_recipe\n",
    "from json import dumps\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "log = []\n",
    "\n",
    "\n",
    "def cross_val(dataset, task, model, num_folds=4):\n",
    "    \"\"\" train and cross validate a model\n",
    "\n",
    "    :lang: the language\n",
    "    :task: the task we want to classify for , ex: age\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # if (task != \"age\") and (task !=\"gender\"):\n",
    "    #    X, y = dataset.get_data(task)\n",
    "    # else:\n",
    "    #    docs = createDocProfiles(dataset)\n",
    "    #    X, y = create_target_prof_trainset(docs, task)\n",
    "    X, y = dataset.get_data(task)\n",
    "    # y = [yy.lower() for yy in y]\n",
    "    # get parameters for grid search if it exists - else pass empty dict\n",
    "    params = model.grid_params if hasattr(model, 'grid_params') else dict()\n",
    "    # from collections import Counter\n",
    "    # import pprint\n",
    "    # pprint.pprint(Counter(y))\n",
    "    print '\\nCreating model for %s - %s' % (dataset.lang, task)\n",
    "    print 'Trainining instances: %s\\n' % (len(X))\n",
    "    print 'Using %s fold validation' % (num_folds)\n",
    "    # get data\n",
    "    log.append('\\nResults for %s - %s with classifier %s' %\n",
    "               (dataset.lang, task, model.__class__.__name__))\n",
    "    if task in dataset.config.classifier_list:\n",
    "        grid_cv = GridSearchCV(model, params, cv=num_folds, verbose=1,\n",
    "                               n_jobs=-1)\n",
    "        grid_cv.fit(X, y)\n",
    "        # y_pred = grid_cv.best_estimator_.predict(X)\n",
    "        # pprint.pprint(y_pred)\n",
    "        # pprint.pprint(y)\n",
    "        # conf = confusion_matrix(y, y_pred, labels=list(set(y)))\n",
    "        accuracy = grid_cv.best_score_\n",
    "        # accuracy2 = accuracy_score(y, y_pred)\n",
    "        log.append('best params: %s' % grid_cv.best_params_)\n",
    "        log.append('Accuracy mean : %s' % accuracy)\n",
    "        import pprint\n",
    "        pprint.pprint(grid_cv.grid_scores_)\n",
    "        with open('./comb_res/res.txt', 'a') as out:\n",
    "            out.write(' Results: %s - %s, params: %s ,Accuracy_Mean: %s\\n' %\n",
    "                      (dataset.lang, task,\n",
    "                       dumps(grid_cv.best_params_), grid_cv.best_score_))\n",
    "        # log.append('Best accuracy: {} '.format(accuracy2))\n",
    "        # log.append('Best Confusion matrix :\\n {}'.format(conf))\n",
    "    else:\n",
    "        # if it's not, we measure mean square root error (regression)\n",
    "        raise KeyError('task %s was not found in task list!' % task)\n",
    "\n",
    "\n",
    "\n",
    "infolder = '../DATA/pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/'\n",
    "num_folds = 3\n",
    "time_start = time.time()\n",
    "print('Loading dataset...')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded %s users...\\n' % len(dataset.entries))\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "for task in tasks:\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    import pprint\n",
    "    #pprint.pprint(tictac.__dict__)\n",
    "    #exit(1)\n",
    "    steps = tictac.steps\n",
    "    #print type(steps)\n",
    "    outline = \"\"\n",
    "    for step in steps:\n",
    "        if step[0]==\"features\":\n",
    "            # print type(step[1])\n",
    "            for tf in step[1].transformer_list:\n",
    "                #print type(tf[1])\n",
    "                #print type(tf[1].get_params())\n",
    "                outline += tf[0] + \" with Params:[\" + str(tf[1].get_params()) + \"]+\"\n",
    "        else:\n",
    "#            if hasattr(step[1], 'get_params'):\n",
    "#                outline += step[0] + \" with Params:[\" + str(step[1].get_params()) + \"]+\"\n",
    "#            else:\n",
    "#                outline += step[0]+ \"+\"\n",
    "            outline += step[0]+ \"+\"\n",
    "    outline = outline[:-1] + \"\\n\"\n",
    "    print('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    with open('./comb_res/res.txt', 'a') as out:\n",
    "        out.write('Task:{}, Pipeline:{}'.format(task, outline))\n",
    "    cross_val(dataset, task, tictac, num_folds)\n",
    "# print results at end\n",
    "print('\\n--------------- Thy time of Judgement ---------------')\n",
    "print ('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "with open('./comb_res/res.txt', 'a') as out:\n",
    "    out.write('Time: {} seconds.\\n'.format(str(time.time()-time_start)))\n",
    "for message in log:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.pickles(tictac)\n",
    "dill.detect.badtypes(tictac).__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### TRAIN ############\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../pan16-author-profiling-training-dataset-2016-02-29/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)\n",
    "    tictac = from_recipe(config.recipes[task])\n",
    "    all_models[task] = tictac.fit(X, y)\n",
    "modelfile = os.path.join(outfolder, '%s2.bin' % dataset.lang)\n",
    "print('Writing model to {}'.format(modelfile))\n",
    "#fo = open(modelfile,  'wb')\n",
    "#import pprint\n",
    "#print type(all_models)\n",
    "#print modelfile\n",
    "#dill.dump(all_models, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#fo.close()\n",
    "# pickle.dump(all_models, modelfile)\n",
    "# dill.dump(all_models, modelfile)\n",
    "joblib.dump(all_models, modelfile, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "a = numpy.array([[1,2],[3,4]], dtype=float)\n",
    "b = numpy.array([[0.1,0.2],[0.3,0.4]], dtype=float)\n",
    "type(a[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = numpy.array([1,2,3,4])\n",
    "print a.shape\n",
    "b = numpy.tile(a, (5, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = b.sum(axis=1)\n",
    "print c.shape, type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import pprint\n",
    "pprint.pprint(a)\n",
    "normalize(a, norm='l1', axis=1, copy=False)\n",
    "pprint.pprint(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset->Grouping User texts.\n",
      "\n",
      "Loaded 436 users...\n",
      "\n",
      "\n",
      "--------------- Thy time of Running ---------------\n",
      "Learning to judge age..\n",
      "Learning to judge gender..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.externals import joblib\n",
    "from tictacs import from_recipe\n",
    "from pan import ProfilingDataset\n",
    "import dill\n",
    "import cPickle as pickle\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "infolder = \"../DATA/pan16-author-profiling-training-dataset-2016-04-25/pan16-author-profiling-training-dataset-english-2016-02-29/\"\n",
    "outfolder = \"models/\"\n",
    "print('Loading dataset->Grouping User texts.\\n')\n",
    "dataset = ProfilingDataset(infolder)\n",
    "print('Loaded {} users...\\n'.format(len(dataset.entries)))\n",
    "# get config\n",
    "config = dataset.config\n",
    "tasks = config.tasks\n",
    "print('\\n--------------- Thy time of Running ---------------')\n",
    "all_models = {}\n",
    "for task in tasks:\n",
    "    print('Learning to judge %s..' % task)\n",
    "    # load data\n",
    "    X, y = dataset.get_data(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "import pprint\n",
    "print \"Num of samples: \" + str(len(y))\n",
    "pprint.pprint(Counter(y))\n",
    "X, y = dataset.get_data('age')\n",
    "print len(X)\n",
    "\n",
    "X, X_cv, X, y_cv = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.5, random_state=42, stratify=y_cv)\n",
    "\n",
    "print len(X_cv), len(X_test), len(X) , len(X)+ len(X_cv) + len(X_test)\n",
    "pprint.pprint(Counter(y))\n",
    "pprint.pprint(Counter(y_cv))\n",
    "pprint.pprint(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "    -Cleaning html\n",
      "    -Detwittifying\n",
      "    -Removing Numbers\n",
      "    -Removing Punctuation\n",
      "    -Removing Links\n"
     ]
    }
   ],
   "source": [
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "X, y = dataset.get_data('age')\n",
    "print len(X)\n",
    "#print X[0]\n",
    "X = preprocess.preprocess(X)\n",
    "#print \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\"\n",
    "#print X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams+soa+soac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smo...ulary=None)), ('soa', SOA_Model2(max_df=1.0, max_features=None, min_df=5, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced', probability=True)\n",
    "#svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('3grams', grams3), ('soa', soa)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + SOA+SOAC. Ommit preprocess!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Complementary of SOA model 22'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(features)\n",
    "features.SOAC_Model2.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3grams',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "          ngram_range=[3, 3], norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "grams3 = TfidfVectorizer(analyzer='word', ngram_range=[3,3], max_features=5000, stop_words='english')\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "scaler = StandardScaler()#MinMaxScaler()#StandardScaler()\n",
    "#svm = DecisionTreeClassifier()\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe = Pipeline([('3grams', grams3), ('svm', svm)])\n",
    "#pipe = Pipeline([('soac',soac), ('svm', svm)])\n",
    "#pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from pan.features import LDA\n",
    "\n",
    "LDAmodel = LDA(num_topics=30, lib='sklearn')\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "countTokens = features.CountTokens()\n",
    "countHash = features.CountHash()\n",
    "countUrls = features.CountURLs()\n",
    "countReplies = features.CountReplies()\n",
    "#svm = SVC(kernel='rbf', C=1, gamma=1, class_weight='balanced')\n",
    "svm = DecisionTreeClassifier()\n",
    "combined = FeatureUnion([('LDA', LDAmodel)])#, ('soa', soa), ('soac', soac)])\n",
    "pipe = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDAA = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1]\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\" \".join([feature_names[i]\n",
    "        #                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "#print_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "     \n",
    "    feat = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_words = \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        feat.append(\"#%d: \" % topic_idx + topic_words)\n",
    "        #print(\"#%d: \" % topic_idx + topic_words)\n",
    "    return feat\n",
    "get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = get_top_words(LDAA.LDA, LDAA.counter.get_feature_names(), 10)\n",
    "print len(feature_names)\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "feature_names = copy.deepcopy(countTokens.l)\n",
    "feature_names += ['numHash', 'numUrl', 'numRep']\n",
    "#soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "#feature_names += soac_feat_names\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]\n",
    "print len(countTokens.l), len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(features)\n",
    "#features.SOAC_Model2.__doc__\n",
    "soac = features.SOAC_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=5000)\n",
    "#y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX = [#\"I like playing video games very much :).\", \n",
    "     #\"Football games are the best!\",\n",
    "     #\"Being young forever is very funny and entertaining\",\n",
    "     # \"Football games are the best!\",\n",
    "      \"best games\",\n",
    "      \"best games\",\n",
    "     #\"World leaders should gather and decide for todays meeting!\",\n",
    "     #\"Problems nowadays seem to thrive everywhere\",\n",
    "     #\"Just got off from work today! Weekend is coming though, so it's alright...\",\n",
    "     #\"This weekend we are going of for 3 days..\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \" Weekend alright...\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\",\n",
    "     \"Awful weather\"]\n",
    "yy = [\"18-24\",\n",
    "     \"18-24\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"25-34\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "     \"35-49\",\n",
    "    ]\n",
    "#reload(preprocess)\n",
    "#reload(features)\n",
    "from pan import features\n",
    "from pan import preprocess\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "XX = preprocess.preprocess(XX)\n",
    "num_folds = 2\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(XX,yy)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = soac.fit_transform(X[0:10], y[0:10])\n",
    "print xx\n",
    "print y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soac = features.SOAC_Model2(max_df=1.0, min_df=1, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soac', soac)])\n",
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe1 = Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe1.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('combined', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('soa', SOA_Model2(max_df=1.0, max_features=None, min_df=5, tokenizer_var='sklearn'))],\n",
       "         transformer_weights=None)),\n",
       " ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=0.1, gamma=1, class_weight='balanced', probability=True)\n",
    "soa = features.SOA_Model2(max_df=1.0, min_df=5, tokenizer_var='sklearn', max_features=None)\n",
    "combined = FeatureUnion([('soa', soa)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies), \n",
    "#                          ('soa', soa), ('soac', soac)])\n",
    "#combined = FeatureUnion([('count_tokens', countTokens), ('count_hash', countHash),\n",
    "#                         ('count_urls', countUrls), ('count_replies', countReplies)])\n",
    "pipe2= Pipeline([('combined',combined), ('svm', svm)])\n",
    "pipe2.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search1 = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search1.fit(X,y)\n",
    "print(grid_search1.best_estimator_)\n",
    "print(grid_search1.best_score_)\n",
    "grid_search2 = GridSearchCV(estimator=pipe2, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search2.fit(X,y)\n",
    "print(grid_search2.best_estimator_)\n",
    "print(grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "We are fitting!\n",
      "[[ 15.57142857   3.11428571   2.3956044    5.45        72.66666667]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.52380952   3.1047619    2.39705882   5.43333333  81.5       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]][[ 15.61904762   3.12380952   2.39416058   5.46666667  65.6       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(326, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "(328, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(110, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "(108, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.447247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "num_folds = 4\n",
    "grid_search = GridSearchCV(estimator=pipe1, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "grid_search.fit(X,y)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 88 436 436\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537)\n",
      "(261, 14138)\n",
      "(262, 14058)\n",
      "(262, 13356)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(13537, 5) <type 'numpy.ndarray'>\n",
      "(14138, 5) <type 'numpy.ndarray'>\n",
      "(14058, 5) <type 'numpy.ndarray'>\n",
      "(13356, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.          0.44151325  0.06550793  0.49297881  0.        ]\n",
      "[ 0.          0.72245332  0.27754668  0.          0.        ]\n",
      "[ 0.          0.34643333  0.17271636  0.48085031  0.        ]\n",
      "[ 0.          0.30669112  0.21100297  0.48230591  0.        ]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(89, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(87, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "[ 1.26691404  1.66449085  2.30417331  1.78089942  1.03220281]\n",
      "[ 2.37359272  2.92592043  2.90394709  3.1043561   1.68510674]\n",
      "[ 1.59815326  1.92811313  2.18654839  2.30936014  1.40540878]\n",
      "[ 2.26109734  2.51535375  2.34143872  2.25845794  1.45798678]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "\n",
      "(348, 16756)\n",
      "Doc_Prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(16756, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.          0.43153198  0.17457671  0.39389131  0.        ]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "0.456896551724\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngra...',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.454022988506\n",
      "Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('soac', SOAC_Model2(max_df=1.0, max_features=None, min_df=1, tokenizer_var='sklearn'))],\n",
      "       transformer_weights=None)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are fitting!\n",
      "Doc_TermsWe are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "We are fitting!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537)\n",
      "(261, 14138)\n",
      "(262, 14058)\n",
      "(262, 13356)\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "Doc_Prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "Doc_Term\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "Term_Prof\n",
      "(13537, 5) <type 'numpy.ndarray'>\n",
      "(14138, 5) <type 'numpy.ndarray'>\n",
      "(14058, 5) <type 'numpy.ndarray'>\n",
      "(13356, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "Random Term_Prof\n",
      "[ 0.          0.44151325  0.06550793  0.49297881  0.        ]\n",
      "[ 0.          0.72245332  0.27754668  0.          0.        ]\n",
      "[ 0.          0.34643333  0.17271636  0.48085031  0.        ]\n",
      "[ 0.          0.30669112  0.21100297  0.48230591  0.        ]\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(259, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(261, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(262, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "[ 2.8290876   2.75209922  3.23799907  2.85175416  1.42228738]\n",
      "[ 1.17531373  1.56845209  2.38956113  1.86018563  1.08943037]\n",
      "[ 1.22597844  1.58720898  2.48222065  1.77605125  1.03818736]\n",
      "[ 1.1048924   1.63160465  2.38379453  1.85462345  1.10881593]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are fitting!We are fitting!We are fitting!We are fitting!\n",
      "\n",
      "\n",
      "\n",
      "[[ 16.1875       3.08333333   2.39814815   5.39583333  86.33333333]][[ 16.3125       3.10714286   2.39449541   5.4375      65.25      ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]][[ 15.41176471   3.11904762   2.40366972   5.45833333  65.5       ]]\n",
      "\n",
      "\n",
      "\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(259, 5) <type 'numpy.ndarray'>\n",
      "(261, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "(262, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!We are transforming!We are transforming!We are transforming!\n",
      "\n",
      "\n",
      "\n",
      "Doc_TermsDoc_TermsDoc_TermsDoc_Terms\n",
      "\n",
      "\n",
      "\n",
      "(89, 13537) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(87, 14138) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 14058) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(86, 13356) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "Doc_prof\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "[ 1.26691404  1.66449085  2.30417331  1.78089942  1.03220281]\n",
      "[ 2.37359272  2.92592043  2.90394709  3.1043561   1.68510674]\n",
      "[ 1.59815326  1.92811313  2.18654839  2.30936014  1.40540878]\n",
      "[ 2.26109734  2.51535375  2.34143872  2.25845794  1.45798678]\n",
      "Len Voc: 13537\n",
      "Len Voc: 14138\n",
      "Len Voc: 14058\n",
      "Len Voc: 13356\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "We are transforming!\n",
      "Doc_profDoc_profDoc_profDoc_prof\n",
      "\n",
      "\n",
      "\n",
      "(89, 5) <type 'numpy.ndarray'>\n",
      "(87, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "(86, 5) <type 'numpy.ndarray'>\n",
      "\n",
      "(348, 16756)\n",
      "Doc_Prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "Doc_Term\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Term_Prof\n",
      "(16756, 5) <type 'numpy.ndarray'>\n",
      "Random Term_Prof\n",
      "[ 0.          0.43153198  0.17457671  0.39389131  0.        ]\n",
      "SOA Model Fitted!\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(348, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "[ 1.20380878  1.61260998  2.39780476  1.82296852  1.11357178]\n",
      "Len Voc: 16756\n",
      "We are fitting!\n",
      "[[ 15.81818182   3.10714286   2.4          5.4375      69.6       ]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(348, 5) <type 'numpy.ndarray'>\n",
      "0.471264367816\n",
      "VotingClassifier(estimators=[('0', Pipeline(steps=[('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('3grams', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]))],\n",
      "         voting='soft', weights=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "num_folds = 4\n",
    "split = 0.2\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=split, random_state=42, stratify=y)\n",
    "print len(X_train), len(X_cv), len(X_cv) + len(X_train), len(X)\n",
    "eclf = VotingClassifier(estimators=[(\"0\", pipe), ('1', pipe1)], voting='soft')\n",
    "trained_models = []\n",
    "for model in [pipe, pipe1, eclf]:\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid={}, verbose=1, n_jobs=-1, cv=num_folds, refit=True)\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_) \n",
    "    trained_models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "Accuracy : 0.534090909091\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 6 29  2  0  0]\n",
      " [ 4 10  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.511363636364\n",
      "Confusion matrix :\n",
      " [[ 9 17  0  2  0]\n",
      " [ 2 33  0  2  0]\n",
      " [ 1 14  1  0  0]\n",
      " [ 2  2  0  2  0]\n",
      " [ 0  1  0  0  0]]\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(88, 16756) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "[ 3.1563402   3.32837876  3.16486118  2.96139769  1.89792746]\n",
      "Len Voc: 16756\n",
      "We are transforming!\n",
      "Doc_prof\n",
      "(88, 5) <type 'numpy.ndarray'>\n",
      "Accuracy : 0.568181818182\n",
      "Confusion matrix :\n",
      " [[15 12  1  0  0]\n",
      " [ 5 32  0  0  0]\n",
      " [ 5  9  2  0  0]\n",
      " [ 3  2  0  1  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for model in trained_models:\n",
    "    predict = model.predict(X_cv)\n",
    "    predictions.append(predict)\n",
    "    acc = accuracy_score(y_cv, predict)\n",
    "    conf = confusion_matrix(y_cv, predict, labels=list(set(y)))\n",
    "    print('Accuracy : {}'.format(acc))\n",
    "    print('Confusion matrix :\\n {}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['35-49', '25-34', '25-34', '25-34', '35-49', '50-64', '35-49',\n",
       "       '35-49', '35-49', '25-34', '35-49', '25-34', '50-64', '35-49',\n",
       "       '35-49', '25-34', '25-34', '35-49', '35-49', '35-49', '25-34',\n",
       "       '25-34', '35-49', '25-34', '25-34', '35-49', '35-49', '35-49',\n",
       "       '35-49', '35-49', '35-49', '25-34', '35-49', '25-34', '25-34',\n",
       "       '25-34', '35-49', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '35-49', '35-49', '25-34', '25-34', '35-49', '35-49', '35-49',\n",
       "       '25-34', '50-64', '25-34', '35-49', '25-34', '35-49', '25-34',\n",
       "       '25-34', '25-34', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '18-24', '35-49', '35-49', '25-34', '35-49', '50-64', '25-34',\n",
       "       '35-49', '35-49', '25-34', '50-64', '35-49', '35-49', '35-49',\n",
       "       '35-49', '18-24', '35-49', '35-49', '35-49', '25-34', '25-34',\n",
       "       '25-34', '18-24', '50-64', '50-64', '35-49', '25-34', '35-49',\n",
       "       '35-49', '25-34', '25-34', '35-49', '35-49', '25-34', '25-34',\n",
       "       '25-34', '25-34', '25-34', '35-49', '35-49', '25-34', '35-49',\n",
       "       '35-49', '25-34', '18-24', '35-49', '35-49', '25-34', '35-49',\n",
       "       '50-64', '35-49', '35-49', '18-24', '25-34', '35-49', '35-49',\n",
       "       '25-34', '35-49', '18-24', '35-49', '25-34', '35-49', '18-24',\n",
       "       '35-49', '35-49', '25-34', '25-34', '35-49'], \n",
       "      dtype='|S5')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3grams + soa + Soac Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#feature_names = grid_search.best_estimator_.steps[0][1].__dict__['transformer_list'][0][1].get_feature_names()\n",
    "#print len(set(y))\n",
    "feature_names = []\n",
    "soa_feat_names = [\"soa_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "soac_feat_names = [\"soac_prob_\"+str(i) for i in range(0, len(set(y)))]\n",
    "#feature_names += soa_feat_names\n",
    "feature_names += soac_feat_names\n",
    "print len(feature_names)\n",
    "feature_names = [feat.encode('utf-8') for feat in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = grid_search.best_estimator_.steps[0][1]\n",
    "#print a.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are transforming!\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "We are transforming!\n",
      "Doc_Terms\n",
      "(436, 15396) <class 'scipy.sparse.csr.csr_matrix'>\n",
      "SOA Transform:\n",
      "Doc_prof\n",
      "(436, 5) <type 'numpy.ndarray'>\n",
      "[ 1.73208396  1.42016737  1.73543481  2.71125545  0.89811672]\n",
      "Len Voc: 15396\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 436), indices imply (5, 436)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-e5d6b8405024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 245\u001b[1;33m                                          copy=copy)\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_ndarray\u001b[1;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_possibly_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   3548\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3549\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3550\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   3525\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3526\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 3527\u001b[1;33m         passed,implied))\n\u001b[0m\u001b[0;32m   3528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3, 436), indices imply (5, 436)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(a.transform(X), columns=feature_names)\n",
    "data[\"class\"] = y\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('25-34', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62e40e63d0>), ('35-49', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6f0c290>), ('50-64', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6eac590>), ('18-24', <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6ebddd0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6e33390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6e05c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6d8c310>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6d02290>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6cd9790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6c4f810>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6bad110>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6b26350>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6bd6990>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f62c6a799d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c69f4950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f62c69cfe50>]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "rowlength = grouped.ngroups/2                         # fix up if odd number of groups\n",
    "fig, axs = plt.subplots(figsize=(9,4), \n",
    "                        nrows=2, ncols=rowlength,     # fix as above\n",
    "                        gridspec_kw=dict(hspace=0.4)) # Much control of gridspec\n",
    "\n",
    "targets = zip(grouped.groups.keys(), axs.flatten())\n",
    "print targets\n",
    "grouped.get_group('18-24').hist(alpha=0.4)\n",
    "#for i, (key, ax) in enumerate(targets):\n",
    "#    ax.plot(grouped.get_group(key))\n",
    "#    ax.set_title('a=%s'%str(key))\n",
    "#ax.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = data.groupby('class')\n",
    "grouped.mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BAR PLOTS OF MEAN VALUE OF FEATURES FOR EACH CLASS ######\n",
    "\n",
    "grouped = data.groupby('class')\n",
    "plt.figure()\n",
    "grouped.mean().T.plot(kind='bar', figsize=(60,10))\n",
    "plt.savefig('test1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Distribution over a feature for each class #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grouped = data.groupby('class')\n",
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "#fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(6,6)) # create the axes\n",
    "j = 0\n",
    "for key in list(data.columns.values):\n",
    "#    ix = numpy.unravel_index(j, ax.shape)\n",
    "#    print ix\n",
    "    print key\n",
    "    if key!='class':\n",
    "        j += 1\n",
    "        plt.figure(j, figsize=(10,10))\n",
    "        grouped[key].plot(kind='kde', alpha=0.8, legend=grouped.groups.keys(), title=key)\n",
    "    #g = grouped[key]\n",
    "    #print grouped[key].mean()\n",
    "    #if j==1:\n",
    "    #    tmp = g.mean()\n",
    "    #else:\n",
    "    #    print g.mean()\n",
    "    #    tmp.append(g.mean())\n",
    "    #print tmp\n",
    "        plt.show()\n",
    "    #if j==2:\n",
    "    #    break\n",
    "#tmp\n",
    "    #break\n",
    "    #ax[ix] = grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "    #break\n",
    "#for key in grouped.keys:\n",
    "#    grouped[key].plot(kind='kde', alpha=0.4, legend=grouped.groups.keys())\n",
    "#for key in grouped.groups.keys():\n",
    "#    b = grouped.get_group(key)\n",
    "#    b.plot('kin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "ncol = 4 # pick one dimension\n",
    "nrow = (len(feature_names)+ ncol-1) / ncol # make sure enough subplots\n",
    "fig, ax = plt.subplots(nrows=nrow, ncols=ncol) # create the axes\n",
    "j = 0\n",
    "for i in feature_names: \n",
    "    ix = numpy.unravel_index(j, ax.shape)\n",
    "    #print ix\n",
    "    j += 1\n",
    "    ax[ix] = data.groupby('class').i.hist(alpha=0.4)   # go over a linear list of data # compute an appropriate index (1d or 2d)\n",
    "    #feat = feature_names[i]\n",
    "    #data.groupby('class').feat.hist(alpha=0.4, ax=ax[i])\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib outline\n",
    "plt.savefig('CameraEvolution.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = grid_search.best_estimator_.steps[1][1]\n",
    "#import pydot\n",
    "import pyparsing\n",
    "\n",
    "#reload(pydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint, numpy\n",
    "from operator import itemgetter\n",
    "\n",
    "feat_importance = zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_[numpy.nonzero(clf.feature_importances_)]))\n",
    "feat_importance = sorted(feat_importance, key=itemgetter(1))[::-1]\n",
    "feat_importance\n",
    "#for i in zip(list(numpy.array(feature_names)[numpy.nonzero(clf.feature_importances_)]), list(clf.feature_importances_([numpy.nonzero(clf.feature_importances_)]))):\n",
    "#    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f, feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "#>>> import os\n",
    "#>>> os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydot\n",
    ">>> from IPython.display import Image  \n",
    ">>> dot_data = StringIO()  \n",
    ">>> tree.export_graphviz(clf,  out_file=dot_data,\n",
    "                         feature_names=feature_names,\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    ">>> graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#>>> Image(graph.create_png())   \n",
    ">>> graph.write_pdf(\"iris.pdf\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
